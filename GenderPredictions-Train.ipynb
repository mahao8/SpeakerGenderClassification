{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from Utils import *\n",
    "from classifier.CNNClassifier import CNNClassifier\n",
    "from classifier.Classifier import Classifier\n",
    "from classifier.ConstantClassifier import ConstantClassifier\n",
    "from classifier.LinearClassifier import LinearClassifier\n",
    "from classifier.RFClassifier import RFClassifier\n",
    "from classifier.SNNClassifier import SNNClassifier\n",
    "from Settings import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from main import run_for_classifier\n",
    "\n",
    "SAVE=True\n",
    "LOAD=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features_with_label = files_to_features_with_labels(list_files(AUDIO_FILES_DIR))\n",
    "train_set, test_set = train_test_split(features_with_label, random_state=SEED, train_size=TRAIN_PERCENT, test_size=1-TRAIN_PERCENT)\n",
    "\n",
    "def test_classifier(classifier : Classifier) -> None:\n",
    "    \"\"\"\n",
    "    Wrapper for method run_for_classifier.\n",
    "    :param classifier: The classifier to test\n",
    "    \"\"\"\n",
    "    one_d = not isinstance(classifier, CNNClassifier)\n",
    "    run_for_classifier(classifier, test_set=test_set, train_set=train_set, save=SAVE, load=LOAD, one_d=one_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_for_classifier\n",
      "Finished loading/creating features\n",
      "Using classifier RFClassifier - n_est 10 - max_depth None\n",
      "Training RFClassifier - n_est 10 - max_depth None\n",
      "Saved RFClassifier - n_est 10 - max_depth None\n",
      "ModePath:models/RFClassifier - n_est 10 - max_depth None.pkl\n",
      "Predicting on files...\n",
      "Predicting on samples...\n",
      "Test accuracy - files : 0.9522821576763485\n",
      "Test accuracy - samples : 0.7911369786082606\n"
     ]
    }
   ],
   "source": [
    "test_classifier(RFClassifier(n_estimators=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run_for_classifier\n",
    "Finished loading/creating features\n",
    "Using classifier RFClassifier - n_est 10 - max_depth None\n",
    "Training RFClassifier - n_est 10 - max_depth None\n",
    "Saved RFClassifier - n_est 10 - max_depth None\n",
    "ModePath:models/RFClassifier - n_est 10 - max_depth None.pkl\n",
    "Predicting on files...\n",
    "Predicting on samples...\n",
    "Test accuracy - files : 0.9522821576763485\n",
    "Test accuracy - samples : 0.7911369786082606"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run_for_classifier\n",
    "Finished loading/creating features\n",
    "Using classifier RFClassifier - n_est 10 - max_depth None\n",
    "Training RFClassifier - n_est 10 - max_depth None\n",
    "Saved RFClassifier - n_est 10 - max_depth None\n",
    "ModePath:models/RFClassifier - n_est 10 - max_depth None.pkl\n",
    "Predicting on files...\n",
    "Predicting on samples...\n",
    "Test accuracy - files : 0.9801587301587301\n",
    "Test accuracy - samples : 0.8513413029800377"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run_for_classifier\n",
    "Finished loading/creating features\n",
    "Using classifier RFClassifier - n_est 10 - max_depth None\n",
    "Training RFClassifier - n_est 10 - max_depth None\n",
    "Saved RFClassifier - n_est 10 - max_depth None\n",
    "ModePath:models/RFClassifier - n_est 10 - max_depth None.pkl\n",
    "Predicting on files...\n",
    "Predicting on samples...\n",
    "Test accuracy - files : 0.9714285714285714\n",
    "Test accuracy - samples : 0.8023207625362619"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "run_for_classifier \n",
    "Finished loading/creating features\n",
    "Using classifier RFClassifier - n_est 10 - max_depth None\n",
    "Training RFClassifier - n_est 10 - max_depth None\n",
    "Saved RFClassifier - n_est 10 - max_depth None\n",
    "ModePath:models/RFClassifier - n_est 10 - max_depth None.pkl\n",
    "Predicting on files...\n",
    "Predicting on samples...\n",
    "Test accuracy - files : 0.9327485380116959\n",
    "Test accuracy - samples : 0.8101299566811063"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run_for_classifier\n",
    "Finished loading/creating features\n",
    "Using classifier RFClassifier - n_est 10 - max_depth None\n",
    "Training RFClassifier - n_est 10 - max_depth None\n",
    "Saved RFClassifier - n_est 10 - max_depth None\n",
    "ModePath:models/RFClassifier - n_est 10 - max_depth None.pkl\n",
    "Predicting on files...\n",
    "Predicting on samples...\n",
    "Test accuracy - files : 0.9780743565300286\n",
    "Test accuracy - samples : 0.7923260066032648"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run_for_classifier\n",
    "Finished loading/creating features\n",
    "Using classifier RFClassifier - n_est 10 - max_depth None\n",
    "Training RFClassifier - n_est 10 - max_depth None\n",
    "Saved RFClassifier - n_est 10 - max_depth None\n",
    "ModePath:models/RFClassifier - n_est 10 - max_depth None.pkl\n",
    "Predicting on files...\n",
    "Predicting on samples...\n",
    "Test accuracy - files : 0.9805680119581465\n",
    "Test accuracy - samples : 0.8075283937263386"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run_for_classifier\n",
    "Finished loading/creating features\n",
    "Using classifier RFClassifier - n_est 10 - max_depth None\n",
    "Training RFClassifier - n_est 10 - max_depth None\n",
    "Saved RFClassifier - n_est 10 - max_depth None\n",
    "ModePath:models/RFClassifier - n_est 10 - max_depth None.pkl\n",
    "Predicting on files...\n",
    "Predicting on samples...\n",
    "Test accuracy - files : 0.9805680119581465\n",
    "Test accuracy - samples : 0.8075283937263386"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run_for_classifier\n",
    "Finished loading/creating features\n",
    "Using classifier RFClassifier - n_est 10 - max_depth None\n",
    "Training RFClassifier - n_est 10 - max_depth None\n",
    "Saved RFClassifier - n_est 10 - max_depth None\n",
    "ModePath:models/RFClassifier - n_est 10 - max_depth None.pkl\n",
    "Predicting on files...\n",
    "Predicting on samples...\n",
    "Test accuracy - files : 0.9819078947368421\n",
    "Test accuracy - samples : 0.8106407598476447"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run_for_classifier\n",
    "Finished loading/creating features\n",
    "Using classifier RFClassifier - n_est 10 - max_depth None\n",
    "Training RFClassifier - n_est 10 - max_depth None\n",
    "Saved RFClassifier - n_est 10 - max_depth None\n",
    "ModePath:models/RFClassifier - n_est 10 - max_depth None.pkl\n",
    "Predicting on files...\n",
    "Predicting on samples...\n",
    "Test accuracy - files : 0.9748427672955975\n",
    "Test accuracy - samples : 0.7540060177734238"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run_for_classifier\n",
    "Finished loading/creating features\n",
    "Using classifier RFClassifier - n_est 10 - max_depth None\n",
    "Training RFClassifier - n_est 10 - max_depth None\n",
    "Saved RFClassifier - n_est 10 - max_depth None\n",
    "ModePath:models/RFClassifier - n_est 10 - max_depth None.pkl\n",
    "Predicting on files...\n",
    "Predicting on samples...\n",
    "Test accuracy - files : 0.948220064724919\n",
    "Test accuracy - samples : 0.7349437337341006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run_for_classifier\n",
    "Finished loading/creating features\n",
    "Using classifier RFClassifier - n_est 10 - max_depth None\n",
    "Training RFClassifier - n_est 10 - max_depth None\n",
    "Saved RFClassifier - n_est 10 - max_depth None\n",
    "ModePath:models/RFClassifier - n_est 10 - max_depth None.pkl\n",
    "Predicting on files...\n",
    "Predicting on samples...\n",
    "Test accuracy - files : 0.9722222222222222\n",
    "Test accuracy - samples : 0.7556776128705543"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run_for_classifier\n",
    "Finished loading/creating features\n",
    "Using classifier RFClassifier - n_est 10 - max_depth None\n",
    "Training RFClassifier - n_est 10 - max_depth None\n",
    "Saved RFClassifier - n_est 10 - max_depth None\n",
    "ModePath:models/RFClassifier - n_est 10 - max_depth None.pkl\n",
    "Predicting on files...\n",
    "Predicting on samples...\n",
    "Test accuracy - files : 0.9754385964912281\n",
    "Test accuracy - samples : 0.7609640299348194"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run_for_classifier\n",
    "Finished loading/creating features\n",
    "Using classifier RFClassifier - n_est 10 - max_depth None\n",
    "Training RFClassifier - n_est 10 - max_depth None\n",
    "Saved RFClassifier - n_est 10 - max_depth None\n",
    "ModePath:models/RFClassifier - n_est 10 - max_depth None.pkl\n",
    "Predicting on files...\n",
    "Predicting on samples...\n",
    "Test accuracy - files : 0.9820143884892086\n",
    "Test accuracy - samples : 0.7675503799141064"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run_for_classifier\n",
    "Finished loading/creating features\n",
    "Using classifier RFClassifier - n_est 10 - max_depth None\n",
    "Training RFClassifier - n_est 10 - max_depth None\n",
    "Saved RFClassifier - n_est 10 - max_depth None\n",
    "ModePath:models/RFClassifier - n_est 10 - max_depth None.pkl\n",
    "Predicting on files...\n",
    "Predicting on samples...\n",
    "Test accuracy - files : 0.9560439560439561\n",
    "Test accuracy - samples : 0.767567787639443"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_for_classifier\n",
      "Finished loading/creating features\n",
      "Using classifier RFClassifier - n_est 100 - max_depth None\n",
      "Training RFClassifier - n_est 100 - max_depth None\n",
      "Saved RFClassifier - n_est 100 - max_depth None\n",
      "ModePath:models/RFClassifier - n_est 100 - max_depth None.pkl\n",
      "Predicting on files...\n",
      "Predicting on samples...\n",
      "Test accuracy - files : 0.966804979253112\n",
      "Test accuracy - samples : 0.8287639761066014\n"
     ]
    }
   ],
   "source": [
    "test_classifier(RFClassifier(n_estimators=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run_for_classifier\n",
    "Finished loading/creating features\n",
    "Using classifier RFClassifier - n_est 100 - max_depth None\n",
    "Training RFClassifier - n_est 100 - max_depth None\n",
    "Saved RFClassifier - n_est 100 - max_depth None\n",
    "ModePath:models/RFClassifier - n_est 100 - max_depth None.pkl\n",
    "Predicting on files...\n",
    "Predicting on samples...\n",
    "Test accuracy - files : 0.969047619047619\n",
    "Test accuracy - samples : 0.8715568593163971"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run_for_classifier\n",
    "Finished loading/creating features\n",
    "Using classifier RFClassifier - n_est 100 - max_depth None\n",
    "Training RFClassifier - n_est 100 - max_depth None\n",
    "Saved RFClassifier - n_est 100 - max_depth None\n",
    "ModePath:models/RFClassifier - n_est 100 - max_depth None.pkl\n",
    "Predicting on files...\n",
    "Predicting on samples...\n",
    "Test accuracy - files : 0.9214285714285714\n",
    "Test accuracy - samples : 0.8354745130542892"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run_for_classifier\n",
    "Finished loading/creating features\n",
    "Using classifier RFClassifier - n_est 100 - max_depth None\n",
    "Training RFClassifier - n_est 100 - max_depth None\n",
    "Saved RFClassifier - n_est 100 - max_depth None\n",
    "ModePath:models/RFClassifier - n_est 100 - max_depth None.pkl\n",
    "Predicting on files...\n",
    "Predicting on samples...\n",
    "Test accuracy - files : 0.956140350877193\n",
    "Test accuracy - samples : 0.8393868710429857"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run_for_classifier\n",
    "Finished loading/creating features\n",
    "Using classifier RFClassifier - n_est 100 - max_depth None\n",
    "Training RFClassifier - n_est 100 - max_depth None\n",
    "Saved RFClassifier - n_est 100 - max_depth None\n",
    "ModePath:models/RFClassifier - n_est 100 - max_depth None.pkl\n",
    "Predicting on files...\n",
    "Predicting on samples...\n",
    "Test accuracy - files : 0.9733079122974261\n",
    "Test accuracy - samples : 0.8285255777856702"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run_for_classifier\n",
    "Finished loading/creating features\n",
    "Using classifier RFClassifier - n_est 100 - max_depth None\n",
    "Training RFClassifier - n_est 100 - max_depth None\n",
    "Saved RFClassifier - n_est 100 - max_depth None\n",
    "ModePath:models/RFClassifier - n_est 100 - max_depth None.pkl\n",
    "Predicting on files...\n",
    "Predicting on samples...\n",
    "Test accuracy - files : 0.9745889387144993\n",
    "Test accuracy - samples : 0.8410383991346674"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run_for_classifier\n",
    "Finished loading/creating features\n",
    "Using classifier RFClassifier - n_est 100 - max_depth None\n",
    "Training RFClassifier - n_est 100 - max_depth None\n",
    "Saved RFClassifier - n_est 100 - max_depth None\n",
    "ModePath:models/RFClassifier - n_est 100 - max_depth None.pkl\n",
    "Predicting on files...\n",
    "Predicting on samples...\n",
    "Test accuracy - files : 0.9802631578947368\n",
    "Test accuracy - samples : 0.8487054626102888"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run_for_classifier\n",
    "Finished loading/creating features\n",
    "Using classifier RFClassifier - n_est 100 - max_depth None\n",
    "Training RFClassifier - n_est 100 - max_depth None\n",
    "Saved RFClassifier - n_est 100 - max_depth None\n",
    "ModePath:models/RFClassifier - n_est 100 - max_depth None.pkl\n",
    "Predicting on files...\n",
    "Predicting on samples...\n",
    "Test accuracy - files : 0.9779874213836478\n",
    "Test accuracy - samples : 0.7998390595479673"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run_for_classifier\n",
    "Finished loading/creating features\n",
    "Using classifier RFClassifier - n_est 100 - max_depth None\n",
    "Training RFClassifier - n_est 100 - max_depth None\n",
    "Saved RFClassifier - n_est 100 - max_depth None\n",
    "ModePath:models/RFClassifier - n_est 100 - max_depth None.pkl\n",
    "Predicting on files...\n",
    "Predicting on samples...\n",
    "Test accuracy - files : 0.9546925566343042\n",
    "Test accuracy - samples : 0.7787471133756094"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run_for_classifier\n",
    "Finished loading/creating features\n",
    "Using classifier RFClassifier - n_est 100 - max_depth None\n",
    "Training RFClassifier - n_est 100 - max_depth None\n",
    "Saved RFClassifier - n_est 100 - max_depth None\n",
    "ModePath:models/RFClassifier - n_est 100 - max_depth None.pkl\n",
    "Predicting on files...\n",
    "Predicting on samples...\n",
    "Test accuracy - files : 0.9756944444444444\n",
    "Test accuracy - samples : 0.7995013828834093"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run_for_classifier\n",
    "Finished loading/creating features\n",
    "Using classifier RFClassifier - n_est 100 - max_depth None\n",
    "Training RFClassifier - n_est 100 - max_depth None\n",
    "Saved RFClassifier - n_est 100 - max_depth None\n",
    "ModePath:models/RFClassifier - n_est 100 - max_depth None.pkl\n",
    "Predicting on files...\n",
    "Predicting on samples...\n",
    "Test accuracy - files : 0.9719298245614035\n",
    "Test accuracy - samples : 0.8007564174780719"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run_for_classifier\n",
    "Finished loading/creating features\n",
    "Using classifier RFClassifier - n_est 100 - max_depth None\n",
    "Training RFClassifier - n_est 100 - max_depth None\n",
    "Saved RFClassifier - n_est 100 - max_depth None\n",
    "ModePath:models/RFClassifier - n_est 100 - max_depth None.pkl\n",
    "Predicting on files...\n",
    "Predicting on samples...\n",
    "Test accuracy - files : 0.9646643109540636\n",
    "Test accuracy - samples : 0.7948184038761863"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run_for_classifier\n",
    "Finished loading/creating features\n",
    "Using classifier RFClassifier - n_est 100 - max_depth None\n",
    "Training RFClassifier - n_est 100 - max_depth None\n",
    "Saved RFClassifier - n_est 100 - max_depth None\n",
    "ModePath:models/RFClassifier - n_est 100 - max_depth None.pkl\n",
    "Predicting on files...\n",
    "Predicting on samples...\n",
    "Test accuracy - files : 0.9820143884892086\n",
    "Test accuracy - samples : 0.8051288404360754"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run_for_classifier\n",
    "Finished loading/creating features\n",
    "Using classifier RFClassifier - n_est 100 - max_depth None\n",
    "Training RFClassifier - n_est 100 - max_depth None\n",
    "Saved RFClassifier - n_est 100 - max_depth None\n",
    "ModePath:models/RFClassifier - n_est 100 - max_depth None.pkl\n",
    "Predicting on files...\n",
    "Predicting on samples...\n",
    "Test accuracy - files : 0.978021978021978\n",
    "Test accuracy - samples : 0.8037619086393616"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run_for_classifier\n",
    "Finished loading/creating features\n",
    "Using classifier RFClassifier - n_est 100 - max_depth None\n",
    "Training RFClassifier - n_est 100 - max_depth None\n",
    "Saved RFClassifier - n_est 100 - max_depth None\n",
    "ModePath:models/RFClassifier - n_est 100 - max_depth None.pkl\n",
    "Predicting on files...\n",
    "Predicting on samples...\n",
    "Test accuracy - files : 0.984313725490196\n",
    "Test accuracy - samples : 0.8058165548098434"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run_for_classifier\n",
    "Finished loading/creating features\n",
    "Using classifier RFClassifier - n_est 100 - max_depth None\n",
    "Training RFClassifier - n_est 100 - max_depth None\n",
    "Saved RFClassifier - n_est 100 - max_depth None\n",
    "ModePath:models/RFClassifier - n_est 100 - max_depth None.pkl\n",
    "Predicting on files...\n",
    "Predicting on samples...\n",
    "Test accuracy - files : 0.9740740740740741\n",
    "Test accuracy - samples : 0.7995526496902959"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run_for_classifier\n",
    "Finished loading/creating features\n",
    "Using classifier RFClassifier - n_est 100 - max_depth None\n",
    "Training RFClassifier - n_est 100 - max_depth None\n",
    "Saved RFClassifier - n_est 100 - max_depth None\n",
    "ModePath:models/RFClassifier - n_est 100 - max_depth None.pkl\n",
    "Predicting on files...\n",
    "Predicting on samples...\n",
    "Test accuracy - files : 0.9839357429718876\n",
    "Test accuracy - samples : 0.8234393987128134"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_for_classifier\n",
      "Finished loading/creating features\n",
      "Using classifier RFClassifier - n_est 10 - max_depth None\n",
      "Training RFClassifier - n_est 10 - max_depth None\n",
      "Saved RFClassifier - n_est 10 - max_depth None\n",
      "ModePath:models/RFClassifier - n_est 10 - max_depth None.pkl\n",
      "Predicting on files...\n",
      "Predicting on samples...\n",
      "Test accuracy - files : 0.9717741935483871\n",
      "Test accuracy - samples : 0.7775365268919346\n"
     ]
    }
   ],
   "source": [
    "test_classifier(RFClassifier(n_estimators=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run_for_classifier\n",
    "Finished loading/creating features\n",
    "Using classifier RFClassifier - n_est 100 - max_depth None\n",
    "Training RFClassifier - n_est 100 - max_depth None\n",
    "Saved RFClassifier - n_est 100 - max_depth None\n",
    "ModePath:models/RFClassifier - n_est 100 - max_depth None.pkl\n",
    "Predicting on files...\n",
    "Predicting on samples...\n",
    "Test accuracy - files : 0.9873417721518988\n",
    "Test accuracy - samples : 0.8189973852673339"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_classifier(classifier : Classifier) -> None:\n",
    "    \"\"\"\n",
    "    Wrapper for method run_for_classifier.\n",
    "    :param classifier: The classifier to test\n",
    "    \"\"\"\n",
    "    one_d = not isinstance(classifier, CNNClassifier)\n",
    "    run_for_classifier(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_multi_for_classifier(classifier: Classifier, one_d: bool = True, cv: int = None,\n",
    "                       train_set: np.ndarray = None,\n",
    "                       test_set: np.ndarray = None,\n",
    "                       save: bool = True,\n",
    "                       load: bool = True) -> None:\n",
    "    \"\"\"\n",
    "    Test a given classifier and print the results.\n",
    "    :param classifier: The classifier to test\n",
    "    :param one_d: If the features are to be flattened or not\n",
    "    :param cv: If >1, will run cross validation(on samples) with the given number of splits on the classifier\n",
    "    :param train_set: Optionally given to save time if run_for_classifier is called multiple times\n",
    "    :param test_set: Optionally given to save time if run_for_classifier is called multiple times\n",
    "    :param save: If the classifier is to be saved to a file\n",
    "    :param load: If the classifier is to be loaded from a file\n",
    "    \"\"\"\n",
    "    print(\"run_for_classifier..\")\n",
    "    #folder = \"data/TIMIT\"\n",
    "    #folder = \"predict_dir/DR5\"\n",
    "    #folder = \"predict_dir/Test\"\n",
    "    folder = \"data/Train/Train\"\n",
    "    #folder = \"data/TIMIT/TEST/DR5\"\n",
    "    if train_set is None or test_set is None:\n",
    "        features_with_label = files_to_features_with_labels(list_files(folder))\n",
    "        test_set = features_with_label\n",
    "    print(\"Finished loading/creating features\")\n",
    "    print(\"Using classifier \" + classifier.get_classifier_name())\n",
    "    classifier.load(MODELS_DIR + classifier.get_classifier_name() + DUMP_EXT)\n",
    "    print(\"ModePath:\"+MODELS_DIR + classifier.get_classifier_name() + DUMP_EXT)\n",
    "    print(\"Predicting on files...\")\n",
    "    predictions = []\n",
    "    test_labels = extract_labels(test_set)\n",
    "    for feat_label_tuple in test_set:\n",
    "        features = feat_label_tuple[0]   \n",
    "        if not one_d:\n",
    "            features = extract_features(cut_file(feat_label_tuple))\n",
    "            # Add depth dimension\n",
    "            features = np.asarray(\n",
    "                list(map(lambda sample: sample.reshape(sample.shape[0], sample.shape[1], 1), features)))\n",
    "        results = classifier.predict(features)\n",
    "        predictions.append(return_majority(results))\n",
    "    predictions = np.asarray(predictions)\n",
    "    print(predictions)\n",
    "    print(test_labels)\n",
    "    if not os.path.isdir(OUTPUT_DIR):\n",
    "        os.mkdir(OUTPUT_DIR)\n",
    "    with open(OUTPUT_DIR + classifier.get_classifier_name() + \"_output.txt\", \"w\") as output_file:\n",
    "        output_file.writelines([str(pred) + \"\\n\" for pred in predictions])\n",
    "\n",
    "    # Per sample predictions\n",
    "    print(\"Predicting on samples...\")\n",
    "    if one_d:\n",
    "        transformed_test_set = to_1d(test_set)\n",
    "    else:\n",
    "        transformed_test_set = to_2d(test_set)\n",
    "\n",
    "    samples_features = extract_features(transformed_test_set)\n",
    "    samples_predictions = classifier.predict(samples_features)\n",
    "    samples_test_labels = extract_labels(transformed_test_set)\n",
    "    print(samples_predictions)\n",
    "    print(samples_test_labels)\n",
    "    #prediction = classMode.predict(samples_features)\n",
    "    #print(\"New Test accuracy - files : \" + str(get_accuracy(predictions, test_labels)))\n",
    "    print(\"Test accuracy - files : \" + str(get_accuracy(predictions, test_labels)))\n",
    "    print(\"Test accuracy - samples : \" + str(get_accuracy(samples_predictions, samples_test_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_for_classifier..\n",
      "Finished loading/creating features\n",
      "Using classifier RFClassifier - n_est 100 - max_depth None\n",
      "ModePath:models/RFClassifier - n_est 100 - max_depth None.pkl\n",
      "Predicting on files...\n",
      "[0 0 0 ... 1 1 1]\n",
      "[0 0 0 ... 1 1 1]\n",
      "Predicting on samples...\n",
      "[0 0 0 ... 1 1 1]\n",
      "[0 0 0 ... 1 1 1]\n",
      "Test accuracy - files : 0.9938095238095238\n",
      "Test accuracy - samples : 0.9742056491909216\n"
     ]
    }
   ],
   "source": [
    "run_multi_for_classifier(RFClassifier(n_estimators=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test accuracy - files : 0.9842180774748924\n",
    "Test accuracy - samples : 0.9667518110631883"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_for_classifier..\n",
      "Finished loading/creating features\n",
      "Using classifier RFClassifier - n_est 10 - max_depth None\n",
      "ModePath:models/RFClassifier - n_est 10 - max_depth None.pkl\n",
      "Predicting on files...\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Predicting on samples...\n",
      "[0 0 0 ... 1 1 1]\n",
      "[0 0 0 ... 1 1 1]\n",
      "Test accuracy - files : 0.994261119081779\n",
      "Test accuracy - samples : 0.9572463464679034\n"
     ]
    }
   ],
   "source": [
    "run_multi_for_classifier(RFClassifier(n_estimators=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test accuracy - files : 0.994261119081779\n",
    "Test accuracy - samples : 0.9572463464679034"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_for_classifier..\n",
      "Finished loading/creating features\n",
      "Using classifier CNNClassifier\n",
      "ModePath:models/CNNClassifier.pkl\n",
      "Predicting on files...\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Predicting on samples...\n",
      "[0 0 0 ... 1 1 1]\n",
      "[0 0 0 ... 1 1 1]\n",
      "Test accuracy - files : 0.9827833572453372\n",
      "Test accuracy - samples : 0.950571744743637\n"
     ]
    }
   ],
   "source": [
    "run_multi_for_classifier(CNNClassifier(verbose=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test accuracy - files : 0.9827833572453372\n",
    "Test accuracy - samples : 0.950571744743637"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run_for_classifier..\n",
    "Finished loading/creating features\n",
    "Using classifier RFClassifier - n_est 10 - max_depth None\n",
    "ModePath:models/RFClassifier - n_est 10 - max_depth None.pkl\n",
    "Predicting on files...\n",
    "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
    " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
    " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
    " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
    " 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
    " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
    " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
    " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
    " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
    " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
    " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
    " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
    "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
    " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
    " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
    " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
    " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
    " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
    " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
    " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
    " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
    " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
    " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
    " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
    "Predicting on samples...\n",
    "[0 0 0 ... 1 1 1]\n",
    "[0 0 0 ... 1 1 1]\n",
    "Test accuracy - files : 0.994261119081779\n",
    "Test accuracy - samples : 0.9572463464679034"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run_for_classifier..\n",
    "Finished loading/creating features\n",
    "Using classifier RFClassifier - n_est 10 - max_depth None\n",
    "ModePath:models/RFClassifier - n_est 10 - max_depth None.pkl\n",
    "Predicting on files...\n",
    "[0 0 0 ... 1 1 1]\n",
    "[0 0 0 ... 1 1 1]\n",
    "Predicting on samples...\n",
    "[0 1 0 ... 1 1 1]\n",
    "[0 0 0 ... 1 1 1]\n",
    "Test accuracy - files : 0.9865418373317729\n",
    "Test accuracy - samples : 0.9571777706938689"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run_for_classifier..\n",
    "Finished loading/creating features\n",
    "Using classifier RFClassifier - n_est 100 - max_depth None\n",
    "ModePath:models/RFClassifier - n_est 100 - max_depth None.pkl\n",
    "Predicting on files...\n",
    "[0 0 0 ... 1 1 1]\n",
    "[0 0 0 ... 1 1 1]\n",
    "Predicting on samples...\n",
    "[0 0 0 ... 1 1 1]\n",
    "[0 0 0 ... 1 1 1]\n",
    "Test accuracy - files : 0.9912229373902867\n",
    "Test accuracy - samples : 0.9679895866539157"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_for_classifier\n",
      "Finished loading/creating features\n",
      "Using classifier RFClassifier - n_est 100 - max_depth None\n",
      "Training RFClassifier - n_est 100 - max_depth None\n",
      "Saved RFClassifier - n_est 100 - max_depth None\n",
      "ModePath:models/RFClassifier - n_est 100 - max_depth None.pkl\n",
      "Predicting on files...\n",
      "Predicting on samples...\n",
      "Test accuracy - files : 0.9751243781094527\n",
      "Test accuracy - samples : 0.8437397305290831\n"
     ]
    }
   ],
   "source": [
    "test_classifier(RFClassifier(n_estimators=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_for_classifier..\n",
      "Finished loading/creating features\n",
      "Using classifier RFClassifier - n_est 100 - max_depth None\n",
      "ModePath:models/RFClassifier - n_est 100 - max_depth None.pkl\n",
      "Predicting on files...\n",
      "[1 1]\n",
      "[0 0]\n",
      "Predicting on samples...\n",
      "[1 1 1 ... 1 1 1]\n",
      "[0 0 0 ... 0 0 0]\n",
      "Test accuracy - files : 0.0\n",
      "Test accuracy - samples : 0.12033067973055726\n"
     ]
    }
   ],
   "source": [
    "test_classifier(RFClassifier(n_estimators=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminary informations\n",
    "##### Disclaimer : The neural networks results may vary a bit when re-training them due to some randomness in tensorflow-gpu / cuDNN.\n",
    "\n",
    "The models were trained on a computer with an i7-6700K, 16GB RAM and a GTX 1070.    \n",
    "The main libraries used are Keras with tensorflow backend, librosa, scikit-learn.    \n",
    "###### If you want to avoid retraining every classifier, set LOAD=True above. The RF with 100 estimators couldn't be pushed to the repository due to its file size though.\n",
    "\n",
    "Let's begin by explaining how to measure the performance of the classifiers. There are two main metrics :    \n",
    "- The sample accuracy : It's the accuracy for predicting the label of a sample of a file. For the CNN, it's a window of 10 samples.\n",
    "- The file accuracy : It's the accuracy for predicting the label of a file. The label is simply calculated by taking the most predicted label on all the samples of the file.\n",
    "\n",
    "The files were cut in samples of 20 MFCC features using the librosa library. This was mostly sufficient to allow the training on most of the classifiers. No preprocessing was done on the audio files or the MFCC features except normalizing them.    \n",
    "Some more preprocessing was done to allow the files to be fed to a CNN (cutting the files in windows).\n",
    "\n",
    "The files were separated in train set and test set using 80/20 proportions. There are 2703 files in total."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constant Classifier\n",
    "This classifier always predicts male."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_for_classifier\n",
      "Finished loading/creating features\n",
      "Using classifier ConstantClassifierTimit\n",
      "Training ConstantClassifierTimit\n",
      "Saved ConstantClassifierTimit\n",
      "ModePath:models/ConstantClassifierTimit.pkl\n",
      "Predicting on files...\n",
      "Predicting on samples...\n",
      "Test accuracy - files : 0.5021645021645021\n",
      "Test accuracy - samples : 0.45987015430937145\n"
     ]
    }
   ],
   "source": [
    "test_classifier(ConstantClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us some information on the files as well as a baseline :     \n",
    "- The files are distributed nearly uniformly between male and female\n",
    "- When taking duration into account, the files are distributed even more closely half male / half female\n",
    "\n",
    "This means that it is not really needed to perform balancing between the train and test set, assuming we distribute the files randomly between them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVC\n",
    "This classifier is created using SVM with a linear kernel. It could serve as another simple baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_for_classifier\n",
      "Finished loading/creating features\n",
      "Using classifier LinearClassifier - C1\n",
      "Training LinearClassifier - C1\n",
      "Saved LinearClassifier - C1\n",
      "ModePath:models/LinearClassifier - C1.pkl\n",
      "Predicting on files...\n",
      "Predicting on samples...\n",
      "Test accuracy - files : 0.9233870967741935\n",
      "Test accuracy - samples : 0.7227574976251866\n"
     ]
    }
   ],
   "source": [
    "test_classifier(LinearClassifier(c=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_for_classifier\n",
    "Finished loading/creating features\n",
    "Using classifier LinearClassifier - C1\n",
    "Training LinearClassifier - C1\n",
    "Saved LinearClassifier - C1\n",
    "ModePath:models/LinearClassifier - C1.pkl\n",
    "Predicting on files...\n",
    "Predicting on samples...\n",
    "Test accuracy - files : 0.9307359307359307\n",
    "Test accuracy - samples : 0.7412965750846819"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Here, the linear SVC returns quite mediocre results, having a file-accuracy of only 82%, and a worse sample accuracy of 70%.    \n",
    "Trying to increase the C parameter to 1000 makes the classifier not converge (or very slowly. When tested earlier, it hadn't converged in 10000 iterations).    \n",
    "It isn't surprising that a linear classifier would fail on this problem, as it is probably non-linear. Improving the preprocessing as well as doing features selection could improve the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_for_classifier\n",
      "Finished loading/creating features\n",
      "Using classifier LinearClassifier - C1000\n",
      "Training LinearClassifier - C1000\n",
      "Saved LinearClassifier - C1000\n",
      "ModePath:models/LinearClassifier - C1000.pkl\n",
      "Predicting on files...\n",
      "Predicting on samples...\n",
      "Test accuracy - files : 0.5604838709677419\n",
      "Test accuracy - samples : 0.6452254941873614\n"
     ]
    }
   ],
   "source": [
    "test_classifier(LinearClassifier(c=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_for_classifier\n",
    "Finished loading/creating features\n",
    "Using classifier LinearClassifier - C1000\n",
    "Training LinearClassifier - C1000\n",
    "Saved LinearClassifier - C1000\n",
    "ModePath:models/LinearClassifier - C1000.pkl\n",
    "Predicting on files...\n",
    "Predicting on samples...\n",
    "Test accuracy - files : 0.5021645021645021\n",
    "Test accuracy - samples : 0.48367519759126837"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestClassifier\n",
    "Let's test RandomForestClassifiers, which are known to be quite accurate when features are well-defined and results are dependent on these features, which should be the case with the MFCC features and the speaker's gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_for_classifier\n",
      "Finished loading/creating features\n",
      "Using classifier RFClassifier - n_est 10 - max_depth None\n",
      "Training RFClassifier - n_est 10 - max_depth None\n",
      "Saved RFClassifier - n_est 10 - max_depth None\n",
      "ModePath:models/RFClassifier - n_est 10 - max_depth None.pkl\n",
      "Predicting on files...\n",
      "Predicting on samples...\n",
      "Test accuracy - files : 0.9800995024875622\n",
      "Test accuracy - samples : 0.8138898017307482\n"
     ]
    }
   ],
   "source": [
    "test_classifier(RFClassifier(n_estimators=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we can already see that the files accuracy is nearly perfect (in fact, only 1 file is mispredicted). The sample accuracy could be better though.    \n",
    "Let's try to improve it by increasing the number of trees. We may also get a 100% file accuracy by doing this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_for_classifier\n",
      "Finished loading/creating features\n",
      "Using classifier RFClassifier - n_est 100 - max_depth None\n",
      "Training RFClassifier - n_est 100 - max_depth None\n",
      "Saved RFClassifier - n_est 100 - max_depth None\n",
      "ModePath:models/RFClassifier - n_est 100 - max_depth None.pkl\n",
      "Predicting on files...\n",
      "Predicting on samples...\n",
      "Test accuracy - files : 0.9914529914529915\n",
      "Test accuracy - samples : 0.836785648233771\n"
     ]
    }
   ],
   "source": [
    "test_classifier(RFClassifier(n_estimators=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It doesn't seem to improve much and isn't really worth it given the increase in memory and time consumption. It is better, as expected (averaging over more votes should lead to a better result), but not needed for the files accuracy.    \n",
    "Let's try with 1 and 5 trees to see if we can go lower than 10 while preserving the accuracy :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_for_classifier\n",
      "Finished loading/creating features\n",
      "Using classifier RFClassifier - n_est 5 - max_depth None\n",
      "Training RFClassifier - n_est 5 - max_depth None\n",
      "Saved RFClassifier - n_est 5 - max_depth None\n",
      "ModePath:models/RFClassifier - n_est 5 - max_depth None.pkl\n",
      "Predicting on files...\n",
      "Predicting on samples...\n",
      "Test accuracy - files : 0.9761677788369876\n",
      "Test accuracy - samples : 0.7735422174868132\n",
      "\n",
      "\n",
      "run_for_classifier\n",
      "Finished loading/creating features\n",
      "Using classifier RFClassifier - n_est 1 - max_depth None\n",
      "Training RFClassifier - n_est 1 - max_depth None\n",
      "Saved RFClassifier - n_est 1 - max_depth None\n",
      "ModePath:models/RFClassifier - n_est 1 - max_depth None.pkl\n",
      "Predicting on files...\n",
      "Predicting on samples...\n",
      "Test accuracy - files : 0.9599618684461392\n",
      "Test accuracy - samples : 0.7057732528313799\n"
     ]
    }
   ],
   "source": [
    "test_classifier(RFClassifier(n_estimators=5))\n",
    "print(\"\\n\")\n",
    "test_classifier(RFClassifier(n_estimators=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_for_classifier\n",
    "Finished loading/creating features\n",
    "Using classifier RFClassifier - n_est 5 - max_depth None\n",
    "Training RFClassifier - n_est 5 - max_depth None\n",
    "Saved RFClassifier - n_est 5 - max_depth None\n",
    "ModePath:models/RFClassifier - n_est 5 - max_depth None.pkl\n",
    "Predicting on files...\n",
    "Predicting on samples...\n",
    "Test accuracy - files : 0.9786184210526315\n",
    "Test accuracy - samples : 0.7906561882262186\n",
    "\n",
    "\n",
    "run_for_classifier\n",
    "Finished loading/creating features\n",
    "Using classifier RFClassifier - n_est 1 - max_depth None\n",
    "Training RFClassifier - n_est 1 - max_depth None\n",
    "Saved RFClassifier - n_est 1 - max_depth None\n",
    "ModePath:models/RFClassifier - n_est 1 - max_depth None.pkl\n",
    "Predicting on files...\n",
    "Predicting on samples...\n",
    "Test accuracy - files : 0.9671052631578947\n",
    "Test accuracy - samples : 0.7200231425678607"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run_for_classifier\n",
    "Finished loading/creating features\n",
    "Using classifier RFClassifier - n_est 5 - max_depth None\n",
    "Training RFClassifier - n_est 5 - max_depth None\n",
    "Saved RFClassifier - n_est 5 - max_depth None\n",
    "ModePath:models/RFClassifier - n_est 5 - max_depth None.pkl\n",
    "Predicting on files...\n",
    "Predicting on samples...\n",
    "Test accuracy - files : 0.9434628975265018\n",
    "Test accuracy - samples : 0.7369559123853762\n",
    "\n",
    "\n",
    "run_for_classifier\n",
    "Finished loading/creating features\n",
    "Using classifier RFClassifier - n_est 1 - max_depth None\n",
    "Training RFClassifier - n_est 1 - max_depth None\n",
    "Saved RFClassifier - n_est 1 - max_depth None\n",
    "ModePath:models/RFClassifier - n_est 1 - max_depth None.pkl\n",
    "Predicting on files...\n",
    "Predicting on samples...\n",
    "Test accuracy - files : 0.950530035335689\n",
    "Test accuracy - samples : 0.6760501341448765"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run_for_classifier\n",
    "Finished loading/creating features\n",
    "Using classifier RFClassifier - n_est 5 - max_depth None\n",
    "Training RFClassifier - n_est 5 - max_depth None\n",
    "Saved RFClassifier - n_est 5 - max_depth None\n",
    "ModePath:models/RFClassifier - n_est 5 - max_depth None.pkl\n",
    "Predicting on files...\n",
    "Predicting on samples...\n",
    "Test accuracy - files : 0.974025974025974\n",
    "Test accuracy - samples : 0.7659013925479865\n",
    "\n",
    "\n",
    "run_for_classifier\n",
    "Finished loading/creating features\n",
    "Using classifier RFClassifier - n_est 1 - max_depth None\n",
    "Training RFClassifier - n_est 1 - max_depth None\n",
    "Saved RFClassifier - n_est 1 - max_depth None\n",
    "ModePath:models/RFClassifier - n_est 1 - max_depth None.pkl\n",
    "Predicting on files...\n",
    "Predicting on samples...\n",
    "Test accuracy - files : 0.987012987012987\n",
    "Test accuracy - samples : 0.7046010538200979"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strangely enough, we get a really good result with even only one tree. The sample accuracy decreases quite a bit obviously, but the file accuracy is still very good. This means that there are features which are very relevant to finding the speaker's gender.   \n",
    "With 5 trees, the file accuracy is the same as the one with 10 trees.    \n",
    "The RandomForest seems to be very well suited for this problem, as expected. What was less expected was that such a performance was obtained using a very small number of estimators.    \n",
    "RandomForest is therefore a very efficient and easy way to solve this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shallow Neural Network\n",
    "Let's try using a shallow neural network with only a single fully-connected hidden layer.    \n",
    "In theory, such a simple neural net should be able to approximate every function perfectly, but in practice, a deep neural network usually yields better results than a wide one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_for_classifier\n",
      "Finished loading/creating features\n",
      "Using classifier SNNClassifier - units 64\n",
      "Training SNNClassifier - units 64\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 64)                1344      \n",
      "_________________________________________________________________\n",
      "p_re_lu_1 (PReLU)            (None, 64)                64        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 81080 samples, validate on 20270 samples\n",
      "Epoch 1/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.6258 - acc: 0.6486 - val_loss: 0.6057 - val_acc: 0.6509\n",
      "Epoch 2/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.5648 - acc: 0.6911 - val_loss: 0.5731 - val_acc: 0.6772\n",
      "Epoch 3/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.5354 - acc: 0.7116 - val_loss: 0.5562 - val_acc: 0.6906\n",
      "Epoch 4/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.5135 - acc: 0.7280 - val_loss: 0.5684 - val_acc: 0.6757\n",
      "Epoch 5/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.5007 - acc: 0.7365 - val_loss: 0.5329 - val_acc: 0.7185\n",
      "Epoch 6/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4914 - acc: 0.7407 - val_loss: 0.5257 - val_acc: 0.7252\n",
      "Epoch 7/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4850 - acc: 0.7460 - val_loss: 0.5274 - val_acc: 0.7144\n",
      "Epoch 8/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4796 - acc: 0.7483 - val_loss: 0.5145 - val_acc: 0.7293\n",
      "Epoch 9/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4753 - acc: 0.7517 - val_loss: 0.5129 - val_acc: 0.7312\n",
      "Epoch 10/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4713 - acc: 0.7544 - val_loss: 0.5239 - val_acc: 0.7118\n",
      "Epoch 11/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4681 - acc: 0.7580 - val_loss: 0.5085 - val_acc: 0.7326\n",
      "Epoch 12/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4650 - acc: 0.7602 - val_loss: 0.5136 - val_acc: 0.7269\n",
      "Epoch 13/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4619 - acc: 0.7629 - val_loss: 0.5007 - val_acc: 0.7442\n",
      "Epoch 14/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4600 - acc: 0.7618 - val_loss: 0.5112 - val_acc: 0.7246\n",
      "Epoch 15/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4573 - acc: 0.7645 - val_loss: 0.4975 - val_acc: 0.7482\n",
      "Epoch 16/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4550 - acc: 0.7666 - val_loss: 0.5093 - val_acc: 0.7291\n",
      "Epoch 17/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4531 - acc: 0.7676 - val_loss: 0.5048 - val_acc: 0.7294\n",
      "Epoch 18/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4511 - acc: 0.7692 - val_loss: 0.4957 - val_acc: 0.7451\n",
      "Epoch 19/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4493 - acc: 0.7698 - val_loss: 0.4946 - val_acc: 0.7433\n",
      "Epoch 20/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4479 - acc: 0.7706 - val_loss: 0.4895 - val_acc: 0.7529\n",
      "Epoch 21/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4457 - acc: 0.7725 - val_loss: 0.4867 - val_acc: 0.7519\n",
      "Epoch 22/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4443 - acc: 0.7723 - val_loss: 0.4898 - val_acc: 0.7499\n",
      "Epoch 23/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4427 - acc: 0.7751 - val_loss: 0.4963 - val_acc: 0.7381\n",
      "Epoch 24/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4421 - acc: 0.7732 - val_loss: 0.4923 - val_acc: 0.7456\n",
      "Epoch 25/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4397 - acc: 0.7764 - val_loss: 0.4848 - val_acc: 0.7532\n",
      "Epoch 26/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4392 - acc: 0.7760 - val_loss: 0.4894 - val_acc: 0.7427\n",
      "Epoch 27/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4378 - acc: 0.7776 - val_loss: 0.4892 - val_acc: 0.7462\n",
      "Epoch 28/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4366 - acc: 0.7790 - val_loss: 0.4817 - val_acc: 0.7587\n",
      "Epoch 29/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4361 - acc: 0.7786 - val_loss: 0.4856 - val_acc: 0.7496\n",
      "Epoch 30/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4352 - acc: 0.7781 - val_loss: 0.4903 - val_acc: 0.7467\n",
      "Epoch 31/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4344 - acc: 0.7793 - val_loss: 0.4811 - val_acc: 0.7600\n",
      "Epoch 32/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4329 - acc: 0.7795 - val_loss: 0.4802 - val_acc: 0.7561\n",
      "Epoch 33/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4317 - acc: 0.7798 - val_loss: 0.4789 - val_acc: 0.7598\n",
      "Epoch 34/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4305 - acc: 0.7821 - val_loss: 0.4780 - val_acc: 0.7604\n",
      "Epoch 35/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4302 - acc: 0.7810 - val_loss: 0.4810 - val_acc: 0.7575\n",
      "Epoch 36/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4288 - acc: 0.7833 - val_loss: 0.4792 - val_acc: 0.7539\n",
      "Epoch 37/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4279 - acc: 0.7831 - val_loss: 0.4798 - val_acc: 0.7574\n",
      "Epoch 38/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4274 - acc: 0.7837 - val_loss: 0.4757 - val_acc: 0.7621\n",
      "Epoch 39/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4267 - acc: 0.7836 - val_loss: 0.4750 - val_acc: 0.7616\n",
      "Epoch 40/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4263 - acc: 0.7844 - val_loss: 0.4842 - val_acc: 0.7476\n",
      "Epoch 41/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4255 - acc: 0.7853 - val_loss: 0.5003 - val_acc: 0.7317\n",
      "Epoch 42/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4243 - acc: 0.7859 - val_loss: 0.4848 - val_acc: 0.7447\n",
      "Epoch 43/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4231 - acc: 0.7871 - val_loss: 0.4841 - val_acc: 0.7475\n",
      "Epoch 44/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4231 - acc: 0.7877 - val_loss: 0.4837 - val_acc: 0.7491\n",
      "Epoch 45/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4223 - acc: 0.7879 - val_loss: 0.4798 - val_acc: 0.7483\n",
      "Epoch 46/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4220 - acc: 0.7865 - val_loss: 0.4984 - val_acc: 0.7354\n",
      "Epoch 47/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4197 - acc: 0.7901 - val_loss: 0.4727 - val_acc: 0.7589\n",
      "Epoch 48/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4209 - acc: 0.7884 - val_loss: 0.4897 - val_acc: 0.7422\n",
      "Epoch 49/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4200 - acc: 0.7887 - val_loss: 0.4728 - val_acc: 0.7600\n",
      "Epoch 50/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4193 - acc: 0.7904 - val_loss: 0.4809 - val_acc: 0.7499\n",
      "Epoch 51/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4190 - acc: 0.7892 - val_loss: 0.4739 - val_acc: 0.7581\n",
      "Epoch 52/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4185 - acc: 0.7897 - val_loss: 0.4752 - val_acc: 0.7559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4174 - acc: 0.7905 - val_loss: 0.4669 - val_acc: 0.7653\n",
      "Epoch 54/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4170 - acc: 0.7915 - val_loss: 0.4671 - val_acc: 0.7626\n",
      "Epoch 55/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4158 - acc: 0.7920 - val_loss: 0.4705 - val_acc: 0.7571\n",
      "Epoch 56/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4159 - acc: 0.7906 - val_loss: 0.4784 - val_acc: 0.7485\n",
      "Epoch 57/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4153 - acc: 0.7925 - val_loss: 0.4749 - val_acc: 0.7564\n",
      "Epoch 58/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4148 - acc: 0.7909 - val_loss: 0.4718 - val_acc: 0.7556\n",
      "Epoch 59/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4145 - acc: 0.7908 - val_loss: 0.4712 - val_acc: 0.7560\n",
      "Epoch 60/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4135 - acc: 0.7928 - val_loss: 0.4652 - val_acc: 0.7628\n",
      "Epoch 61/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4140 - acc: 0.7911 - val_loss: 0.4892 - val_acc: 0.7413\n",
      "Epoch 62/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4125 - acc: 0.7930 - val_loss: 0.4681 - val_acc: 0.7577\n",
      "Epoch 63/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4117 - acc: 0.7942 - val_loss: 0.4745 - val_acc: 0.7529\n",
      "Epoch 64/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4120 - acc: 0.7941 - val_loss: 0.4962 - val_acc: 0.7341\n",
      "Epoch 65/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4123 - acc: 0.7934 - val_loss: 0.4663 - val_acc: 0.7625\n",
      "Epoch 66/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4112 - acc: 0.7948 - val_loss: 0.4624 - val_acc: 0.7639\n",
      "Epoch 67/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4092 - acc: 0.7959 - val_loss: 0.4638 - val_acc: 0.7617\n",
      "Epoch 68/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4095 - acc: 0.7944 - val_loss: 0.4608 - val_acc: 0.7667\n",
      "Epoch 69/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4090 - acc: 0.7954 - val_loss: 0.4719 - val_acc: 0.7603\n",
      "Epoch 70/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4093 - acc: 0.7947 - val_loss: 0.4625 - val_acc: 0.7652\n",
      "Epoch 71/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4082 - acc: 0.7962 - val_loss: 0.4649 - val_acc: 0.7621\n",
      "Epoch 72/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4082 - acc: 0.7962 - val_loss: 0.4589 - val_acc: 0.7656\n",
      "Epoch 73/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4072 - acc: 0.7971 - val_loss: 0.4557 - val_acc: 0.7699\n",
      "Epoch 74/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4072 - acc: 0.7966 - val_loss: 0.4624 - val_acc: 0.7645\n",
      "Epoch 75/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4074 - acc: 0.7967 - val_loss: 0.4606 - val_acc: 0.7655\n",
      "Epoch 76/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4059 - acc: 0.7969 - val_loss: 0.4650 - val_acc: 0.7647\n",
      "Epoch 77/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4064 - acc: 0.7967 - val_loss: 0.4601 - val_acc: 0.7656\n",
      "Epoch 78/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4055 - acc: 0.7974 - val_loss: 0.4563 - val_acc: 0.7688\n",
      "Epoch 79/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4049 - acc: 0.7984 - val_loss: 0.4595 - val_acc: 0.7652\n",
      "Epoch 80/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4045 - acc: 0.7973 - val_loss: 0.4584 - val_acc: 0.7633\n",
      "Epoch 81/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4045 - acc: 0.7991 - val_loss: 0.4679 - val_acc: 0.7597\n",
      "Epoch 82/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4038 - acc: 0.7998 - val_loss: 0.4662 - val_acc: 0.7634\n",
      "Epoch 83/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4038 - acc: 0.7991 - val_loss: 0.4595 - val_acc: 0.7655\n",
      "\n",
      "Epoch 00083: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 84/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3971 - acc: 0.8046 - val_loss: 0.4566 - val_acc: 0.7697\n",
      "Epoch 85/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3964 - acc: 0.8046 - val_loss: 0.4556 - val_acc: 0.7699\n",
      "Epoch 86/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3961 - acc: 0.8041 - val_loss: 0.4546 - val_acc: 0.7703\n",
      "Epoch 87/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3961 - acc: 0.8049 - val_loss: 0.4543 - val_acc: 0.7710\n",
      "Epoch 88/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3961 - acc: 0.8047 - val_loss: 0.4551 - val_acc: 0.7694\n",
      "Epoch 89/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3961 - acc: 0.8046 - val_loss: 0.4581 - val_acc: 0.7678\n",
      "Epoch 90/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3959 - acc: 0.8054 - val_loss: 0.4586 - val_acc: 0.7687\n",
      "Epoch 91/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3959 - acc: 0.8051 - val_loss: 0.4551 - val_acc: 0.7714\n",
      "Epoch 92/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3959 - acc: 0.8052 - val_loss: 0.4543 - val_acc: 0.7704\n",
      "Epoch 93/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3958 - acc: 0.8056 - val_loss: 0.4553 - val_acc: 0.7699\n",
      "Epoch 94/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3958 - acc: 0.8044 - val_loss: 0.4578 - val_acc: 0.7681\n",
      "Epoch 95/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3957 - acc: 0.8044 - val_loss: 0.4559 - val_acc: 0.7687\n",
      "Epoch 96/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3956 - acc: 0.8053 - val_loss: 0.4527 - val_acc: 0.7716\n",
      "Epoch 97/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3956 - acc: 0.8052 - val_loss: 0.4591 - val_acc: 0.7670\n",
      "Epoch 98/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3955 - acc: 0.8058 - val_loss: 0.4561 - val_acc: 0.7684\n",
      "Epoch 99/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3954 - acc: 0.8053 - val_loss: 0.4573 - val_acc: 0.7693\n",
      "Epoch 100/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3956 - acc: 0.8053 - val_loss: 0.4531 - val_acc: 0.7713\n",
      "Epoch 101/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3956 - acc: 0.8052 - val_loss: 0.4580 - val_acc: 0.7667\n",
      "Epoch 102/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3955 - acc: 0.8055 - val_loss: 0.4562 - val_acc: 0.7696\n",
      "Epoch 103/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3954 - acc: 0.8045 - val_loss: 0.4574 - val_acc: 0.7680\n",
      "Epoch 104/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3954 - acc: 0.8056 - val_loss: 0.4564 - val_acc: 0.7693\n",
      "Epoch 105/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3953 - acc: 0.8058 - val_loss: 0.4618 - val_acc: 0.7650\n",
      "Epoch 106/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3953 - acc: 0.8044 - val_loss: 0.4559 - val_acc: 0.7691\n",
      "\n",
      "Epoch 00106: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 107/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3944 - acc: 0.8059 - val_loss: 0.4553 - val_acc: 0.7708\n",
      "Epoch 108/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3944 - acc: 0.8060 - val_loss: 0.4557 - val_acc: 0.7702\n",
      "Epoch 109/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3943 - acc: 0.8062 - val_loss: 0.4564 - val_acc: 0.7697\n",
      "Epoch 110/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3943 - acc: 0.8063 - val_loss: 0.4561 - val_acc: 0.7700\n",
      "Epoch 111/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3943 - acc: 0.8058 - val_loss: 0.4560 - val_acc: 0.7700\n",
      "Epoch 00111: early stopping\n",
      "Saved SNNClassifier - units 64\n",
      "ModePath:models/SNNClassifier - units 64.pkl\n",
      "Predicting on files...\n",
      "Predicting on samples...\n",
      "Test accuracy - files : 0.9540636042402827\n",
      "Test accuracy - samples : 0.7851279381732271\n"
     ]
    }
   ],
   "source": [
    "test_classifier(SNNClassifier(num_units=64, verbose=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test accuracy - files : 0.9800995024875622\n",
    "Test accuracy - samples : 0.8527768649359185"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already get a nearly perfect accuracy for files, which is very impressive with only 64 units. This probably means that the function to approximate / the problem is not really complex, but still non-linear.    \n",
    "Let's try to improve the accuracy by increasing the number of units in the dense layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_for_classifier\n",
      "Finished loading/creating features\n",
      "Using classifier SNNClassifier - units 128\n",
      "Training SNNClassifier - units 128\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 128)               2688      \n",
      "_________________________________________________________________\n",
      "p_re_lu_2 (PReLU)            (None, 128)               128       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 129       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 2,945\n",
      "Trainable params: 2,945\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 81080 samples, validate on 20270 samples\n",
      "Epoch 1/300\n",
      "81080/81080 [==============================] - 1s 10us/step - loss: 0.6150 - acc: 0.6531 - val_loss: 0.6117 - val_acc: 0.6460\n",
      "Epoch 2/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.5595 - acc: 0.6923 - val_loss: 0.5691 - val_acc: 0.6801\n",
      "Epoch 3/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.5279 - acc: 0.7159 - val_loss: 0.5498 - val_acc: 0.6915\n",
      "Epoch 4/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.5039 - acc: 0.7331 - val_loss: 0.5405 - val_acc: 0.6937\n",
      "Epoch 5/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4898 - acc: 0.7410 - val_loss: 0.5264 - val_acc: 0.7138\n",
      "Epoch 6/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4808 - acc: 0.7468 - val_loss: 0.5254 - val_acc: 0.7124\n",
      "Epoch 7/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.4744 - acc: 0.7503 - val_loss: 0.5228 - val_acc: 0.7117\n",
      "Epoch 8/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.4693 - acc: 0.7543 - val_loss: 0.5100 - val_acc: 0.7346\n",
      "Epoch 9/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4643 - acc: 0.7581 - val_loss: 0.5091 - val_acc: 0.7305\n",
      "Epoch 10/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4605 - acc: 0.7604 - val_loss: 0.5004 - val_acc: 0.7449\n",
      "Epoch 11/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4579 - acc: 0.7616 - val_loss: 0.5074 - val_acc: 0.7373\n",
      "Epoch 12/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4546 - acc: 0.7640 - val_loss: 0.5074 - val_acc: 0.7281\n",
      "Epoch 13/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4504 - acc: 0.7675 - val_loss: 0.4998 - val_acc: 0.7403\n",
      "Epoch 14/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4487 - acc: 0.7686 - val_loss: 0.4945 - val_acc: 0.7491\n",
      "Epoch 15/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.4466 - acc: 0.7710 - val_loss: 0.5027 - val_acc: 0.7354\n",
      "Epoch 16/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.4441 - acc: 0.7723 - val_loss: 0.4917 - val_acc: 0.7479\n",
      "Epoch 17/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.4410 - acc: 0.7738 - val_loss: 0.4851 - val_acc: 0.7511\n",
      "Epoch 18/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.4396 - acc: 0.7755 - val_loss: 0.4931 - val_acc: 0.7446\n",
      "Epoch 19/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4372 - acc: 0.7766 - val_loss: 0.4819 - val_acc: 0.7510\n",
      "Epoch 20/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.4360 - acc: 0.7769 - val_loss: 0.4789 - val_acc: 0.7533\n",
      "Epoch 21/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.4337 - acc: 0.7784 - val_loss: 0.4909 - val_acc: 0.7443\n",
      "Epoch 22/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.4325 - acc: 0.7801 - val_loss: 0.4896 - val_acc: 0.7419\n",
      "Epoch 23/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.4308 - acc: 0.7814 - val_loss: 0.4814 - val_acc: 0.7576\n",
      "Epoch 24/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.4296 - acc: 0.7809 - val_loss: 0.4821 - val_acc: 0.7453\n",
      "Epoch 25/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.4275 - acc: 0.7834 - val_loss: 0.4830 - val_acc: 0.7445\n",
      "Epoch 26/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.4266 - acc: 0.7838 - val_loss: 0.4852 - val_acc: 0.7441\n",
      "Epoch 27/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.4238 - acc: 0.7872 - val_loss: 0.4866 - val_acc: 0.7394\n",
      "Epoch 28/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.4233 - acc: 0.7860 - val_loss: 0.4735 - val_acc: 0.7566\n",
      "Epoch 29/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.4223 - acc: 0.7855 - val_loss: 0.4664 - val_acc: 0.7670\n",
      "Epoch 30/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.4213 - acc: 0.7870 - val_loss: 0.4680 - val_acc: 0.7574\n",
      "Epoch 31/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.4188 - acc: 0.7881 - val_loss: 0.4694 - val_acc: 0.7570\n",
      "Epoch 32/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.4186 - acc: 0.7897 - val_loss: 0.4750 - val_acc: 0.7508\n",
      "Epoch 33/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.4179 - acc: 0.7882 - val_loss: 0.4660 - val_acc: 0.7663\n",
      "Epoch 34/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.4166 - acc: 0.7887 - val_loss: 0.4701 - val_acc: 0.7603\n",
      "Epoch 35/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.4145 - acc: 0.7915 - val_loss: 0.4758 - val_acc: 0.7500\n",
      "Epoch 36/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.4144 - acc: 0.7909 - val_loss: 0.4635 - val_acc: 0.7630\n",
      "Epoch 37/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.4130 - acc: 0.7922 - val_loss: 0.4671 - val_acc: 0.7607\n",
      "Epoch 38/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.4118 - acc: 0.7938 - val_loss: 0.4651 - val_acc: 0.7599\n",
      "Epoch 39/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.4107 - acc: 0.7943 - val_loss: 0.4628 - val_acc: 0.7627\n",
      "Epoch 40/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.4111 - acc: 0.7923 - val_loss: 0.4683 - val_acc: 0.7555\n",
      "Epoch 41/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.4092 - acc: 0.7949 - val_loss: 0.4554 - val_acc: 0.7691\n",
      "Epoch 42/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.4089 - acc: 0.7951 - val_loss: 0.4656 - val_acc: 0.7642\n",
      "Epoch 43/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.4079 - acc: 0.7961 - val_loss: 0.4564 - val_acc: 0.7711\n",
      "Epoch 44/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.4064 - acc: 0.7964 - val_loss: 0.4666 - val_acc: 0.7543\n",
      "Epoch 45/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.4056 - acc: 0.7969 - val_loss: 0.4648 - val_acc: 0.7618\n",
      "Epoch 46/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.4046 - acc: 0.7977 - val_loss: 0.4517 - val_acc: 0.7728\n",
      "Epoch 47/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.4049 - acc: 0.7969 - val_loss: 0.4650 - val_acc: 0.7581\n",
      "Epoch 48/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.4034 - acc: 0.7980 - val_loss: 0.4564 - val_acc: 0.7651\n",
      "Epoch 49/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.4030 - acc: 0.7988 - val_loss: 0.4724 - val_acc: 0.7538\n",
      "Epoch 50/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.4027 - acc: 0.7986 - val_loss: 0.4543 - val_acc: 0.7734\n",
      "Epoch 51/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.4010 - acc: 0.8017 - val_loss: 0.4681 - val_acc: 0.7546\n",
      "Epoch 52/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.4005 - acc: 0.8018 - val_loss: 0.4501 - val_acc: 0.7719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4003 - acc: 0.7996 - val_loss: 0.4506 - val_acc: 0.7684\n",
      "Epoch 54/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.4000 - acc: 0.7994 - val_loss: 0.4606 - val_acc: 0.7624\n",
      "Epoch 55/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3995 - acc: 0.8012 - val_loss: 0.4571 - val_acc: 0.7667\n",
      "Epoch 56/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3974 - acc: 0.8023 - val_loss: 0.4561 - val_acc: 0.7699\n",
      "Epoch 57/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3974 - acc: 0.8027 - val_loss: 0.4624 - val_acc: 0.7614\n",
      "Epoch 58/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3965 - acc: 0.8028 - val_loss: 0.4523 - val_acc: 0.7662\n",
      "Epoch 59/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3958 - acc: 0.8034 - val_loss: 0.4552 - val_acc: 0.7709\n",
      "Epoch 60/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3964 - acc: 0.8027 - val_loss: 0.4526 - val_acc: 0.7734\n",
      "Epoch 61/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.3944 - acc: 0.8047 - val_loss: 0.4635 - val_acc: 0.7573\n",
      "Epoch 62/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3944 - acc: 0.8039 - val_loss: 0.4729 - val_acc: 0.7515\n",
      "\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 63/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.3850 - acc: 0.8108 - val_loss: 0.4479 - val_acc: 0.7719\n",
      "Epoch 64/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.3838 - acc: 0.8117 - val_loss: 0.4476 - val_acc: 0.7727\n",
      "Epoch 65/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3834 - acc: 0.8129 - val_loss: 0.4433 - val_acc: 0.7750\n",
      "Epoch 66/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.3834 - acc: 0.8129 - val_loss: 0.4481 - val_acc: 0.7725\n",
      "Epoch 67/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.3832 - acc: 0.8130 - val_loss: 0.4429 - val_acc: 0.7761\n",
      "Epoch 68/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3833 - acc: 0.8124 - val_loss: 0.4444 - val_acc: 0.7753\n",
      "Epoch 69/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.3830 - acc: 0.8129 - val_loss: 0.4473 - val_acc: 0.7720\n",
      "Epoch 70/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3832 - acc: 0.8125 - val_loss: 0.4433 - val_acc: 0.7758\n",
      "Epoch 71/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.3831 - acc: 0.8132 - val_loss: 0.4467 - val_acc: 0.7728\n",
      "Epoch 72/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.3829 - acc: 0.8130 - val_loss: 0.4429 - val_acc: 0.7764\n",
      "Epoch 73/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3828 - acc: 0.8130 - val_loss: 0.4425 - val_acc: 0.7787\n",
      "Epoch 74/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3827 - acc: 0.8131 - val_loss: 0.4466 - val_acc: 0.7740\n",
      "Epoch 75/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3826 - acc: 0.8139 - val_loss: 0.4451 - val_acc: 0.7759\n",
      "Epoch 76/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3824 - acc: 0.8137 - val_loss: 0.4474 - val_acc: 0.7716\n",
      "Epoch 77/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3823 - acc: 0.8132 - val_loss: 0.4472 - val_acc: 0.7735\n",
      "Epoch 78/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3821 - acc: 0.8134 - val_loss: 0.4476 - val_acc: 0.7739\n",
      "Epoch 79/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3823 - acc: 0.8133 - val_loss: 0.4477 - val_acc: 0.7728\n",
      "Epoch 80/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3820 - acc: 0.8133 - val_loss: 0.4456 - val_acc: 0.7754\n",
      "Epoch 81/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.3819 - acc: 0.8142 - val_loss: 0.4441 - val_acc: 0.7756\n",
      "Epoch 82/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3817 - acc: 0.8135 - val_loss: 0.4427 - val_acc: 0.7758\n",
      "Epoch 83/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3819 - acc: 0.8136 - val_loss: 0.4428 - val_acc: 0.7765\n",
      "\n",
      "Epoch 00083: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 84/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3806 - acc: 0.8149 - val_loss: 0.4434 - val_acc: 0.7759\n",
      "Epoch 85/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3805 - acc: 0.8153 - val_loss: 0.4434 - val_acc: 0.7761\n",
      "Epoch 86/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3804 - acc: 0.8151 - val_loss: 0.4424 - val_acc: 0.7763\n",
      "Epoch 87/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3804 - acc: 0.8153 - val_loss: 0.4437 - val_acc: 0.7763\n",
      "Epoch 88/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3804 - acc: 0.8151 - val_loss: 0.4442 - val_acc: 0.7763\n",
      "Epoch 00088: early stopping\n",
      "Saved SNNClassifier - units 128\n",
      "ModePath:models/SNNClassifier - units 128.pkl\n",
      "Predicting on files...\n",
      "Predicting on samples...\n",
      "Test accuracy - files : 0.9646643109540636\n",
      "Test accuracy - samples : 0.7918952468666159\n"
     ]
    }
   ],
   "source": [
    "test_classifier(SNNClassifier(num_units=128, verbose=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the sample accuracy is ~1% better, and the file accuracy is now perfect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading/creating features\n",
      "Using classifier SNNClassifier - units 256\n",
      "Training SNNClassifier - units 256\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 256)               5376      \n",
      "_________________________________________________________________\n",
      "p_re_lu_3 (PReLU)            (None, 256)               256       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 5,889\n",
      "Trainable params: 5,889\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 384480 samples, validate on 96121 samples\n",
      "Epoch 1/300\n",
      "384480/384480 [==============================] - 4s 9us/step - loss: 0.5089 - acc: 0.7378 - val_loss: 0.4492 - val_acc: 0.7834\n",
      "Epoch 2/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.4241 - acc: 0.7948 - val_loss: 0.4121 - val_acc: 0.8089\n",
      "Epoch 3/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.3963 - acc: 0.8125 - val_loss: 0.3936 - val_acc: 0.8153\n",
      "Epoch 4/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.3800 - acc: 0.8220 - val_loss: 0.3745 - val_acc: 0.8294\n",
      "Epoch 5/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.3691 - acc: 0.8278 - val_loss: 0.3681 - val_acc: 0.8321\n",
      "Epoch 6/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.3607 - acc: 0.8322 - val_loss: 0.3605 - val_acc: 0.8381\n",
      "Epoch 7/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.3546 - acc: 0.8350 - val_loss: 0.3504 - val_acc: 0.8434\n",
      "Epoch 8/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.3490 - acc: 0.8383 - val_loss: 0.3573 - val_acc: 0.8357\n",
      "Epoch 9/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.3440 - acc: 0.8413 - val_loss: 0.3546 - val_acc: 0.8352\n",
      "Epoch 10/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.3404 - acc: 0.8433 - val_loss: 0.3384 - val_acc: 0.8497\n",
      "Epoch 11/300\n",
      "384480/384480 [==============================] - 4s 9us/step - loss: 0.3363 - acc: 0.8452 - val_loss: 0.3525 - val_acc: 0.8353\n",
      "Epoch 12/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.3327 - acc: 0.8476 - val_loss: 0.3438 - val_acc: 0.8412\n",
      "Epoch 13/300\n",
      "384480/384480 [==============================] - 4s 9us/step - loss: 0.3291 - acc: 0.8495 - val_loss: 0.3361 - val_acc: 0.8519\n",
      "Epoch 14/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.3265 - acc: 0.8507 - val_loss: 0.3259 - val_acc: 0.8570\n",
      "Epoch 15/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.3238 - acc: 0.8521 - val_loss: 0.3306 - val_acc: 0.8522\n",
      "Epoch 16/300\n",
      "384480/384480 [==============================] - 4s 9us/step - loss: 0.3214 - acc: 0.8536 - val_loss: 0.3241 - val_acc: 0.8559\n",
      "Epoch 17/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.3179 - acc: 0.8560 - val_loss: 0.3402 - val_acc: 0.8437\n",
      "Epoch 18/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.3159 - acc: 0.8562 - val_loss: 0.3276 - val_acc: 0.8518\n",
      "Epoch 19/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.3145 - acc: 0.8569 - val_loss: 0.3228 - val_acc: 0.8563\n",
      "Epoch 20/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.3118 - acc: 0.8584 - val_loss: 0.3191 - val_acc: 0.8609\n",
      "Epoch 21/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.3096 - acc: 0.8600 - val_loss: 0.3318 - val_acc: 0.8493\n",
      "Epoch 22/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.3076 - acc: 0.8612 - val_loss: 0.3407 - val_acc: 0.8447\n",
      "Epoch 23/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.3066 - acc: 0.8620 - val_loss: 0.3156 - val_acc: 0.8607\n",
      "Epoch 24/300\n",
      "384480/384480 [==============================] - 4s 9us/step - loss: 0.3045 - acc: 0.8631 - val_loss: 0.3229 - val_acc: 0.8571\n",
      "Epoch 25/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.3030 - acc: 0.8635 - val_loss: 0.3206 - val_acc: 0.8557\n",
      "Epoch 26/300\n",
      "384480/384480 [==============================] - 4s 9us/step - loss: 0.3006 - acc: 0.8648 - val_loss: 0.3161 - val_acc: 0.8609\n",
      "Epoch 27/300\n",
      "384480/384480 [==============================] - 4s 9us/step - loss: 0.2996 - acc: 0.8655 - val_loss: 0.3072 - val_acc: 0.8661\n",
      "Epoch 28/300\n",
      "384480/384480 [==============================] - 4s 9us/step - loss: 0.2981 - acc: 0.8664 - val_loss: 0.3069 - val_acc: 0.8659\n",
      "Epoch 29/300\n",
      "384480/384480 [==============================] - 4s 9us/step - loss: 0.2971 - acc: 0.8668 - val_loss: 0.3122 - val_acc: 0.8609\n",
      "Epoch 30/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2960 - acc: 0.8677 - val_loss: 0.3165 - val_acc: 0.8589\n",
      "Epoch 31/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2943 - acc: 0.8685 - val_loss: 0.3143 - val_acc: 0.8637\n",
      "Epoch 32/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2931 - acc: 0.8690 - val_loss: 0.3033 - val_acc: 0.8674\n",
      "Epoch 33/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2928 - acc: 0.8693 - val_loss: 0.3039 - val_acc: 0.8661\n",
      "Epoch 34/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2914 - acc: 0.8705 - val_loss: 0.3208 - val_acc: 0.8567\n",
      "Epoch 35/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2904 - acc: 0.8708 - val_loss: 0.3172 - val_acc: 0.8578\n",
      "Epoch 36/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2895 - acc: 0.8709 - val_loss: 0.2991 - val_acc: 0.8710\n",
      "Epoch 37/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2881 - acc: 0.8716 - val_loss: 0.3132 - val_acc: 0.8587\n",
      "Epoch 38/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2872 - acc: 0.8725 - val_loss: 0.3115 - val_acc: 0.8648\n",
      "Epoch 39/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2863 - acc: 0.8731 - val_loss: 0.3058 - val_acc: 0.8673\n",
      "Epoch 40/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2855 - acc: 0.8736 - val_loss: 0.3120 - val_acc: 0.8634\n",
      "Epoch 41/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2857 - acc: 0.8734 - val_loss: 0.3017 - val_acc: 0.8701\n",
      "Epoch 42/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2840 - acc: 0.8744 - val_loss: 0.2996 - val_acc: 0.8712\n",
      "Epoch 43/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2840 - acc: 0.8741 - val_loss: 0.3089 - val_acc: 0.8662\n",
      "Epoch 44/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2833 - acc: 0.8741 - val_loss: 0.3013 - val_acc: 0.8709\n",
      "Epoch 45/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2822 - acc: 0.8753 - val_loss: 0.2973 - val_acc: 0.8704\n",
      "Epoch 46/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2820 - acc: 0.8750 - val_loss: 0.2997 - val_acc: 0.8693\n",
      "Epoch 47/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2807 - acc: 0.8764 - val_loss: 0.3017 - val_acc: 0.8672\n",
      "Epoch 48/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2800 - acc: 0.8759 - val_loss: 0.3053 - val_acc: 0.8677\n",
      "Epoch 49/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2798 - acc: 0.8770 - val_loss: 0.3083 - val_acc: 0.8653\n",
      "Epoch 50/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2793 - acc: 0.8768 - val_loss: 0.2982 - val_acc: 0.8710\n",
      "Epoch 51/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2781 - acc: 0.8773 - val_loss: 0.3010 - val_acc: 0.8699\n",
      "Epoch 52/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2786 - acc: 0.8767 - val_loss: 0.2995 - val_acc: 0.8697\n",
      "Epoch 53/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2776 - acc: 0.8776 - val_loss: 0.2982 - val_acc: 0.8711\n",
      "Epoch 54/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2770 - acc: 0.8777 - val_loss: 0.3073 - val_acc: 0.8637\n",
      "Epoch 55/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2764 - acc: 0.8782 - val_loss: 0.3042 - val_acc: 0.8671\n",
      "\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 56/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2598 - acc: 0.8881 - val_loss: 0.2847 - val_acc: 0.8787\n",
      "Epoch 57/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2592 - acc: 0.8883 - val_loss: 0.2837 - val_acc: 0.8808\n",
      "Epoch 58/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2591 - acc: 0.8883 - val_loss: 0.2852 - val_acc: 0.8800\n",
      "Epoch 59/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2589 - acc: 0.8884 - val_loss: 0.2840 - val_acc: 0.8806\n",
      "Epoch 60/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2587 - acc: 0.8886 - val_loss: 0.2838 - val_acc: 0.8800\n",
      "Epoch 61/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2585 - acc: 0.8885 - val_loss: 0.2854 - val_acc: 0.8795\n",
      "Epoch 62/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2584 - acc: 0.8888 - val_loss: 0.2844 - val_acc: 0.8790\n",
      "Epoch 63/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2582 - acc: 0.8887 - val_loss: 0.2838 - val_acc: 0.8803\n",
      "Epoch 64/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2580 - acc: 0.8890 - val_loss: 0.2828 - val_acc: 0.8804\n",
      "Epoch 65/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2578 - acc: 0.8893 - val_loss: 0.2826 - val_acc: 0.8808\n",
      "Epoch 66/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2577 - acc: 0.8891 - val_loss: 0.2817 - val_acc: 0.8818\n",
      "Epoch 67/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2575 - acc: 0.8891 - val_loss: 0.2839 - val_acc: 0.8795\n",
      "Epoch 68/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2574 - acc: 0.8892 - val_loss: 0.2834 - val_acc: 0.8800\n",
      "Epoch 69/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2573 - acc: 0.8892 - val_loss: 0.2841 - val_acc: 0.8796\n",
      "Epoch 70/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2573 - acc: 0.8891 - val_loss: 0.2836 - val_acc: 0.8802\n",
      "Epoch 71/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2571 - acc: 0.8895 - val_loss: 0.2817 - val_acc: 0.8804\n",
      "Epoch 72/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2570 - acc: 0.8895 - val_loss: 0.2844 - val_acc: 0.8787\n",
      "Epoch 73/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2569 - acc: 0.8892 - val_loss: 0.2819 - val_acc: 0.8807\n",
      "Epoch 74/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2566 - acc: 0.8897 - val_loss: 0.2810 - val_acc: 0.8821\n",
      "Epoch 75/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2566 - acc: 0.8895 - val_loss: 0.2833 - val_acc: 0.8803\n",
      "Epoch 76/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2565 - acc: 0.8898 - val_loss: 0.2819 - val_acc: 0.8813\n",
      "Epoch 77/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2563 - acc: 0.8900 - val_loss: 0.2817 - val_acc: 0.8816\n",
      "Epoch 78/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2562 - acc: 0.8898 - val_loss: 0.2816 - val_acc: 0.8816\n",
      "Epoch 79/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2562 - acc: 0.8899 - val_loss: 0.2830 - val_acc: 0.8809\n",
      "Epoch 80/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2560 - acc: 0.8896 - val_loss: 0.2831 - val_acc: 0.8808\n",
      "Epoch 81/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2559 - acc: 0.8900 - val_loss: 0.2831 - val_acc: 0.8801\n",
      "Epoch 82/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2558 - acc: 0.8899 - val_loss: 0.2810 - val_acc: 0.8825\n",
      "Epoch 83/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2557 - acc: 0.8902 - val_loss: 0.2819 - val_acc: 0.8811\n",
      "Epoch 84/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2555 - acc: 0.8901 - val_loss: 0.2827 - val_acc: 0.8813\n",
      "\n",
      "Epoch 00084: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 85/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2537 - acc: 0.8912 - val_loss: 0.2806 - val_acc: 0.8822\n",
      "Epoch 86/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2535 - acc: 0.8912 - val_loss: 0.2809 - val_acc: 0.8817\n",
      "Epoch 87/300\n",
      "384480/384480 [==============================] - 4s 9us/step - loss: 0.2534 - acc: 0.8914 - val_loss: 0.2809 - val_acc: 0.8818\n",
      "Epoch 88/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2534 - acc: 0.8913 - val_loss: 0.2802 - val_acc: 0.8826\n",
      "Epoch 89/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2534 - acc: 0.8914 - val_loss: 0.2806 - val_acc: 0.8818\n",
      "Epoch 90/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2534 - acc: 0.8914 - val_loss: 0.2807 - val_acc: 0.8819\n",
      "Epoch 91/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2534 - acc: 0.8915 - val_loss: 0.2807 - val_acc: 0.8817\n",
      "Epoch 92/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2534 - acc: 0.8914 - val_loss: 0.2803 - val_acc: 0.8824\n",
      "Epoch 93/300\n",
      "384480/384480 [==============================] - 4s 9us/step - loss: 0.2534 - acc: 0.8914 - val_loss: 0.2808 - val_acc: 0.8815\n",
      "Epoch 94/300\n",
      "384480/384480 [==============================] - 4s 9us/step - loss: 0.2533 - acc: 0.8914 - val_loss: 0.2804 - val_acc: 0.8819\n",
      "Epoch 95/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2533 - acc: 0.8914 - val_loss: 0.2806 - val_acc: 0.8820\n",
      "Epoch 96/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2533 - acc: 0.8914 - val_loss: 0.2807 - val_acc: 0.8820\n",
      "Epoch 97/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2533 - acc: 0.8914 - val_loss: 0.2808 - val_acc: 0.8816\n",
      "Epoch 98/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2533 - acc: 0.8915 - val_loss: 0.2804 - val_acc: 0.8822\n",
      "\n",
      "Epoch 00098: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 99/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2531 - acc: 0.8916 - val_loss: 0.2804 - val_acc: 0.8821\n",
      "Epoch 100/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2530 - acc: 0.8916 - val_loss: 0.2804 - val_acc: 0.8820\n",
      "Epoch 101/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2530 - acc: 0.8916 - val_loss: 0.2804 - val_acc: 0.8820\n",
      "Epoch 102/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2530 - acc: 0.8916 - val_loss: 0.2804 - val_acc: 0.8820\n",
      "Epoch 103/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2530 - acc: 0.8917 - val_loss: 0.2804 - val_acc: 0.8821\n",
      "Epoch 00103: early stopping\n",
      "Saved SNNClassifier - units 256\n",
      "Predicting on files...\n",
      "Predicting on samples...\n",
      "Test accuracy - files : 1.0\n",
      "Test accuracy - samples : 0.8861442697868652\n"
     ]
    }
   ],
   "source": [
    "test_classifier(SNNClassifier(num_units=256, verbose=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We gain a very marginal increase in sample accuracy. File accuracy is still perfect. Increasing the model complexity further shouldn't yield any worthy increase in accuracy, as this model (and even the one with 128 units) is complex enough to accurately class the audio files.\n",
    "\n",
    "I decided to not add any Dropout or regularization to the network because, as we can see in the results, there is little to no overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neural Network\n",
    "The CNN Classifier was more difficult to implement.    \n",
    "First, the input is different compared to the other classifiers. We need to give identical 2D inputs to the network, but the number of samples per file varies a lot.    \n",
    "- The first attempt was padding the smaller files to the size of the biggest one by adding 0s features. Due to the difference in size, the network couldn't learn anything, as most of the data was empty (smallest file has 46 samples, biggest has around 1200).   \n",
    "- The next attempt was cutting the files into smaller windows of 46 samples (and potentially padding the last sample of the file). The next cell is the (reduced) output of a run using this strategy.    \n",
    "- The current one is to cut the files into windows of 10 samples. We'll see the result later.\n",
    "\n",
    "As the purpose of this classifier is to be a deep neural network, I decided to put two convolutional layers along with two max pooling, followed by two denses layers and an output layer. The whole network can be seen in the following cell.    \n",
    "Due to the number of parameters for this network (parameters in each layer, layout of the network, etc), most of these are heuristically chosen from a previous project on road segmentation. \n",
    "\n",
    "About design decisions :    \n",
    "- Batch normalization is used for faster and better training\n",
    "- Prelu activation is used instead of relu for potential better results\n",
    "- Glorot Normal initialization is used, but it seems that it is a matter of preference between uniform and normal and has no real impact on performance\n",
    "- Dropouts are used after max pooling and dense layers to reduce overfitting\n",
    "- Kernel regularizers are used on the convolution and dense layers to reduce overfitting\n",
    "- (Both dropouts and regularizers were added after checking that the network could learn perfectly the training set)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Finished loading/creating features\n",
    "Using classifier CNNClassifier\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "batch_normalization_13 (Batc (None, 46, 20, 1)         4         \n",
    "_________________________________________________________________\n",
    "conv2d_9 (Conv2D)            (None, 44, 18, 32)        320       \n",
    "_________________________________________________________________\n",
    "p_re_lu_17 (PReLU)           (None, 44, 18, 32)        25344     \n",
    "_________________________________________________________________\n",
    "batch_normalization_14 (Batc (None, 44, 18, 32)        128       \n",
    "_________________________________________________________________\n",
    "max_pooling2d_9 (MaxPooling2 (None, 43, 17, 32)        0         \n",
    "_________________________________________________________________\n",
    "dropout_17 (Dropout)         (None, 43, 17, 32)        0         \n",
    "_________________________________________________________________\n",
    "conv2d_10 (Conv2D)           (None, 41, 15, 64)        18496     \n",
    "_________________________________________________________________\n",
    "p_re_lu_18 (PReLU)           (None, 41, 15, 64)        39360     \n",
    "_________________________________________________________________\n",
    "batch_normalization_15 (Batc (None, 41, 15, 64)        256       \n",
    "_________________________________________________________________\n",
    "max_pooling2d_10 (MaxPooling (None, 40, 14, 64)        0         \n",
    "_________________________________________________________________\n",
    "dropout_18 (Dropout)         (None, 40, 14, 64)        0         \n",
    "_________________________________________________________________\n",
    "flatten_5 (Flatten)          (None, 35840)             0         \n",
    "_________________________________________________________________\n",
    "dense_13 (Dense)             (None, 512)               18350592  \n",
    "_________________________________________________________________\n",
    "p_re_lu_19 (PReLU)           (None, 512)               512       \n",
    "_________________________________________________________________\n",
    "dropout_19 (Dropout)         (None, 512)               0         \n",
    "_________________________________________________________________\n",
    "dense_14 (Dense)             (None, 256)               131328    \n",
    "_________________________________________________________________\n",
    "p_re_lu_20 (PReLU)           (None, 256)               256       \n",
    "_________________________________________________________________\n",
    "dropout_20 (Dropout)         (None, 256)               0         \n",
    "_________________________________________________________________\n",
    "dense_15 (Dense)             (None, 1)                 257       \n",
    "_________________________________________________________________\n",
    "activation_5 (Activation)    (None, 1)                 0         \n",
    "=================================================================\n",
    "Total params: 18,566,853\n",
    "Trainable params: 18,566,659\n",
    "Non-trainable params: 194\n",
    "_________________________________________________________________\n",
    "None\n",
    "Training CNNClassifier\n",
    "Train on 9183 samples, validate on 2296 samples\n",
    "Epoch 1/200\n",
    "9183/9183 [==============================] - 5s 527us/step - loss: 14.4615 - acc: 0.5050 - val_loss: 10.9467 - val_acc: 0.4808\n",
    "Epoch 2/200\n",
    "9183/9183 [==============================] - 3s 371us/step - loss: 7.1822 - acc: 0.5513 - val_loss: 4.3108 - val_acc: 0.7522\n",
    "...\n",
    "Epoch 17/200\n",
    "9183/9183 [==============================] - 3s 375us/step - loss: 0.7153 - acc: 0.9245 - val_loss: 0.6791 - val_acc: 0.9299\n",
    "...\n",
    "Epoch 50/200\n",
    "9183/9183 [==============================] - 3s 371us/step - loss: 0.3034 - acc: 0.9543 - val_loss: 0.3069 - val_acc: 0.9525\n",
    "...\n",
    "Epoch 92/200\n",
    "9183/9183 [==============================] - 4s 411us/step - loss: 0.1006 - acc: 0.9808 - val_loss: 0.1658 - val_acc: 0.9612\n",
    "...\n",
    "Epoch 153/200\n",
    "9183/9183 [==============================] - 4s 390us/step - loss: 0.0760 - acc: 0.9857 - val_loss: 0.1658 - val_acc: 0.9564\n",
    "Epoch 154/200\n",
    "9183/9183 [==============================] - 3s 381us/step - loss: 0.0759 - acc: 0.9858 - val_loss: 0.1660 - val_acc: 0.9573\n",
    "\n",
    "Epoch 00154: early stopping\n",
    "Saved CNNClassifier\n",
    "Predicting on files...\n",
    "Predicting on samples...\n",
    "Test accuracy - files : 0.9796672828096118\n",
    "Test accuracy - samples : 0.9539430086149768\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the CNN got a really good score for both file and sample accuracy, but it strangely was not perfect like the SNN and is even a bit worse than the random forest. Moreover, the sample accuracy can not really be compared to the one obtained with the previous classifiers, as the CNN has more context (46 times more information than the other classifiers).  \n",
    "The next run obtains a perfect file score by reducing the window size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_for_classifier\n",
      "Finished loading/creating features\n",
      "Using classifier CNNClassifier\n",
      "Training CNNClassifier\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_1 (Batch (None, 10, 20, 1)         4         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 8, 18, 32)         320       \n",
      "_________________________________________________________________\n",
      "p_re_lu_1 (PReLU)            (None, 8, 18, 32)         4608      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 8, 18, 32)         128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 17, 32)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 7, 17, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 5, 15, 64)         18496     \n",
      "_________________________________________________________________\n",
      "p_re_lu_2 (PReLU)            (None, 5, 15, 64)         4800      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 5, 15, 64)         256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 14, 64)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 14, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3584)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1835520   \n",
      "_________________________________________________________________\n",
      "p_re_lu_3 (PReLU)            (None, 512)               512       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "p_re_lu_4 (PReLU)            (None, 256)               256       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,996,485\n",
      "Trainable params: 1,996,291\n",
      "Non-trainable params: 194\n",
      "_________________________________________________________________\n",
      "None\n",
      "getModeCNN\n",
      "Train on 1732 samples, validate on 434 samples\n",
      "Epoch 1/300\n",
      "1732/1732 [==============================] - 2s 1ms/step - loss: 13.4280 - acc: 0.5918 - val_loss: 11.9255 - val_acc: 0.7396\n",
      "Epoch 2/300\n",
      "1732/1732 [==============================] - 1s 861us/step - loss: 11.4984 - acc: 0.6484 - val_loss: 10.1935 - val_acc: 0.7028\n",
      "Epoch 3/300\n",
      "1732/1732 [==============================] - 2s 946us/step - loss: 9.6284 - acc: 0.6836 - val_loss: 8.4712 - val_acc: 0.7811\n",
      "Epoch 4/300\n",
      "1732/1732 [==============================] - 2s 888us/step - loss: 7.9627 - acc: 0.7229 - val_loss: 7.1128 - val_acc: 0.7396\n",
      "Epoch 5/300\n",
      "1732/1732 [==============================] - 2s 880us/step - loss: 6.6189 - acc: 0.7621 - val_loss: 5.9564 - val_acc: 0.7350\n",
      "Epoch 6/300\n",
      "1732/1732 [==============================] - 2s 894us/step - loss: 5.5051 - acc: 0.7708 - val_loss: 4.9879 - val_acc: 0.7765\n",
      "Epoch 7/300\n",
      "1732/1732 [==============================] - 2s 922us/step - loss: 4.6514 - acc: 0.7852 - val_loss: 4.2937 - val_acc: 0.7811\n",
      "Epoch 8/300\n",
      "1732/1732 [==============================] - 2s 987us/step - loss: 3.9699 - acc: 0.7973 - val_loss: 3.6430 - val_acc: 0.7857\n",
      "Epoch 9/300\n",
      "1732/1732 [==============================] - 2s 898us/step - loss: 3.4129 - acc: 0.8002 - val_loss: 3.1634 - val_acc: 0.7926\n",
      "Epoch 10/300\n",
      "1732/1732 [==============================] - 2s 883us/step - loss: 2.9609 - acc: 0.8141 - val_loss: 2.8116 - val_acc: 0.7972\n",
      "Epoch 11/300\n",
      "1732/1732 [==============================] - 2s 882us/step - loss: 2.5876 - acc: 0.8308 - val_loss: 2.4870 - val_acc: 0.7903\n",
      "Epoch 12/300\n",
      "1732/1732 [==============================] - 2s 875us/step - loss: 2.2794 - acc: 0.8360 - val_loss: 2.2384 - val_acc: 0.7880\n",
      "Epoch 13/300\n",
      "1732/1732 [==============================] - 2s 888us/step - loss: 2.0224 - acc: 0.8470 - val_loss: 2.0030 - val_acc: 0.7742\n",
      "Epoch 14/300\n",
      "1732/1732 [==============================] - 2s 898us/step - loss: 1.8397 - acc: 0.8412 - val_loss: 1.8303 - val_acc: 0.8088\n",
      "Epoch 15/300\n",
      "1732/1732 [==============================] - 2s 877us/step - loss: 1.6521 - acc: 0.8505 - val_loss: 1.6497 - val_acc: 0.8157\n",
      "Epoch 16/300\n",
      "1732/1732 [==============================] - 2s 882us/step - loss: 1.5373 - acc: 0.8603 - val_loss: 1.5665 - val_acc: 0.7926\n",
      "Epoch 17/300\n",
      "1732/1732 [==============================] - 2s 883us/step - loss: 1.4263 - acc: 0.8516 - val_loss: 1.5133 - val_acc: 0.7972\n",
      "Epoch 18/300\n",
      "1732/1732 [==============================] - 2s 875us/step - loss: 1.3106 - acc: 0.8684 - val_loss: 1.3707 - val_acc: 0.8318\n",
      "Epoch 19/300\n",
      "1732/1732 [==============================] - 2s 872us/step - loss: 1.2148 - acc: 0.8764 - val_loss: 1.3895 - val_acc: 0.7903\n",
      "Epoch 20/300\n",
      "1732/1732 [==============================] - 2s 888us/step - loss: 1.1411 - acc: 0.8764 - val_loss: 1.2195 - val_acc: 0.8226\n",
      "Epoch 21/300\n",
      "1732/1732 [==============================] - 2s 870us/step - loss: 1.0695 - acc: 0.8811 - val_loss: 1.1930 - val_acc: 0.8203\n",
      "Epoch 22/300\n",
      "1732/1732 [==============================] - 2s 892us/step - loss: 1.0064 - acc: 0.8857 - val_loss: 1.1759 - val_acc: 0.7949\n",
      "Epoch 23/300\n",
      "1732/1732 [==============================] - 2s 895us/step - loss: 0.9689 - acc: 0.8863 - val_loss: 1.0945 - val_acc: 0.8456\n",
      "Epoch 24/300\n",
      "1732/1732 [==============================] - 2s 878us/step - loss: 0.9482 - acc: 0.8770 - val_loss: 1.0986 - val_acc: 0.8111\n",
      "Epoch 25/300\n",
      "1732/1732 [==============================] - 2s 880us/step - loss: 0.8797 - acc: 0.9018 - val_loss: 1.0439 - val_acc: 0.8364\n",
      "Epoch 26/300\n",
      "1732/1732 [==============================] - 2s 900us/step - loss: 0.8341 - acc: 0.9088 - val_loss: 1.0060 - val_acc: 0.8226\n",
      "Epoch 27/300\n",
      "1732/1732 [==============================] - 2s 886us/step - loss: 0.8372 - acc: 0.8984 - val_loss: 0.9408 - val_acc: 0.8318\n",
      "Epoch 28/300\n",
      "1732/1732 [==============================] - 1s 865us/step - loss: 0.7885 - acc: 0.8955 - val_loss: 0.9490 - val_acc: 0.8272\n",
      "Epoch 29/300\n",
      "1732/1732 [==============================] - 2s 874us/step - loss: 0.7424 - acc: 0.9059 - val_loss: 0.9066 - val_acc: 0.8456\n",
      "Epoch 30/300\n",
      "1732/1732 [==============================] - 2s 885us/step - loss: 0.7340 - acc: 0.9007 - val_loss: 0.9239 - val_acc: 0.8226\n",
      "Epoch 31/300\n",
      "1732/1732 [==============================] - 2s 879us/step - loss: 0.7005 - acc: 0.9105 - val_loss: 0.8748 - val_acc: 0.8318\n",
      "Epoch 32/300\n",
      "1732/1732 [==============================] - 2s 875us/step - loss: 0.6782 - acc: 0.9157 - val_loss: 0.9019 - val_acc: 0.8249\n",
      "Epoch 33/300\n",
      "1732/1732 [==============================] - 2s 883us/step - loss: 0.6688 - acc: 0.9099 - val_loss: 0.8657 - val_acc: 0.8387\n",
      "Epoch 34/300\n",
      "1732/1732 [==============================] - 2s 872us/step - loss: 0.6573 - acc: 0.9070 - val_loss: 0.8303 - val_acc: 0.8525\n",
      "Epoch 35/300\n",
      "1732/1732 [==============================] - 2s 868us/step - loss: 0.6181 - acc: 0.9226 - val_loss: 0.9262 - val_acc: 0.8065\n",
      "Epoch 36/300\n",
      "1732/1732 [==============================] - 2s 887us/step - loss: 0.5963 - acc: 0.9249 - val_loss: 0.9185 - val_acc: 0.8226\n",
      "Epoch 37/300\n",
      "1732/1732 [==============================] - 1s 856us/step - loss: 0.5762 - acc: 0.9301 - val_loss: 0.7958 - val_acc: 0.8710\n",
      "Epoch 38/300\n",
      "1732/1732 [==============================] - 1s 850us/step - loss: 0.5805 - acc: 0.9174 - val_loss: 0.7823 - val_acc: 0.8525\n",
      "Epoch 39/300\n",
      "1732/1732 [==============================] - 1s 855us/step - loss: 0.5752 - acc: 0.9267 - val_loss: 0.8573 - val_acc: 0.8203\n",
      "Epoch 40/300\n",
      "1732/1732 [==============================] - 1s 849us/step - loss: 0.5989 - acc: 0.9197 - val_loss: 0.7912 - val_acc: 0.8456\n",
      "Epoch 41/300\n",
      "1732/1732 [==============================] - 1s 854us/step - loss: 0.5786 - acc: 0.9238 - val_loss: 0.8770 - val_acc: 0.8364\n",
      "Epoch 42/300\n",
      "1732/1732 [==============================] - 1s 847us/step - loss: 0.5616 - acc: 0.9192 - val_loss: 0.8154 - val_acc: 0.8295\n",
      "Epoch 43/300\n",
      "1732/1732 [==============================] - 1s 861us/step - loss: 0.5576 - acc: 0.9174 - val_loss: 0.7687 - val_acc: 0.8387\n",
      "Epoch 44/300\n",
      "1732/1732 [==============================] - 1s 858us/step - loss: 0.5408 - acc: 0.9319 - val_loss: 0.7805 - val_acc: 0.8548\n",
      "Epoch 45/300\n",
      "1732/1732 [==============================] - 1s 861us/step - loss: 0.5479 - acc: 0.9249 - val_loss: 0.8001 - val_acc: 0.8318\n",
      "Epoch 46/300\n",
      "1732/1732 [==============================] - 1s 866us/step - loss: 0.5676 - acc: 0.9117 - val_loss: 0.7810 - val_acc: 0.8479\n",
      "Epoch 47/300\n",
      "1732/1732 [==============================] - 1s 862us/step - loss: 0.5355 - acc: 0.9301 - val_loss: 0.7756 - val_acc: 0.8456\n",
      "Epoch 48/300\n",
      "1732/1732 [==============================] - 1s 859us/step - loss: 0.5115 - acc: 0.9353 - val_loss: 0.8141 - val_acc: 0.8525\n",
      "Epoch 49/300\n",
      "1732/1732 [==============================] - 1s 855us/step - loss: 0.5158 - acc: 0.9301 - val_loss: 0.7968 - val_acc: 0.8618\n",
      "Epoch 50/300\n",
      "1732/1732 [==============================] - 2s 877us/step - loss: 0.4869 - acc: 0.9388 - val_loss: 0.7852 - val_acc: 0.8433\n",
      "Epoch 51/300\n",
      "1732/1732 [==============================] - 1s 863us/step - loss: 0.5031 - acc: 0.9336 - val_loss: 0.7488 - val_acc: 0.8641\n",
      "Epoch 52/300\n",
      "1732/1732 [==============================] - 1s 860us/step - loss: 0.5178 - acc: 0.9307 - val_loss: 0.7558 - val_acc: 0.8456\n",
      "Epoch 53/300\n",
      "1732/1732 [==============================] - 1s 866us/step - loss: 0.5045 - acc: 0.9376 - val_loss: 0.7657 - val_acc: 0.8594\n",
      "Epoch 54/300\n",
      "1732/1732 [==============================] - 1s 858us/step - loss: 0.5148 - acc: 0.9307 - val_loss: 0.7748 - val_acc: 0.8364\n",
      "Epoch 55/300\n",
      "1732/1732 [==============================] - 1s 860us/step - loss: 0.5128 - acc: 0.9290 - val_loss: 0.7591 - val_acc: 0.8456\n",
      "Epoch 56/300\n",
      "1732/1732 [==============================] - 1s 863us/step - loss: 0.4973 - acc: 0.9284 - val_loss: 0.7740 - val_acc: 0.8525\n",
      "Epoch 57/300\n",
      "1732/1732 [==============================] - 1s 861us/step - loss: 0.4642 - acc: 0.9405 - val_loss: 0.6938 - val_acc: 0.8641\n",
      "Epoch 58/300\n",
      "1732/1732 [==============================] - 1s 866us/step - loss: 0.4490 - acc: 0.9463 - val_loss: 0.7383 - val_acc: 0.8364\n",
      "Epoch 59/300\n",
      "1732/1732 [==============================] - 2s 876us/step - loss: 0.4665 - acc: 0.9324 - val_loss: 0.7931 - val_acc: 0.8387\n",
      "Epoch 60/300\n",
      "1732/1732 [==============================] - 1s 865us/step - loss: 0.4706 - acc: 0.9388 - val_loss: 0.7811 - val_acc: 0.8433\n",
      "Epoch 61/300\n",
      "1732/1732 [==============================] - 1s 862us/step - loss: 0.4590 - acc: 0.9423 - val_loss: 0.7199 - val_acc: 0.8664\n",
      "Epoch 62/300\n",
      "1732/1732 [==============================] - 2s 877us/step - loss: 0.4474 - acc: 0.9555 - val_loss: 0.7518 - val_acc: 0.8479\n",
      "Epoch 63/300\n",
      "1732/1732 [==============================] - 2s 871us/step - loss: 0.4623 - acc: 0.9348 - val_loss: 0.7012 - val_acc: 0.8364\n",
      "Epoch 64/300\n",
      "1732/1732 [==============================] - 2s 872us/step - loss: 0.4289 - acc: 0.9492 - val_loss: 0.7065 - val_acc: 0.8664\n",
      "Epoch 65/300\n",
      "1732/1732 [==============================] - 2s 883us/step - loss: 0.4198 - acc: 0.9538 - val_loss: 0.7586 - val_acc: 0.8387\n",
      "Epoch 66/300\n",
      "1732/1732 [==============================] - 2s 906us/step - loss: 0.4087 - acc: 0.9532 - val_loss: 0.7731 - val_acc: 0.8410\n",
      "Epoch 67/300\n",
      "1732/1732 [==============================] - 2s 925us/step - loss: 0.4301 - acc: 0.9400 - val_loss: 0.7217 - val_acc: 0.8364\n",
      "\n",
      "Epoch 00067: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 68/300\n",
      "1732/1732 [==============================] - 2s 887us/step - loss: 0.4211 - acc: 0.9475 - val_loss: 0.7106 - val_acc: 0.8456\n",
      "Epoch 69/300\n",
      "1732/1732 [==============================] - 2s 909us/step - loss: 0.3961 - acc: 0.9561 - val_loss: 0.6947 - val_acc: 0.8641\n",
      "Epoch 70/300\n",
      "1732/1732 [==============================] - 2s 892us/step - loss: 0.3861 - acc: 0.9711 - val_loss: 0.6790 - val_acc: 0.8502\n",
      "Epoch 71/300\n",
      "1732/1732 [==============================] - 2s 880us/step - loss: 0.3619 - acc: 0.9752 - val_loss: 0.6829 - val_acc: 0.8664\n",
      "Epoch 72/300\n",
      "1732/1732 [==============================] - 2s 885us/step - loss: 0.3617 - acc: 0.9665 - val_loss: 0.6950 - val_acc: 0.8733\n",
      "Epoch 73/300\n",
      "1732/1732 [==============================] - 2s 894us/step - loss: 0.3487 - acc: 0.9729 - val_loss: 0.6671 - val_acc: 0.8710\n",
      "Epoch 74/300\n",
      "1732/1732 [==============================] - 2s 886us/step - loss: 0.3335 - acc: 0.9792 - val_loss: 0.6848 - val_acc: 0.8687\n",
      "Epoch 75/300\n",
      "1732/1732 [==============================] - 2s 886us/step - loss: 0.3337 - acc: 0.9746 - val_loss: 0.6843 - val_acc: 0.8664\n",
      "Epoch 76/300\n",
      "1732/1732 [==============================] - 2s 871us/step - loss: 0.3295 - acc: 0.9746 - val_loss: 0.6758 - val_acc: 0.8710\n",
      "Epoch 77/300\n",
      "1732/1732 [==============================] - 2s 888us/step - loss: 0.3283 - acc: 0.9746 - val_loss: 0.6647 - val_acc: 0.8618\n",
      "Epoch 78/300\n",
      "1732/1732 [==============================] - 2s 884us/step - loss: 0.3171 - acc: 0.9758 - val_loss: 0.6848 - val_acc: 0.8710\n",
      "Epoch 79/300\n",
      "1732/1732 [==============================] - 2s 883us/step - loss: 0.3202 - acc: 0.9746 - val_loss: 0.6448 - val_acc: 0.8733\n",
      "Epoch 80/300\n",
      "1732/1732 [==============================] - 2s 880us/step - loss: 0.3111 - acc: 0.9746 - val_loss: 0.6664 - val_acc: 0.8733\n",
      "Epoch 81/300\n",
      "1732/1732 [==============================] - 2s 880us/step - loss: 0.3008 - acc: 0.9792 - val_loss: 0.6475 - val_acc: 0.8664\n",
      "Epoch 82/300\n",
      "1732/1732 [==============================] - 2s 886us/step - loss: 0.2996 - acc: 0.9734 - val_loss: 0.6351 - val_acc: 0.8594\n",
      "Epoch 83/300\n",
      "1732/1732 [==============================] - 2s 889us/step - loss: 0.2936 - acc: 0.9809 - val_loss: 0.6338 - val_acc: 0.8641\n",
      "Epoch 84/300\n",
      "1732/1732 [==============================] - 2s 886us/step - loss: 0.2872 - acc: 0.9815 - val_loss: 0.6495 - val_acc: 0.8664\n",
      "Epoch 85/300\n",
      "1732/1732 [==============================] - 2s 896us/step - loss: 0.2932 - acc: 0.9740 - val_loss: 0.6494 - val_acc: 0.8710\n",
      "Epoch 86/300\n",
      "1732/1732 [==============================] - 2s 965us/step - loss: 0.2812 - acc: 0.9809 - val_loss: 0.6561 - val_acc: 0.8733\n",
      "Epoch 87/300\n",
      "1732/1732 [==============================] - 2s 908us/step - loss: 0.2805 - acc: 0.9775 - val_loss: 0.6553 - val_acc: 0.8733\n",
      "Epoch 88/300\n",
      "1732/1732 [==============================] - 2s 936us/step - loss: 0.2800 - acc: 0.9740 - val_loss: 0.6490 - val_acc: 0.8733\n",
      "Epoch 89/300\n",
      "1732/1732 [==============================] - 2s 947us/step - loss: 0.2721 - acc: 0.9786 - val_loss: 0.6203 - val_acc: 0.8664\n",
      "Epoch 90/300\n",
      "1732/1732 [==============================] - 2s 907us/step - loss: 0.2703 - acc: 0.9769 - val_loss: 0.6184 - val_acc: 0.8641\n",
      "Epoch 91/300\n",
      "1732/1732 [==============================] - 2s 939us/step - loss: 0.2642 - acc: 0.9792 - val_loss: 0.6636 - val_acc: 0.8664\n",
      "Epoch 92/300\n",
      "1732/1732 [==============================] - 2s 913us/step - loss: 0.2634 - acc: 0.9769 - val_loss: 0.6280 - val_acc: 0.8594\n",
      "Epoch 93/300\n",
      "1732/1732 [==============================] - 2s 907us/step - loss: 0.2605 - acc: 0.9752 - val_loss: 0.6192 - val_acc: 0.8664\n",
      "Epoch 94/300\n",
      "1732/1732 [==============================] - 2s 913us/step - loss: 0.2544 - acc: 0.9781 - val_loss: 0.6290 - val_acc: 0.8664\n",
      "Epoch 95/300\n",
      "1732/1732 [==============================] - 2s 899us/step - loss: 0.2537 - acc: 0.9815 - val_loss: 0.7054 - val_acc: 0.8664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/300\n",
      "1732/1732 [==============================] - 1s 863us/step - loss: 0.2466 - acc: 0.9809 - val_loss: 0.6143 - val_acc: 0.8594\n",
      "Epoch 97/300\n",
      "1732/1732 [==============================] - 2s 877us/step - loss: 0.2445 - acc: 0.9838 - val_loss: 0.6152 - val_acc: 0.8594\n",
      "Epoch 98/300\n",
      "1732/1732 [==============================] - 2s 874us/step - loss: 0.2405 - acc: 0.9838 - val_loss: 0.6162 - val_acc: 0.8664\n",
      "Epoch 99/300\n",
      "1732/1732 [==============================] - 2s 882us/step - loss: 0.2370 - acc: 0.9827 - val_loss: 0.5911 - val_acc: 0.8710\n",
      "Epoch 100/300\n",
      "1732/1732 [==============================] - 2s 870us/step - loss: 0.2340 - acc: 0.9821 - val_loss: 0.5900 - val_acc: 0.8664\n",
      "Epoch 101/300\n",
      "1732/1732 [==============================] - 2s 869us/step - loss: 0.2319 - acc: 0.9833 - val_loss: 0.6128 - val_acc: 0.8618\n",
      "Epoch 102/300\n",
      "1732/1732 [==============================] - 1s 859us/step - loss: 0.2320 - acc: 0.9804 - val_loss: 0.5940 - val_acc: 0.8710\n",
      "Epoch 103/300\n",
      "1732/1732 [==============================] - 2s 882us/step - loss: 0.2273 - acc: 0.9833 - val_loss: 0.6017 - val_acc: 0.8687\n",
      "Epoch 104/300\n",
      "1732/1732 [==============================] - 2s 880us/step - loss: 0.2324 - acc: 0.9786 - val_loss: 0.5892 - val_acc: 0.8664\n",
      "Epoch 105/300\n",
      "1732/1732 [==============================] - 2s 896us/step - loss: 0.2203 - acc: 0.9850 - val_loss: 0.5797 - val_acc: 0.8710\n",
      "Epoch 106/300\n",
      "1732/1732 [==============================] - 2s 887us/step - loss: 0.2181 - acc: 0.9827 - val_loss: 0.5892 - val_acc: 0.8664\n",
      "Epoch 107/300\n",
      "1732/1732 [==============================] - 2s 908us/step - loss: 0.2202 - acc: 0.9804 - val_loss: 0.5889 - val_acc: 0.8502\n",
      "Epoch 108/300\n",
      "1732/1732 [==============================] - 2s 873us/step - loss: 0.2162 - acc: 0.9804 - val_loss: 0.5885 - val_acc: 0.8687\n",
      "Epoch 109/300\n",
      "1732/1732 [==============================] - 2s 872us/step - loss: 0.2112 - acc: 0.9844 - val_loss: 0.6036 - val_acc: 0.8571\n",
      "Epoch 110/300\n",
      "1732/1732 [==============================] - 2s 886us/step - loss: 0.2104 - acc: 0.9833 - val_loss: 0.5875 - val_acc: 0.8641\n",
      "Epoch 111/300\n",
      "1732/1732 [==============================] - 1s 861us/step - loss: 0.2059 - acc: 0.9856 - val_loss: 0.5755 - val_acc: 0.8756\n",
      "Epoch 112/300\n",
      "1732/1732 [==============================] - 2s 869us/step - loss: 0.2053 - acc: 0.9838 - val_loss: 0.6139 - val_acc: 0.8594\n",
      "Epoch 113/300\n",
      "1732/1732 [==============================] - 2s 867us/step - loss: 0.2050 - acc: 0.9838 - val_loss: 0.5723 - val_acc: 0.8687\n",
      "Epoch 114/300\n",
      "1732/1732 [==============================] - 1s 859us/step - loss: 0.2028 - acc: 0.9804 - val_loss: 0.5576 - val_acc: 0.8802\n",
      "Epoch 115/300\n",
      "1732/1732 [==============================] - 2s 880us/step - loss: 0.2003 - acc: 0.9833 - val_loss: 0.5786 - val_acc: 0.8664\n",
      "Epoch 116/300\n",
      "1732/1732 [==============================] - 1s 865us/step - loss: 0.2021 - acc: 0.9833 - val_loss: 0.5817 - val_acc: 0.8664\n",
      "Epoch 117/300\n",
      "1732/1732 [==============================] - 2s 874us/step - loss: 0.1961 - acc: 0.9844 - val_loss: 0.5615 - val_acc: 0.8687\n",
      "Epoch 118/300\n",
      "1732/1732 [==============================] - 2s 878us/step - loss: 0.1914 - acc: 0.9844 - val_loss: 0.5971 - val_acc: 0.8664\n",
      "Epoch 119/300\n",
      "1732/1732 [==============================] - 2s 869us/step - loss: 0.1948 - acc: 0.9833 - val_loss: 0.5660 - val_acc: 0.8664\n",
      "Epoch 120/300\n",
      "1732/1732 [==============================] - 1s 864us/step - loss: 0.1851 - acc: 0.9861 - val_loss: 0.5870 - val_acc: 0.8594\n",
      "Epoch 121/300\n",
      "1732/1732 [==============================] - 2s 878us/step - loss: 0.1929 - acc: 0.9821 - val_loss: 0.5776 - val_acc: 0.8664\n",
      "Epoch 122/300\n",
      "1732/1732 [==============================] - 2s 871us/step - loss: 0.1875 - acc: 0.9838 - val_loss: 0.5657 - val_acc: 0.8594\n",
      "Epoch 123/300\n",
      "1732/1732 [==============================] - 2s 872us/step - loss: 0.1879 - acc: 0.9838 - val_loss: 0.5657 - val_acc: 0.8641\n",
      "Epoch 124/300\n",
      "1732/1732 [==============================] - 2s 874us/step - loss: 0.1888 - acc: 0.9844 - val_loss: 0.5580 - val_acc: 0.8687\n",
      "\n",
      "Epoch 00124: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 125/300\n",
      "1732/1732 [==============================] - 2s 875us/step - loss: 0.1795 - acc: 0.9856 - val_loss: 0.5653 - val_acc: 0.8756\n",
      "Epoch 126/300\n",
      "1732/1732 [==============================] - 2s 870us/step - loss: 0.1831 - acc: 0.9844 - val_loss: 0.5470 - val_acc: 0.8594\n",
      "Epoch 127/300\n",
      "1732/1732 [==============================] - 2s 872us/step - loss: 0.1865 - acc: 0.9781 - val_loss: 0.5535 - val_acc: 0.8664\n",
      "Epoch 128/300\n",
      "1732/1732 [==============================] - 2s 882us/step - loss: 0.1807 - acc: 0.9856 - val_loss: 0.5535 - val_acc: 0.8618\n",
      "Epoch 129/300\n",
      "1732/1732 [==============================] - 2s 879us/step - loss: 0.1790 - acc: 0.9850 - val_loss: 0.5635 - val_acc: 0.8779\n",
      "Epoch 130/300\n",
      "1732/1732 [==============================] - 2s 879us/step - loss: 0.1808 - acc: 0.9856 - val_loss: 0.5510 - val_acc: 0.8802\n",
      "Epoch 131/300\n",
      "1732/1732 [==============================] - 2s 887us/step - loss: 0.1814 - acc: 0.9861 - val_loss: 0.5588 - val_acc: 0.8618\n",
      "Epoch 132/300\n",
      "1732/1732 [==============================] - 2s 882us/step - loss: 0.1830 - acc: 0.9815 - val_loss: 0.5700 - val_acc: 0.8641\n",
      "Epoch 133/300\n",
      "1732/1732 [==============================] - 2s 879us/step - loss: 0.1815 - acc: 0.9844 - val_loss: 0.5687 - val_acc: 0.8618\n",
      "Epoch 134/300\n",
      "1732/1732 [==============================] - 2s 890us/step - loss: 0.1820 - acc: 0.9867 - val_loss: 0.5700 - val_acc: 0.8641\n",
      "Epoch 135/300\n",
      "1732/1732 [==============================] - 2s 875us/step - loss: 0.1854 - acc: 0.9856 - val_loss: 0.5758 - val_acc: 0.8618\n",
      "Epoch 136/300\n",
      "1732/1732 [==============================] - 2s 891us/step - loss: 0.1771 - acc: 0.9867 - val_loss: 0.5480 - val_acc: 0.8779\n",
      "\n",
      "Epoch 00136: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 137/300\n",
      "1732/1732 [==============================] - 2s 888us/step - loss: 0.1790 - acc: 0.9844 - val_loss: 0.5771 - val_acc: 0.8664\n",
      "Epoch 138/300\n",
      "1732/1732 [==============================] - 2s 890us/step - loss: 0.1792 - acc: 0.9890 - val_loss: 0.5525 - val_acc: 0.8641\n",
      "Epoch 139/300\n",
      "1732/1732 [==============================] - 2s 873us/step - loss: 0.1839 - acc: 0.9827 - val_loss: 0.5558 - val_acc: 0.8733\n",
      "Epoch 140/300\n",
      "1732/1732 [==============================] - 2s 874us/step - loss: 0.1825 - acc: 0.9815 - val_loss: 0.5772 - val_acc: 0.8571\n",
      "Epoch 141/300\n",
      "1732/1732 [==============================] - 2s 891us/step - loss: 0.1806 - acc: 0.9838 - val_loss: 0.5599 - val_acc: 0.8710\n",
      "Epoch 00141: early stopping\n",
      "Saved CNNClassifier\n",
      "ModePath:models/CNNClassifier.pkl\n",
      "Predicting on files...\n",
      "Predicting on samples...\n",
      "Test accuracy - files : 0.9428571428571428\n",
      "Test accuracy - samples : 0.8825688073394495\n"
     ]
    }
   ],
   "source": [
    "test_classifier(CNNClassifier(verbose=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test accuracy - files : 0.9428571428571428\n",
    "Test accuracy - samples : 0.8825688073394495"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test accuracy - files : 0.9513822688274547\n",
    "Test accuracy - samples : 0.8443757725587144"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test accuracy - files : 0.9539473684210527\n",
    "Test accuracy - samples : 0.8594594594594595"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test accuracy - files : 0.9798387096774194\n",
    "Test accuracy - samples : 0.8597168597168597"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test accuracy - files : 0.950530035335689\n",
    "Test accuracy - samples : 0.8377042949448879"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, by using windows of size 10, we get a the same result as the RandomForest for file accuracy (1 mispredicted file), which is better than with a window size of 46. It is probably mainly due to averaging over more samples : As the per sample accuracy is still very high, averaging over them allows for a very good score. In theory, as long as we have a per sample accuracy >50% and a very high number of samples per file, the predictions should be perfect. It is not always the case in practice due to the number of samples per file. \n",
    "\n",
    "\n",
    "100% files accuracy should be obtainable by tuning the parameters or changing the layout.      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to the other classifiers however, it is slower to train, more memory hungry, and therefore seems a bit overkill for this task, given than a simple neural net with a single hidden layer obtains file predictions results better than this one.    \n",
    "\n",
    "### Dumps size\n",
    "If we compare the performance/file size metric of the classifiers, we see that the SNN is easily the best one, the 256 units network weighing only 96Ko, compared to the 12Mo for the 10 estimators RandomForest or the 23Mo CNN. The linear SVC only weighs 1Ko, but gives bad results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other considerations\n",
    "- I've also added a cross-validation method to test the classifiers on samples, but due to the time it takes to execute it, I decided to leave it out.\n",
    "- I have considered data augmentation, but given the results we've already obtained, this isn't at all necessary for this problem and would only be wasted time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "In conclusion, we can rate the classifiers like this : \n",
    "- The winner is obviously the SNN. The complexity of designing it is really low, the file size is also very small, and it gets a perfect result.\n",
    "- The second one would be the RandomForest. The design complexity is non-existant, the file size is moderately high but still very manageable for a low number of trees, and it gets a nearly perfect result.\n",
    "- The third is the CNN. Although the design complexity is high due to the number of parameters we can change and layouts we can do, and the file size is higher than the others, it gets a nearly score. It is totally unnecessary to implement such a complex network for this problem though.\n",
    "- The fourth is the linear SVC, because even though the design complexity and file size is null, the results are bad.\n",
    "- For obvious reasons, the constant classifier is the last one.\n",
    "\n",
    "In short, a more complex model is not always better than a simple one. If the neural network doesn't have to learn complex features, which is the case here as it seems that the MFCC features are expressive enough, a simple model can do a very good job while being faster and less resource-intensive to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = RFClassifier(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/RFClassifier - n_est 100 - max_depth None.pkl\n",
      "Begin to Load model\n"
     ]
    }
   ],
   "source": [
    "pathGender = MODELS_DIR + classifier.get_classifier_name() + DUMP_EXT\n",
    "print(pathGender)\n",
    "if os.path.isfile(pathGender):\n",
    "    print(\"Begin to Load model\")\n",
    "    classifier.load(pathGender)\n",
    "    #model.save_weights(\"gender_cnn_model_weight.h5\")\n",
    "    #json_string = model.to_json()\n",
    "    #open('gender_cnn_model_json.json','w').write(json_string)\n",
    "    #model.save(\"gender_cnn_model.h5\")\n",
    "else:\n",
    "    print(\"Model file not exist.{}\".format(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_for_classifier..\n",
      "Finished loading/creating features\n",
      "Using classifier RFClassifier - n_est 100 - max_depth None\n",
      "Loaded RFClassifier - n_est 100 - max_depth None\n",
      "ModePath:models/RFClassifier - n_est 100 - max_depth None.pkl\n",
      "Predicting on files...\n",
      "Predicting on samples...\n",
      "Test accuracy - files : 0.0\n",
      "Test accuracy - samples : 0.4727272727272727\n"
     ]
    }
   ],
   "source": [
    "test_classifier(RFClassifier(n_estimators=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_for_classifier..\n",
      "Finished loading/creating features\n",
      "Using classifier RFClassifier - n_est 100 - max_depth None\n",
      "Loaded RFClassifier - n_est 100 - max_depth None\n",
      "ModePath:models/RFClassifier - n_est 100 - max_depth None.pkl\n",
      "Predicting on files...\n",
      "Predicting on samples...\n",
      "Test accuracy - files : 1.0\n",
      "Test accuracy - samples : 0.5824175824175825\n"
     ]
    }
   ],
   "source": [
    "test_classifier(RFClassifier(n_estimators=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_for_classifier\n",
      "Finished loading/creating features\n",
      "Using classifier RFClassifier - n_est 100 - max_depth None\n",
      "Loaded RFClassifier - n_est 100 - max_depth None\n",
      "ModePath:models/RFClassifier - n_est 100 - max_depth None.pkl\n",
      "Predicting on files...\n",
      "Predicting on samples...\n",
      "Test accuracy - files : 0.969047619047619\n",
      "Test accuracy - samples : 0.8715568593163971\n"
     ]
    }
   ],
   "source": [
    "test_classifier(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_for_classifier..\n",
      "Finished loading/creating features\n",
      "Using classifier RFClassifier - n_est 100 - max_depth None\n",
      "Loaded RFClassifier - n_est 100 - max_depth None\n",
      "ModePath:models/RFClassifier - n_est 100 - max_depth None.pkl\n",
      "Predicting on files...\n",
      "Predicting on samples...\n",
      "Test accuracy - files : 0.969047619047619\n",
      "Test accuracy - samples : 0.8715568593163971\n"
     ]
    }
   ],
   "source": [
    "test_classifier(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
