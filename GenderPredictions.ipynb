{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/RFClassifier - n_est 100 - max_depth None.pkl\n",
      "Begin to Load model\n"
     ]
    }
   ],
   "source": [
    "from Utils import *\n",
    "from classifier.CNNClassifier import CNNClassifier\n",
    "from classifier.Classifier import Classifier\n",
    "from classifier.ConstantClassifier import ConstantClassifier\n",
    "from classifier.LinearClassifier import LinearClassifier\n",
    "from classifier.RFClassifier import RFClassifier\n",
    "from classifier.SNNClassifier import SNNClassifier\n",
    "from Settings import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from main import run_for_classifier\n",
    "from Predict import *\n",
    "\n",
    "SAVE=True\n",
    "LOAD=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from auditok import ADSFactory, AudioEnergyValidator, StreamTokenizer, player_for, dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertPCM(destPath, srcPath):\n",
    "    #print(srcPath)\n",
    "    outPath = destPath\n",
    "    fout = open(outPath,'wb') #用二进制的写入模式\n",
    "    #fout.write(struct.pack('4s','\\x66\\x6D\\x74\\x20'))\n",
    "    #写入一个长度为4的串，这个串的二进制内容为 66 6D 74 20\n",
    "    #Riff_flag,afd,fad,afdd, = struct.unpack('4c',fin.read(4))\n",
    "    #读入四个字节，每一个都解析成一个字母\n",
    "    #open(sys.argv[4],'wb').write(struct.pack('4s','fmt '))\n",
    "    #将字符串解析成二进制后再写入\n",
    "    #open(sys.argv[4],'wb').write('\\x3C\\x9C\\x00\\x00\\x57')\n",
    "    #直接写入二进制内容：3C 9C 00 00 57\n",
    "    #fout.write(struct.pack('i',6000)) #写入6000的二进制形式\n",
    "    #check whether inFile has head-Info\n",
    "    inPath= srcPath\n",
    "    fin = open(inPath,'rb')\n",
    "    Riff_flag, = struct.unpack('4s',fin.read(4))\n",
    "    if Riff_flag == 'RIFF':\n",
    "        #print(\"%s have head\" % inPath)\n",
    "        fin.close()\n",
    "        #sys.exit(0)\n",
    "    else:\n",
    "        #print(\"%s no head\" % inPath)\n",
    "        fin.close()\n",
    "        #采样率\n",
    "        sampleRate = int(16000)\n",
    "        #bit位\n",
    "        bits = int(16)\n",
    "        fin = open(inPath,'rb')\n",
    "        startPos = fin.tell()\n",
    "        fin.seek(0,os.SEEK_END)\n",
    "        endPos = fin.tell()\n",
    "        sampleNum = int(endPos - startPos)\n",
    "        #print(sampleNum)\n",
    "        #headInfo = geneHeadInfo(sampleRate,bits,sampleNum)\n",
    "        #fout.write(headInfo)\n",
    "        fout.write('\\x52\\x49\\x46\\x46'.encode())\n",
    "        fout.write(struct.pack('i',sampleNum + 36))\n",
    "        #fout.write(fileLength)\n",
    "        fout.write('\\x57\\x41\\x56\\x45\\x66\\x6D\\x74\\x20\\x10\\x00\\x00\\x00\\x01\\x00\\x01\\x00'.encode())\n",
    "        fout.write(struct.pack('i',sampleRate))\n",
    "        fout.write(struct.pack('i',int(sampleRate * bits / 8)))\n",
    "        fout.write('\\x02\\x00'.encode())\n",
    "        fout.write(struct.pack('H',bits))\n",
    "        fout.write('\\x64\\x61\\x74\\x61'.encode())\n",
    "        fout.write(struct.pack('i',sampleNum))\n",
    "        fin.seek(os.SEEK_SET)\n",
    "        fout.write(fin.read())\n",
    "        fin.close()\n",
    "        fout.close()\n",
    "        # We set the `record` argument to True so that we can rewind the source\n",
    "        asource = ADSFactory.ads(filename=destPath, record=True)\n",
    "        validator = AudioEnergyValidator(sample_width=asource.get_sample_width(), energy_threshold=50)\n",
    "        # Default analysis window is 10 ms (float(asource.get_block_size()) / asource.get_sampling_rate())\n",
    "        # min_length=20 : minimum length of a valid audio activity is 20 * 10 == 200 ms\n",
    "        # max_length=400 :  maximum length of a valid audio activity is 400 * 10 == 4000 ms == 4 seconds\n",
    "        # max_continuous_silence=30 : maximum length of a tolerated  silence within a valid audio activity is 30 * 30 == 300 ms\n",
    "        tokenizer = StreamTokenizer(validator=validator, min_length=50, max_length=400, max_continuous_silence=1)\n",
    "        asource.open()\n",
    "        tokens = tokenizer.tokenize(asource)\n",
    "        # Play detected regions back\n",
    "        #player = player_for(asource)\n",
    "        #print(\"\\n ** playing detected regions...\\n\")\n",
    "        data = b''\n",
    "        \n",
    "        for i,t in enumerate(tokens):\n",
    "            #print(\"Token [{0}] starts at {1} and ends at {2}\".format(i+1, t[1], t[2]))\n",
    "            data = data + b''.join(t[0])\n",
    "        #player.play(data)\n",
    "\n",
    "        sampleNum = len(data)\n",
    "        if sampleNum>1000:\n",
    "            #采样率\n",
    "            sampleRate = int(16000)\n",
    "            #bit位\n",
    "            bits = int(16)\n",
    "            fout = open(srcPath+\".wav\",'wb')\n",
    "            fout.write('\\x52\\x49\\x46\\x46'.encode())\n",
    "            fout.write(struct.pack('i',sampleNum + 36))\n",
    "            #fout.write(fileLength)\n",
    "            fout.write('\\x57\\x41\\x56\\x45\\x66\\x6D\\x74\\x20\\x10\\x00\\x00\\x00\\x01\\x00\\x01\\x00'.encode())\n",
    "            fout.write(struct.pack('i',sampleRate))\n",
    "            fout.write(struct.pack('i',int(sampleRate * bits / 8)))\n",
    "            fout.write('\\x02\\x00'.encode())\n",
    "            fout.write(struct.pack('H',bits))\n",
    "            fout.write('\\x64\\x61\\x74\\x61'.encode())\n",
    "            fout.write(struct.pack('i',sampleNum))\n",
    "            fout.write(data)\n",
    "            fout.close()\n",
    "            #assert len(tokens) == 8\n",
    "            asource.close()\n",
    "\n",
    "def read_audio(path, target_fs=None):\n",
    "    #print(path)\n",
    "    if path.upper().endswith(\".PCM\"):\n",
    "        convertPCM(TEMP_WAV, path)\n",
    "        path = path+\".wav\"\n",
    "    (audio, fs) = soundfile.read(path)\n",
    "    if audio.ndim > 1:\n",
    "        audio = np.mean(audio, axis=1)\n",
    "    if target_fs is not None and fs != target_fs:\n",
    "        audio = librosa.resample(audio, orig_sr=fs, target_sr=target_fs)\n",
    "        fs = target_fs\n",
    "    return audio, fs\n",
    "\n",
    "def audio_to_features(filename: str, n_features: int = FEATURES_NUMBER) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Extract MFCC features from audio file using librosa.\n",
    "    :param filename: The name of the file\n",
    "    :param n_features: The number of features to extract\n",
    "    :return: An ndarray of features\n",
    "    \"\"\"\n",
    "    #data, samplerate = librosa.load(filename, sr=None)\n",
    "    fs = cfg.sample_rate\n",
    "    print(filename)\n",
    "    data, samplerate = read_audio(filename, target_fs=fs)\n",
    "    mfcc_features = np.asarray(librosa.feature.mfcc(data, samplerate, n_mfcc=n_features))\n",
    "    global min_shape\n",
    "    if mfcc_features.shape[1] < min_shape:  # Keep track of min_shape for 2D input\n",
    "        min_shape = mfcc_features.shape[1]\n",
    "    return mfcc_features.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = RFClassifier(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_files_to_features(filenames: Iterable[str]) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Extract features and labels from a list of files.\n",
    "    :param filenames: The filenames to use\n",
    "    :return: An array of (features, label) tuples\n",
    "    \"\"\"\n",
    "    if os.path.isfile(FEATURES_WITH_LABEL_FILE):\n",
    "        features_with_label = np.asarray([pre_file_to_features_with_labels(file) for file in filenames])\n",
    "        if not os.path.isfile(MIN_FEATURES_FILE) or not os.path.isfile(MAX_FEATURES_FILE):\n",
    "            flattened_features = flatten(extract_features(features_with_label))\n",
    "            min_f = flattened_features.min(axis=0)\n",
    "            #save_nparray(min_f, MIN_FEATURES_FILE)\n",
    "            max_f = flattened_features.max(axis=0)\n",
    "            #save_nparray(max_f, MAX_FEATURES_FILE)\n",
    "        else:\n",
    "            min_f = load_nparray(MIN_FEATURES_FILE)\n",
    "            max_f = load_nparray(MAX_FEATURES_FILE)\n",
    "\n",
    "        # Normalize the features\n",
    "        features_with_label = np.asarray(list(\n",
    "            map(lambda feat_label_tuple: (\n",
    "                np.asarray(list(map(lambda sample: (sample - min_f) / (max_f - min_f), feat_label_tuple[0]))),\n",
    "                feat_label_tuple[1]),\n",
    "                features_with_label)))\n",
    "\n",
    "    else:\n",
    "        features_with_label = load_nparray(FEATURES_WITH_LABEL_FILE)\n",
    "\n",
    "    return features_with_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_PredictGender(path):\n",
    "    print(\"Begin to load audio & extract features\")\n",
    "    pre_features_with_label = pre_files_to_features(list_files(path))\n",
    "    #pre_set = to_2d(pre_features_with_label)\n",
    "    pre_set = to_1d(pre_features_with_label)\n",
    "    pre_features = extract_features(pre_set)\n",
    "    pre_label = extract_labels(pre_set)\n",
    "    print(\"Begin to predict\")\n",
    "    #results_pre = modelGender.predict(pre_features, batch_size=64, verbose=1)\n",
    "\n",
    "    results_pre = classifier.predict(pre_features)\n",
    "    #print(results_pre)\n",
    "    res = clamp(results_pre)\n",
    "    print(res)\n",
    "    print(\"male:{}\".format(np.sum(res)))\n",
    "    print(\"female:{}\".format(len(res)-np.sum(res)))\n",
    "    return return_majority(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_PredictGender(path):\n",
    "    print(\"Begin to load audio & extract features\")\n",
    "    #print(path)\n",
    "    pre_features_with_label = pre_files_to_features(list_files(path))\n",
    "    #print(pre_features_with_label)\n",
    "    print(\"Begin to predict\")\n",
    "    predictions = []\n",
    "    for feat_label_tuple in pre_features_with_label:\n",
    "        features = feat_label_tuple[0]\n",
    "        results = classifier.predict(features)\n",
    "        print(results)\n",
    "        predictions.append(return_majority(results))\n",
    "    predictions = np.asarray(predictions)\n",
    "    print(predictions)\n",
    "    return predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictGender(path):\n",
    "    try:\n",
    "        value = pre_PredictGender(path)\n",
    "        result = \"Unknown\"\n",
    "        if value == 1:\n",
    "            result = \"Male\"\n",
    "        elif value == 0:\n",
    "            result = \"Female\"\n",
    "        print(result)\n",
    "        return result    \n",
    "    except Exception as e:\n",
    "        print(\"Error occur, Unknown\")\n",
    "        return \"Unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_file_to_features_with_labels(filename: str) -> Any:\n",
    "    \"\"\"\n",
    "    Extract features and label from an audio file.\n",
    "    :param filename: The filename\n",
    "    :return: A tuple (features, label)\n",
    "    \"\"\"\n",
    "    features = audio_to_features(filename)\n",
    "    #print(features)\n",
    "    return features, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(path):\n",
    "    #if path.endswith(AUDIO_EXT) == False and path.endswith(AUDIO_EXT_FLAC) == False and path.endswith(AUDIO_EXT_MP3) == False and path.endswith(AUDIO_EXT_PCM) == False:\n",
    "    if path.endswith(AUDIO_EXT_PCM) == False:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def list_files(dir_name: str, ext=AUDIO_EXT) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    List the files in a directory recursively for a given extension.\n",
    "    :param dir_name: The directory to search\n",
    "    :param ext: The extension of the files to search for\n",
    "    :return: The array of filenames\n",
    "    \"\"\"\n",
    "    return np.asarray(list(map(lambda path: path.replace(\"\\\\\", PATH_SEPARATOR),\n",
    "                               filter(lambda path: f(path),\n",
    "                                      [os.path.join(dp, f) for dp, dn, fn in os.walk(dir_name) for f in fn]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/RFClassifier - n_est 100 - max_depth None.pkl\n",
      "Begin to Load model\n"
     ]
    }
   ],
   "source": [
    "pathGender = MODELS_DIR + classifier.get_classifier_name() + DUMP_EXT\n",
    "print(pathGender)\n",
    "if os.path.isfile(pathGender):\n",
    "    print(\"Begin to Load model\")\n",
    "    classifier.load(pathGender)\n",
    "    #model.save_weights(\"gender_cnn_model_weight.h5\")\n",
    "    #json_string = model.to_json()\n",
    "    #open('gender_cnn_model_json.json','w').write(json_string)\n",
    "    #model.save(\"gender_cnn_model.h5\")\n",
    "else:\n",
    "    print(\"Model file not exist.{}\".format(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = SNNClassifier(num_units=64, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin to load audio & extract features\n",
      "predict_dir/Random_A1/MAHH0/mahao_VrUsbPcm_003_vc.pcm\n",
      "Begin to predict\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "male:64\n",
      "female:0\n",
      "Male\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictGender(\"predict_dir/Random_A1\") == \"Male\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin to load audio & extract features\n",
      "predict_dir/Random_A2/MAHH0/VrUsbPcm_004_vc.pcm\n",
      "Begin to predict\n",
      "[1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 0 0 0 0 1 1 0]\n",
      "male:15\n",
      "female:7\n",
      "Male\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictGender(\"predict_dir/Random_A2\") == \"Male\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin to load audio & extract features\n",
      "predict_dir/Random_A3/MAHH0/VrUsbPcm_005_vc.pcm\n",
      "Begin to predict\n",
      "[1 1 1 1 0 1 1 0 0 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 0 1 0 0 0 0 1 1 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 0 0\n",
      " 0]\n",
      "male:53\n",
      "female:22\n",
      "Male\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictGender(\"predict_dir/Random_A3\") == \"Male\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin to load audio & extract features\n",
      "predict_dir/Random_A4/MAHH0/VrUsbPcm_006_vc.pcm\n",
      "Begin to predict\n",
      "[1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1]\n",
      "male:43\n",
      "female:3\n",
      "Male\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictGender(\"predict_dir/Random_A4\") == \"Male\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin to load audio & extract features\n",
      "predict_dir/Random_A5/MAHH0/lm_UsbPcm_001_vc.pcm\n",
      "Begin to predict\n",
      "[0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      "male:5\n",
      "female:23\n",
      "Female\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictGender(\"predict_dir/Random_A5\") == \"Female\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin to load audio & extract features\n",
      "predict_dir/Random_A6/MAHH0/ll_UsbPcm_013_vc.pcm\n",
      "Error occur, Unknown\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictGender(\"predict_dir/Random_A6\") == \"Female\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin to load audio & extract features\n",
      "predict_dir/Random_A7/7_Female_test.pcm\n",
      "Begin to predict\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "male:18\n",
      "female:0\n",
      "Male\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictGender(\"predict_dir/Random_A7\") == \"Male\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin to load audio & extract features\n",
      "predict_dir/Random_A8/97_Male_test.pcm\n",
      "Begin to predict\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "male:0\n",
      "female:37\n",
      "Female\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictGender(\"predict_dir/Random_A8\") == \"Female\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin to load audio & extract features\n",
      "predict_dir/Random_A8/97_Male_test.pcm\n",
      "Begin to predict\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "male:0\n",
      "female:37\n",
      "Female\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictGender(\"predict_dir/Random_A8\") == \"Female\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin to load audio & extract features\n",
      "predict_dir/Random_A8/97_Male_test.pcm\n",
      "Begin to predict\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "male:0\n",
      "female:37\n",
      "Female\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictGender(\"predict_dir/Random_A8\") == \"Female\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
