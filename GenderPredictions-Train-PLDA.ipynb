{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from Utils import *\n",
    "from classifier.CNNClassifier import CNNClassifier\n",
    "from classifier.Classifier import Classifier\n",
    "from classifier.ConstantClassifier import ConstantClassifier\n",
    "from classifier.LinearClassifier import LinearClassifier\n",
    "from classifier.RFClassifier import RFClassifier\n",
    "from classifier.SNNClassifier import SNNClassifier\n",
    "from Settings import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from main import run_for_classifier\n",
    "\n",
    "SAVE=True\n",
    "LOAD=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_with_label = files_to_features_with_labels(list_files(AUDIO_FILES_DIR))\n",
    "train_set, test_set = train_test_split(features_with_label, random_state=SEED, train_size=TRAIN_PERCENT, test_size=1-TRAIN_PERCENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = extract_features(train_set)\n",
    "labels_train = extract_labels(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2675"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(features_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.DataFrame(np.zeros(127))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels1 = pd.DataFrame(np.zeros(50)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "if labels_train[1] == 0:\n",
    "    print(0)\n",
    "else:\n",
    "    print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(features_train[0])\n",
    "train_label = pd.DataFrame(np.zeros(train_df.shape[0]))\n",
    "if labels_train[0] == 1:\n",
    "    train_label = train_label+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, features_train.shape[0]):\n",
    "    dfTemp = pd.DataFrame(features_train[i])\n",
    "    train_df = train_df.append(dfTemp, ignore_index=True)\n",
    "    labelTemp = pd.DataFrame(np.zeros(dfTemp.shape[0]))\n",
    "    if labels_train[i] == 1:\n",
    "        labelTemp = labelTemp+1\n",
    "    train_label = train_label.append(labelTemp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178956, 20)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178956, 1)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178956, 20)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(features_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(features_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.append(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(179, 20)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.array(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(179, 20)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = pd.DataFrame(features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2675, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(127, 20)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52, 20)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (127,20) (52,20) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-e76317e983a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfeatures_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfeatures_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (127,20) (52,20) "
     ]
    }
   ],
   "source": [
    "features_train[0], features_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plda\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import random,mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = plda.Classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(features_train[0])\n",
    "train_label = pd.DataFrame(np.zeros(train_df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178956, 20) (178956, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape, train_label.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.68070254, 0.47540527, 0.61192208, ..., 0.40995414, 0.39588086,\n",
       "        0.41895868],\n",
       "       [0.77501817, 0.47743728, 0.62427862, ..., 0.41562028, 0.40069454,\n",
       "        0.41986239],\n",
       "       [0.75638254, 0.48190874, 0.63091752, ..., 0.41835072, 0.40872033,\n",
       "        0.42232574],\n",
       "       ...,\n",
       "       [0.31728625, 0.51517216, 0.48357028, ..., 0.44187902, 0.43103272,\n",
       "        0.39526543],\n",
       "       [0.32280107, 0.51535633, 0.50492888, ..., 0.40199477, 0.36728799,\n",
       "        0.39610247],\n",
       "       [0.31626533, 0.50685449, 0.53579937, ..., 0.39866276, 0.3447906 ,\n",
       "        0.37878463]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178956, 20) (178956, 1)\n"
     ]
    }
   ],
   "source": [
    "print(np.array(train_df).shape, np.array(train_label).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.68070254, 0.47540527, 0.61192208, ..., 0.40995414, 0.39588086,\n",
       "        0.41895868],\n",
       "       [0.77501817, 0.47743728, 0.62427862, ..., 0.41562028, 0.40069454,\n",
       "        0.41986239],\n",
       "       [0.75638254, 0.48190874, 0.63091752, ..., 0.41835072, 0.40872033,\n",
       "        0.42232574],\n",
       "       ...,\n",
       "       [0.31728625, 0.51517216, 0.48357028, ..., 0.44187902, 0.43103272,\n",
       "        0.39526543],\n",
       "       [0.32280107, 0.51535633, 0.50492888, ..., 0.40199477, 0.36728799,\n",
       "        0.39610247],\n",
       "       [0.31626533, 0.50685449, 0.53579937, ..., 0.39866276, 0.3447906 ,\n",
       "        0.37878463]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       ...,\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.68070254, 0.47540527, 0.61192208, ..., 0.40995414, 0.39588086,\n",
       "        0.41895868],\n",
       "       [0.77501817, 0.47743728, 0.62427862, ..., 0.41562028, 0.40069454,\n",
       "        0.41986239],\n",
       "       [0.75638254, 0.48190874, 0.63091752, ..., 0.41835072, 0.40872033,\n",
       "        0.42232574],\n",
       "       ...,\n",
       "       [0.31728625, 0.51517216, 0.48357028, ..., 0.44187902, 0.43103272,\n",
       "        0.39526543],\n",
       "       [0.32280107, 0.51535633, 0.50492888, ..., 0.40199477, 0.36728799,\n",
       "        0.39610247],\n",
       "       [0.31626533, 0.50685449, 0.53579937, ..., 0.39866276, 0.3447906 ,\n",
       "        0.37878463]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178956, 20)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178956, 20)\n",
      "[[0.68070254 0.47540527 0.61192208 ... 0.40995414 0.39588086 0.41895868]\n",
      " [0.77501817 0.47743728 0.62427862 ... 0.41562028 0.40069454 0.41986239]\n",
      " [0.75638254 0.48190874 0.63091752 ... 0.41835072 0.40872033 0.42232574]\n",
      " ...\n",
      " [0.31728625 0.51517216 0.48357028 ... 0.44187902 0.43103272 0.39526543]\n",
      " [0.32280107 0.51535633 0.50492888 ... 0.40199477 0.36728799 0.39610247]\n",
      " [0.31626533 0.50685449 0.53579937 ... 0.39866276 0.3447906  0.37878463]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "expected square matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-4cc60b38f810>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_principal_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/SC/tensorflow3/backup/SpeakerGenderClassificationTimit_0.3.okay/plda/classifier.py\u001b[0m in \u001b[0;36mfit_model\u001b[0;34m(self, X, Y, n_principal_components)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_principal_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_principal_components\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'D'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize_logps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SC/tensorflow3/backup/SpeakerGenderClassificationTimit_0.3.okay/plda/model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, row_wise_data, labels, n_principal_components)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposterior_predictive_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow_wise_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_principal_components\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcalc_logp_posterior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SC/tensorflow3/backup/SpeakerGenderClassificationTimit_0.3.okay/plda/model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, data, labels, n_principal_components)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPsi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelevant_U_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv_A\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0moptimize_maximum_likelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mU_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_space\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'X'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_space\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'U_model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SC/tensorflow3/backup/SpeakerGenderClassificationTimit_0.3.okay/plda/optimizer.py\u001b[0m in \u001b[0;36moptimize_maximum_likelihood\u001b[0;34m(X, labels)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0mS_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_scatter_matrices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_W\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mLambda_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_Lambda_b\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SC/tensorflow3/backup/SpeakerGenderClassificationTimit_0.3.okay/plda/optimizer.py\u001b[0m in \u001b[0;36mcalc_W\u001b[0;34m(S_b, S_w)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcalc_W\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;34m\"\"\" See Fig. 2 on p.537 of Ioffe 2006. \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m     \u001b[0meigenvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meigenvectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meigh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0meigenvectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SC/tensorflow3/lib/python3.6/site-packages/scipy/linalg/decomp.py\u001b[0m in \u001b[0;36meigh\u001b[0;34m(a, b, lower, eigvals_only, overwrite_a, overwrite_b, turbo, eigvals, type, check_finite)\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[0ma1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_validated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_finite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_finite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0ma1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0ma1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'expected square matrix'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m     \u001b[0moverwrite_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moverwrite_a\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_datacopied\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0miscomplexobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: expected square matrix"
     ]
    }
   ],
   "source": [
    "classifier.fit_model(train_df.values, train_label.values, n_principal_components=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(127, 20)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52, 20)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([[0.68070254, 0.47540527, 0.61192208, ..., 0.40995414, 0.39588086,\n",
       "        0.41895868],\n",
       "       [0.77501817, 0.47743728, 0.62427862, ..., 0.41562028, 0.40069454,\n",
       "        0.41986239],\n",
       "       [0.75638254, 0.48190874, 0.63091752, ..., 0.41835072, 0.40872033,\n",
       "        0.42232574],\n",
       "       ...,\n",
       "       [0.30291971, 0.58938896, 0.54612862, ..., 0.36057181, 0.46820339,\n",
       "        0.41672315],\n",
       "       [0.29783974, 0.56977407, 0.54070181, ..., 0.42241812, 0.49122132,\n",
       "        0.39464192],\n",
       "       [0.28331963, 0.55951368, 0.57182201, ..., 0.3925112 , 0.4594885 ,\n",
       "        0.39984143]]),\n",
       "       array([[0.79154606, 0.47070665, 0.62033734, ..., 0.40973844, 0.38939352,\n",
       "        0.41045938],\n",
       "       [0.78647905, 0.47926179, 0.63623767, ..., 0.43855846, 0.38625923,\n",
       "        0.39764628],\n",
       "       [0.72634122, 0.47382993, 0.60589375, ..., 0.30442197, 0.44752815,\n",
       "        0.4392363 ],\n",
       "       ...,\n",
       "       [0.2360081 , 0.5217082 , 0.59980882, ..., 0.46095102, 0.47208483,\n",
       "        0.36998096],\n",
       "       [0.24837287, 0.53270295, 0.56825099, ..., 0.41249957, 0.47824098,\n",
       "        0.37377661],\n",
       "       [0.25662521, 0.52967679, 0.52905631, ..., 0.38663023, 0.42531295,\n",
       "        0.32242599]]),\n",
       "       array([[0.80844584, 0.47651271, 0.60953941, ..., 0.41498649, 0.42995362,\n",
       "        0.4217656 ],\n",
       "       [0.79860997, 0.47562862, 0.62026646, ..., 0.43529988, 0.41353827,\n",
       "        0.39883596],\n",
       "       [0.68042344, 0.48705553, 0.63532821, ..., 0.46422008, 0.38636338,\n",
       "        0.39341388],\n",
       "       ...,\n",
       "       [0.31358447, 0.64847355, 0.64538973, ..., 0.39664588, 0.4273655 ,\n",
       "        0.3317285 ],\n",
       "       [0.30678703, 0.53692147, 0.64188567, ..., 0.50068187, 0.51857422,\n",
       "        0.33779467],\n",
       "       [0.30067848, 0.47856468, 0.62521551, ..., 0.46981813, 0.52291857,\n",
       "        0.34921287]]),\n",
       "       ...,\n",
       "       array([[0.84713185, 0.48659715, 0.61204829, ..., 0.40296881, 0.50963243,\n",
       "        0.31933684],\n",
       "       [0.79969017, 0.54262092, 0.60265403, ..., 0.34870722, 0.45349151,\n",
       "        0.28239659],\n",
       "       [0.71344827, 0.54129153, 0.58364402, ..., 0.26954279, 0.36607702,\n",
       "        0.2673325 ],\n",
       "       ...,\n",
       "       [0.53913594, 0.78156807, 0.60313612, ..., 0.31536921, 0.36933209,\n",
       "        0.31247832],\n",
       "       [0.45028343, 0.74933324, 0.68449914, ..., 0.37142083, 0.34834365,\n",
       "        0.32744918],\n",
       "       [0.33516749, 0.64827362, 0.70010223, ..., 0.34769223, 0.38489448,\n",
       "        0.38364749]]),\n",
       "       array([[0.70482176, 0.49026177, 0.55041397, 0.37792565, 0.62172541,\n",
       "        0.4826621 , 0.60144314, 0.48950024, 0.48891452, 0.41938729,\n",
       "        0.40291457, 0.42430334, 0.31051366, 0.33642096, 0.42939696,\n",
       "        0.3322759 , 0.39043265, 0.38129392, 0.39050307, 0.29019137],\n",
       "       [0.75146796, 0.59193594, 0.60316041, 0.30674536, 0.54457051,\n",
       "        0.47541313, 0.64734702, 0.55302711, 0.50262573, 0.39086372,\n",
       "        0.35452844, 0.3863841 , 0.33505131, 0.36604587, 0.4966553 ,\n",
       "        0.36460146, 0.39637592, 0.35093269, 0.3919473 , 0.28439123],\n",
       "       [0.71649439, 0.72084739, 0.64326693, 0.22155861, 0.44164274,\n",
       "        0.48674359, 0.66939279, 0.5956489 , 0.53610752, 0.42172737,\n",
       "        0.33956909, 0.41449241, 0.39523134, 0.39524503, 0.54508789,\n",
       "        0.38785837, 0.40128377, 0.33595828, 0.39897628, 0.31594437],\n",
       "       [0.65563191, 0.79682137, 0.62739076, 0.15535888, 0.35984144,\n",
       "        0.50428916, 0.6691539 , 0.56353427, 0.57941879, 0.52951974,\n",
       "        0.26200244, 0.52522945, 0.38600922, 0.42481951, 0.55918545,\n",
       "        0.33830793, 0.50750197, 0.34795293, 0.35306745, 0.3410249 ],\n",
       "       [0.63336547, 0.76242613, 0.55144898, 0.1801745 , 0.3917078 ,\n",
       "        0.55374512, 0.65443671, 0.50410819, 0.57496432, 0.57899371,\n",
       "        0.2692457 , 0.66152393, 0.27781984, 0.38909255, 0.56106276,\n",
       "        0.35724632, 0.49338768, 0.30391031, 0.26455901, 0.36855516],\n",
       "       [0.60585748, 0.71280883, 0.44400395, 0.29788243, 0.55104264,\n",
       "        0.46042979, 0.6221794 , 0.42981589, 0.58945943, 0.64203475,\n",
       "        0.28989756, 0.6973761 , 0.34633606, 0.34369634, 0.50907895,\n",
       "        0.32512835, 0.37781703, 0.26209328, 0.31051508, 0.37848521],\n",
       "       [0.62195436, 0.64985198, 0.48557665, 0.47358978, 0.56318055,\n",
       "        0.35304773, 0.47142603, 0.42463781, 0.56158564, 0.44738569,\n",
       "        0.38384897, 0.4591999 , 0.51713931, 0.31975357, 0.4822136 ,\n",
       "        0.37584343, 0.4237512 , 0.33600342, 0.36104995, 0.30873751],\n",
       "       [0.6360422 , 0.55318954, 0.55147136, 0.50451093, 0.54083262,\n",
       "        0.31233428, 0.44914885, 0.46730911, 0.60176265, 0.34592033,\n",
       "        0.44194904, 0.4421078 , 0.52078586, 0.27907914, 0.5252247 ,\n",
       "        0.38623405, 0.42888938, 0.26010708, 0.41488331, 0.31345107],\n",
       "       [0.59981452, 0.54668941, 0.53563871, 0.42030172, 0.5451774 ,\n",
       "        0.39082193, 0.5039351 , 0.40186646, 0.60698379, 0.38957688,\n",
       "        0.45510233, 0.4428089 , 0.43334654, 0.25244023, 0.50689336,\n",
       "        0.3762314 , 0.45026635, 0.27103379, 0.47153254, 0.33510858],\n",
       "       [0.55387092, 0.69728691, 0.57314929, 0.38160615, 0.54675727,\n",
       "        0.47160601, 0.5662157 , 0.26568618, 0.5245586 , 0.48546185,\n",
       "        0.35107103, 0.41623299, 0.37319146, 0.26341616, 0.41725958,\n",
       "        0.34285504, 0.48997415, 0.33931883, 0.50020972, 0.36944209],\n",
       "       [0.48560781, 0.75896031, 0.54927729, 0.38859716, 0.56790646,\n",
       "        0.48247734, 0.70702222, 0.25968777, 0.41031323, 0.63151352,\n",
       "        0.24679277, 0.37466296, 0.33473993, 0.32920512, 0.36705358,\n",
       "        0.37549089, 0.33425515, 0.33451972, 0.52101057, 0.33386364],\n",
       "       [0.51503657, 0.73214254, 0.47262453, 0.38146285, 0.62781773,\n",
       "        0.5637796 , 0.81345934, 0.29406178, 0.34960754, 0.56542093,\n",
       "        0.10848375, 0.30702285, 0.32241304, 0.36768996, 0.38738273,\n",
       "        0.39561921, 0.2553808 , 0.29976542, 0.47730315, 0.24090373],\n",
       "       [0.60129897, 0.76288136, 0.47839427, 0.23199515, 0.60104592,\n",
       "        0.49104158, 0.87600632, 0.31766024, 0.49425537, 0.62032636,\n",
       "        0.29264277, 0.32069669, 0.27178415, 0.2607328 , 0.3250343 ,\n",
       "        0.44584486, 0.30965574, 0.32685166, 0.42397668, 0.24903372],\n",
       "       [0.69075711, 0.72892364, 0.44783591, 0.07760905, 0.66005333,\n",
       "        0.47755023, 0.81154665, 0.39707399, 0.56436585, 0.62406228,\n",
       "        0.4337326 , 0.29596821, 0.25506009, 0.3666708 , 0.39545143,\n",
       "        0.46310222, 0.37806521, 0.26211272, 0.39914678, 0.34764063],\n",
       "       [0.69272712, 0.67293053, 0.39942193, 0.06251075, 0.68456439,\n",
       "        0.46783374, 0.75355215, 0.44815685, 0.54115268, 0.60628288,\n",
       "        0.44037667, 0.29909918, 0.23657878, 0.40573179, 0.41319972,\n",
       "        0.46834473, 0.40768215, 0.22684208, 0.39104257, 0.39354139],\n",
       "       [0.62675783, 0.62377962, 0.32909961, 0.09362542, 0.72507566,\n",
       "        0.53541801, 0.73027224, 0.49767933, 0.50297773, 0.63037386,\n",
       "        0.4391831 , 0.35412201, 0.27543464, 0.46214575, 0.4204214 ,\n",
       "        0.47220361, 0.40237704, 0.28071103, 0.38059339, 0.38914846],\n",
       "       [0.60797589, 0.71424494, 0.36617969, 0.09539841, 0.73357159,\n",
       "        0.55527522, 0.72164754, 0.50679774, 0.53531881, 0.68176183,\n",
       "        0.43134112, 0.440234  , 0.31610484, 0.46312462, 0.38031868,\n",
       "        0.48798583, 0.36967945, 0.35834199, 0.40185456, 0.37960711],\n",
       "       [0.62321957, 0.82974511, 0.50842507, 0.15109162, 0.74250012,\n",
       "        0.58229961, 0.75662841, 0.47870854, 0.66387309, 0.68607166,\n",
       "        0.51568089, 0.48961242, 0.38958568, 0.44154792, 0.44218671,\n",
       "        0.50263369, 0.43291121, 0.33143389, 0.46391413, 0.40402529],\n",
       "       [0.54857771, 0.85717449, 0.58353653, 0.23477384, 0.66559107,\n",
       "        0.60513121, 0.80163967, 0.45760005, 0.67309233, 0.69247756,\n",
       "        0.57977287, 0.46054013, 0.40591477, 0.45017029, 0.46728084,\n",
       "        0.50835242, 0.48288432, 0.32684405, 0.47892177, 0.44388272]]),\n",
       "       array([[0.70551015, 0.49821128, 0.59386976, ..., 0.419884  , 0.39265606,\n",
       "        0.41267755],\n",
       "       [0.76592882, 0.47245813, 0.63249629, ..., 0.41124717, 0.41374765,\n",
       "        0.40109318],\n",
       "       [0.73021382, 0.47075677, 0.66992511, ..., 0.41748017, 0.42199201,\n",
       "        0.39790485],\n",
       "       ...,\n",
       "       [0.31728625, 0.51517216, 0.48357028, ..., 0.44187902, 0.43103272,\n",
       "        0.39526543],\n",
       "       [0.32280107, 0.51535633, 0.50492888, ..., 0.40199477, 0.36728799,\n",
       "        0.39610247],\n",
       "       [0.31626533, 0.50685449, 0.53579937, ..., 0.39866276, 0.3447906 ,\n",
       "        0.37878463]])], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([[0.68070254, 0.47540527, 0.61192208, ..., 0.40995414, 0.39588086,\n",
       "        0.41895868],\n",
       "       [0.77501817, 0.47743728, 0.62427862, ..., 0.41562028, 0.40069454,\n",
       "        0.41986239],\n",
       "       [0.75638254, 0.48190874, 0.63091752, ..., 0.41835072, 0.40872033,\n",
       "        0.42232574],\n",
       "       ...,\n",
       "       [0.30291971, 0.58938896, 0.54612862, ..., 0.36057181, 0.46820339,\n",
       "        0.41672315],\n",
       "       [0.29783974, 0.56977407, 0.54070181, ..., 0.42241812, 0.49122132,\n",
       "        0.39464192],\n",
       "       [0.28331963, 0.55951368, 0.57182201, ..., 0.3925112 , 0.4594885 ,\n",
       "        0.39984143]]),\n",
       "       array([[0.79154606, 0.47070665, 0.62033734, ..., 0.40973844, 0.38939352,\n",
       "        0.41045938],\n",
       "       [0.78647905, 0.47926179, 0.63623767, ..., 0.43855846, 0.38625923,\n",
       "        0.39764628],\n",
       "       [0.72634122, 0.47382993, 0.60589375, ..., 0.30442197, 0.44752815,\n",
       "        0.4392363 ],\n",
       "       ...,\n",
       "       [0.2360081 , 0.5217082 , 0.59980882, ..., 0.46095102, 0.47208483,\n",
       "        0.36998096],\n",
       "       [0.24837287, 0.53270295, 0.56825099, ..., 0.41249957, 0.47824098,\n",
       "        0.37377661],\n",
       "       [0.25662521, 0.52967679, 0.52905631, ..., 0.38663023, 0.42531295,\n",
       "        0.32242599]]),\n",
       "       array([[0.80844584, 0.47651271, 0.60953941, ..., 0.41498649, 0.42995362,\n",
       "        0.4217656 ],\n",
       "       [0.79860997, 0.47562862, 0.62026646, ..., 0.43529988, 0.41353827,\n",
       "        0.39883596],\n",
       "       [0.68042344, 0.48705553, 0.63532821, ..., 0.46422008, 0.38636338,\n",
       "        0.39341388],\n",
       "       ...,\n",
       "       [0.31358447, 0.64847355, 0.64538973, ..., 0.39664588, 0.4273655 ,\n",
       "        0.3317285 ],\n",
       "       [0.30678703, 0.53692147, 0.64188567, ..., 0.50068187, 0.51857422,\n",
       "        0.33779467],\n",
       "       [0.30067848, 0.47856468, 0.62521551, ..., 0.46981813, 0.52291857,\n",
       "        0.34921287]]),\n",
       "       ...,\n",
       "       array([[0.84713185, 0.48659715, 0.61204829, ..., 0.40296881, 0.50963243,\n",
       "        0.31933684],\n",
       "       [0.79969017, 0.54262092, 0.60265403, ..., 0.34870722, 0.45349151,\n",
       "        0.28239659],\n",
       "       [0.71344827, 0.54129153, 0.58364402, ..., 0.26954279, 0.36607702,\n",
       "        0.2673325 ],\n",
       "       ...,\n",
       "       [0.53913594, 0.78156807, 0.60313612, ..., 0.31536921, 0.36933209,\n",
       "        0.31247832],\n",
       "       [0.45028343, 0.74933324, 0.68449914, ..., 0.37142083, 0.34834365,\n",
       "        0.32744918],\n",
       "       [0.33516749, 0.64827362, 0.70010223, ..., 0.34769223, 0.38489448,\n",
       "        0.38364749]]),\n",
       "       array([[0.70482176, 0.49026177, 0.55041397, 0.37792565, 0.62172541,\n",
       "        0.4826621 , 0.60144314, 0.48950024, 0.48891452, 0.41938729,\n",
       "        0.40291457, 0.42430334, 0.31051366, 0.33642096, 0.42939696,\n",
       "        0.3322759 , 0.39043265, 0.38129392, 0.39050307, 0.29019137],\n",
       "       [0.75146796, 0.59193594, 0.60316041, 0.30674536, 0.54457051,\n",
       "        0.47541313, 0.64734702, 0.55302711, 0.50262573, 0.39086372,\n",
       "        0.35452844, 0.3863841 , 0.33505131, 0.36604587, 0.4966553 ,\n",
       "        0.36460146, 0.39637592, 0.35093269, 0.3919473 , 0.28439123],\n",
       "       [0.71649439, 0.72084739, 0.64326693, 0.22155861, 0.44164274,\n",
       "        0.48674359, 0.66939279, 0.5956489 , 0.53610752, 0.42172737,\n",
       "        0.33956909, 0.41449241, 0.39523134, 0.39524503, 0.54508789,\n",
       "        0.38785837, 0.40128377, 0.33595828, 0.39897628, 0.31594437],\n",
       "       [0.65563191, 0.79682137, 0.62739076, 0.15535888, 0.35984144,\n",
       "        0.50428916, 0.6691539 , 0.56353427, 0.57941879, 0.52951974,\n",
       "        0.26200244, 0.52522945, 0.38600922, 0.42481951, 0.55918545,\n",
       "        0.33830793, 0.50750197, 0.34795293, 0.35306745, 0.3410249 ],\n",
       "       [0.63336547, 0.76242613, 0.55144898, 0.1801745 , 0.3917078 ,\n",
       "        0.55374512, 0.65443671, 0.50410819, 0.57496432, 0.57899371,\n",
       "        0.2692457 , 0.66152393, 0.27781984, 0.38909255, 0.56106276,\n",
       "        0.35724632, 0.49338768, 0.30391031, 0.26455901, 0.36855516],\n",
       "       [0.60585748, 0.71280883, 0.44400395, 0.29788243, 0.55104264,\n",
       "        0.46042979, 0.6221794 , 0.42981589, 0.58945943, 0.64203475,\n",
       "        0.28989756, 0.6973761 , 0.34633606, 0.34369634, 0.50907895,\n",
       "        0.32512835, 0.37781703, 0.26209328, 0.31051508, 0.37848521],\n",
       "       [0.62195436, 0.64985198, 0.48557665, 0.47358978, 0.56318055,\n",
       "        0.35304773, 0.47142603, 0.42463781, 0.56158564, 0.44738569,\n",
       "        0.38384897, 0.4591999 , 0.51713931, 0.31975357, 0.4822136 ,\n",
       "        0.37584343, 0.4237512 , 0.33600342, 0.36104995, 0.30873751],\n",
       "       [0.6360422 , 0.55318954, 0.55147136, 0.50451093, 0.54083262,\n",
       "        0.31233428, 0.44914885, 0.46730911, 0.60176265, 0.34592033,\n",
       "        0.44194904, 0.4421078 , 0.52078586, 0.27907914, 0.5252247 ,\n",
       "        0.38623405, 0.42888938, 0.26010708, 0.41488331, 0.31345107],\n",
       "       [0.59981452, 0.54668941, 0.53563871, 0.42030172, 0.5451774 ,\n",
       "        0.39082193, 0.5039351 , 0.40186646, 0.60698379, 0.38957688,\n",
       "        0.45510233, 0.4428089 , 0.43334654, 0.25244023, 0.50689336,\n",
       "        0.3762314 , 0.45026635, 0.27103379, 0.47153254, 0.33510858],\n",
       "       [0.55387092, 0.69728691, 0.57314929, 0.38160615, 0.54675727,\n",
       "        0.47160601, 0.5662157 , 0.26568618, 0.5245586 , 0.48546185,\n",
       "        0.35107103, 0.41623299, 0.37319146, 0.26341616, 0.41725958,\n",
       "        0.34285504, 0.48997415, 0.33931883, 0.50020972, 0.36944209],\n",
       "       [0.48560781, 0.75896031, 0.54927729, 0.38859716, 0.56790646,\n",
       "        0.48247734, 0.70702222, 0.25968777, 0.41031323, 0.63151352,\n",
       "        0.24679277, 0.37466296, 0.33473993, 0.32920512, 0.36705358,\n",
       "        0.37549089, 0.33425515, 0.33451972, 0.52101057, 0.33386364],\n",
       "       [0.51503657, 0.73214254, 0.47262453, 0.38146285, 0.62781773,\n",
       "        0.5637796 , 0.81345934, 0.29406178, 0.34960754, 0.56542093,\n",
       "        0.10848375, 0.30702285, 0.32241304, 0.36768996, 0.38738273,\n",
       "        0.39561921, 0.2553808 , 0.29976542, 0.47730315, 0.24090373],\n",
       "       [0.60129897, 0.76288136, 0.47839427, 0.23199515, 0.60104592,\n",
       "        0.49104158, 0.87600632, 0.31766024, 0.49425537, 0.62032636,\n",
       "        0.29264277, 0.32069669, 0.27178415, 0.2607328 , 0.3250343 ,\n",
       "        0.44584486, 0.30965574, 0.32685166, 0.42397668, 0.24903372],\n",
       "       [0.69075711, 0.72892364, 0.44783591, 0.07760905, 0.66005333,\n",
       "        0.47755023, 0.81154665, 0.39707399, 0.56436585, 0.62406228,\n",
       "        0.4337326 , 0.29596821, 0.25506009, 0.3666708 , 0.39545143,\n",
       "        0.46310222, 0.37806521, 0.26211272, 0.39914678, 0.34764063],\n",
       "       [0.69272712, 0.67293053, 0.39942193, 0.06251075, 0.68456439,\n",
       "        0.46783374, 0.75355215, 0.44815685, 0.54115268, 0.60628288,\n",
       "        0.44037667, 0.29909918, 0.23657878, 0.40573179, 0.41319972,\n",
       "        0.46834473, 0.40768215, 0.22684208, 0.39104257, 0.39354139],\n",
       "       [0.62675783, 0.62377962, 0.32909961, 0.09362542, 0.72507566,\n",
       "        0.53541801, 0.73027224, 0.49767933, 0.50297773, 0.63037386,\n",
       "        0.4391831 , 0.35412201, 0.27543464, 0.46214575, 0.4204214 ,\n",
       "        0.47220361, 0.40237704, 0.28071103, 0.38059339, 0.38914846],\n",
       "       [0.60797589, 0.71424494, 0.36617969, 0.09539841, 0.73357159,\n",
       "        0.55527522, 0.72164754, 0.50679774, 0.53531881, 0.68176183,\n",
       "        0.43134112, 0.440234  , 0.31610484, 0.46312462, 0.38031868,\n",
       "        0.48798583, 0.36967945, 0.35834199, 0.40185456, 0.37960711],\n",
       "       [0.62321957, 0.82974511, 0.50842507, 0.15109162, 0.74250012,\n",
       "        0.58229961, 0.75662841, 0.47870854, 0.66387309, 0.68607166,\n",
       "        0.51568089, 0.48961242, 0.38958568, 0.44154792, 0.44218671,\n",
       "        0.50263369, 0.43291121, 0.33143389, 0.46391413, 0.40402529],\n",
       "       [0.54857771, 0.85717449, 0.58353653, 0.23477384, 0.66559107,\n",
       "        0.60513121, 0.80163967, 0.45760005, 0.67309233, 0.69247756,\n",
       "        0.57977287, 0.46054013, 0.40591477, 0.45017029, 0.46728084,\n",
       "        0.50835242, 0.48288432, 0.32684405, 0.47892177, 0.44388272]]),\n",
       "       array([[0.70551015, 0.49821128, 0.59386976, ..., 0.419884  , 0.39265606,\n",
       "        0.41267755],\n",
       "       [0.76592882, 0.47245813, 0.63249629, ..., 0.41124717, 0.41374765,\n",
       "        0.40109318],\n",
       "       [0.73021382, 0.47075677, 0.66992511, ..., 0.41748017, 0.42199201,\n",
       "        0.39790485],\n",
       "       ...,\n",
       "       [0.31728625, 0.51517216, 0.48357028, ..., 0.44187902, 0.43103272,\n",
       "        0.39526543],\n",
       "       [0.32280107, 0.51535633, 0.50492888, ..., 0.40199477, 0.36728799,\n",
       "        0.39610247],\n",
       "       [0.31626533, 0.50685449, 0.53579937, ..., 0.39866276, 0.3447906 ,\n",
       "        0.37878463]])], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2675,)\n",
      "[array([[0.68070254, 0.47540527, 0.61192208, ..., 0.40995414, 0.39588086,\n",
      "        0.41895868],\n",
      "       [0.77501817, 0.47743728, 0.62427862, ..., 0.41562028, 0.40069454,\n",
      "        0.41986239],\n",
      "       [0.75638254, 0.48190874, 0.63091752, ..., 0.41835072, 0.40872033,\n",
      "        0.42232574],\n",
      "       ...,\n",
      "       [0.30291971, 0.58938896, 0.54612862, ..., 0.36057181, 0.46820339,\n",
      "        0.41672315],\n",
      "       [0.29783974, 0.56977407, 0.54070181, ..., 0.42241812, 0.49122132,\n",
      "        0.39464192],\n",
      "       [0.28331963, 0.55951368, 0.57182201, ..., 0.3925112 , 0.4594885 ,\n",
      "        0.39984143]])\n",
      " array([[0.79154606, 0.47070665, 0.62033734, ..., 0.40973844, 0.38939352,\n",
      "        0.41045938],\n",
      "       [0.78647905, 0.47926179, 0.63623767, ..., 0.43855846, 0.38625923,\n",
      "        0.39764628],\n",
      "       [0.72634122, 0.47382993, 0.60589375, ..., 0.30442197, 0.44752815,\n",
      "        0.4392363 ],\n",
      "       ...,\n",
      "       [0.2360081 , 0.5217082 , 0.59980882, ..., 0.46095102, 0.47208483,\n",
      "        0.36998096],\n",
      "       [0.24837287, 0.53270295, 0.56825099, ..., 0.41249957, 0.47824098,\n",
      "        0.37377661],\n",
      "       [0.25662521, 0.52967679, 0.52905631, ..., 0.38663023, 0.42531295,\n",
      "        0.32242599]])\n",
      " array([[0.80844584, 0.47651271, 0.60953941, ..., 0.41498649, 0.42995362,\n",
      "        0.4217656 ],\n",
      "       [0.79860997, 0.47562862, 0.62026646, ..., 0.43529988, 0.41353827,\n",
      "        0.39883596],\n",
      "       [0.68042344, 0.48705553, 0.63532821, ..., 0.46422008, 0.38636338,\n",
      "        0.39341388],\n",
      "       ...,\n",
      "       [0.31358447, 0.64847355, 0.64538973, ..., 0.39664588, 0.4273655 ,\n",
      "        0.3317285 ],\n",
      "       [0.30678703, 0.53692147, 0.64188567, ..., 0.50068187, 0.51857422,\n",
      "        0.33779467],\n",
      "       [0.30067848, 0.47856468, 0.62521551, ..., 0.46981813, 0.52291857,\n",
      "        0.34921287]])\n",
      " ...\n",
      " array([[0.84713185, 0.48659715, 0.61204829, ..., 0.40296881, 0.50963243,\n",
      "        0.31933684],\n",
      "       [0.79969017, 0.54262092, 0.60265403, ..., 0.34870722, 0.45349151,\n",
      "        0.28239659],\n",
      "       [0.71344827, 0.54129153, 0.58364402, ..., 0.26954279, 0.36607702,\n",
      "        0.2673325 ],\n",
      "       ...,\n",
      "       [0.53913594, 0.78156807, 0.60313612, ..., 0.31536921, 0.36933209,\n",
      "        0.31247832],\n",
      "       [0.45028343, 0.74933324, 0.68449914, ..., 0.37142083, 0.34834365,\n",
      "        0.32744918],\n",
      "       [0.33516749, 0.64827362, 0.70010223, ..., 0.34769223, 0.38489448,\n",
      "        0.38364749]])\n",
      " array([[0.70482176, 0.49026177, 0.55041397, 0.37792565, 0.62172541,\n",
      "        0.4826621 , 0.60144314, 0.48950024, 0.48891452, 0.41938729,\n",
      "        0.40291457, 0.42430334, 0.31051366, 0.33642096, 0.42939696,\n",
      "        0.3322759 , 0.39043265, 0.38129392, 0.39050307, 0.29019137],\n",
      "       [0.75146796, 0.59193594, 0.60316041, 0.30674536, 0.54457051,\n",
      "        0.47541313, 0.64734702, 0.55302711, 0.50262573, 0.39086372,\n",
      "        0.35452844, 0.3863841 , 0.33505131, 0.36604587, 0.4966553 ,\n",
      "        0.36460146, 0.39637592, 0.35093269, 0.3919473 , 0.28439123],\n",
      "       [0.71649439, 0.72084739, 0.64326693, 0.22155861, 0.44164274,\n",
      "        0.48674359, 0.66939279, 0.5956489 , 0.53610752, 0.42172737,\n",
      "        0.33956909, 0.41449241, 0.39523134, 0.39524503, 0.54508789,\n",
      "        0.38785837, 0.40128377, 0.33595828, 0.39897628, 0.31594437],\n",
      "       [0.65563191, 0.79682137, 0.62739076, 0.15535888, 0.35984144,\n",
      "        0.50428916, 0.6691539 , 0.56353427, 0.57941879, 0.52951974,\n",
      "        0.26200244, 0.52522945, 0.38600922, 0.42481951, 0.55918545,\n",
      "        0.33830793, 0.50750197, 0.34795293, 0.35306745, 0.3410249 ],\n",
      "       [0.63336547, 0.76242613, 0.55144898, 0.1801745 , 0.3917078 ,\n",
      "        0.55374512, 0.65443671, 0.50410819, 0.57496432, 0.57899371,\n",
      "        0.2692457 , 0.66152393, 0.27781984, 0.38909255, 0.56106276,\n",
      "        0.35724632, 0.49338768, 0.30391031, 0.26455901, 0.36855516],\n",
      "       [0.60585748, 0.71280883, 0.44400395, 0.29788243, 0.55104264,\n",
      "        0.46042979, 0.6221794 , 0.42981589, 0.58945943, 0.64203475,\n",
      "        0.28989756, 0.6973761 , 0.34633606, 0.34369634, 0.50907895,\n",
      "        0.32512835, 0.37781703, 0.26209328, 0.31051508, 0.37848521],\n",
      "       [0.62195436, 0.64985198, 0.48557665, 0.47358978, 0.56318055,\n",
      "        0.35304773, 0.47142603, 0.42463781, 0.56158564, 0.44738569,\n",
      "        0.38384897, 0.4591999 , 0.51713931, 0.31975357, 0.4822136 ,\n",
      "        0.37584343, 0.4237512 , 0.33600342, 0.36104995, 0.30873751],\n",
      "       [0.6360422 , 0.55318954, 0.55147136, 0.50451093, 0.54083262,\n",
      "        0.31233428, 0.44914885, 0.46730911, 0.60176265, 0.34592033,\n",
      "        0.44194904, 0.4421078 , 0.52078586, 0.27907914, 0.5252247 ,\n",
      "        0.38623405, 0.42888938, 0.26010708, 0.41488331, 0.31345107],\n",
      "       [0.59981452, 0.54668941, 0.53563871, 0.42030172, 0.5451774 ,\n",
      "        0.39082193, 0.5039351 , 0.40186646, 0.60698379, 0.38957688,\n",
      "        0.45510233, 0.4428089 , 0.43334654, 0.25244023, 0.50689336,\n",
      "        0.3762314 , 0.45026635, 0.27103379, 0.47153254, 0.33510858],\n",
      "       [0.55387092, 0.69728691, 0.57314929, 0.38160615, 0.54675727,\n",
      "        0.47160601, 0.5662157 , 0.26568618, 0.5245586 , 0.48546185,\n",
      "        0.35107103, 0.41623299, 0.37319146, 0.26341616, 0.41725958,\n",
      "        0.34285504, 0.48997415, 0.33931883, 0.50020972, 0.36944209],\n",
      "       [0.48560781, 0.75896031, 0.54927729, 0.38859716, 0.56790646,\n",
      "        0.48247734, 0.70702222, 0.25968777, 0.41031323, 0.63151352,\n",
      "        0.24679277, 0.37466296, 0.33473993, 0.32920512, 0.36705358,\n",
      "        0.37549089, 0.33425515, 0.33451972, 0.52101057, 0.33386364],\n",
      "       [0.51503657, 0.73214254, 0.47262453, 0.38146285, 0.62781773,\n",
      "        0.5637796 , 0.81345934, 0.29406178, 0.34960754, 0.56542093,\n",
      "        0.10848375, 0.30702285, 0.32241304, 0.36768996, 0.38738273,\n",
      "        0.39561921, 0.2553808 , 0.29976542, 0.47730315, 0.24090373],\n",
      "       [0.60129897, 0.76288136, 0.47839427, 0.23199515, 0.60104592,\n",
      "        0.49104158, 0.87600632, 0.31766024, 0.49425537, 0.62032636,\n",
      "        0.29264277, 0.32069669, 0.27178415, 0.2607328 , 0.3250343 ,\n",
      "        0.44584486, 0.30965574, 0.32685166, 0.42397668, 0.24903372],\n",
      "       [0.69075711, 0.72892364, 0.44783591, 0.07760905, 0.66005333,\n",
      "        0.47755023, 0.81154665, 0.39707399, 0.56436585, 0.62406228,\n",
      "        0.4337326 , 0.29596821, 0.25506009, 0.3666708 , 0.39545143,\n",
      "        0.46310222, 0.37806521, 0.26211272, 0.39914678, 0.34764063],\n",
      "       [0.69272712, 0.67293053, 0.39942193, 0.06251075, 0.68456439,\n",
      "        0.46783374, 0.75355215, 0.44815685, 0.54115268, 0.60628288,\n",
      "        0.44037667, 0.29909918, 0.23657878, 0.40573179, 0.41319972,\n",
      "        0.46834473, 0.40768215, 0.22684208, 0.39104257, 0.39354139],\n",
      "       [0.62675783, 0.62377962, 0.32909961, 0.09362542, 0.72507566,\n",
      "        0.53541801, 0.73027224, 0.49767933, 0.50297773, 0.63037386,\n",
      "        0.4391831 , 0.35412201, 0.27543464, 0.46214575, 0.4204214 ,\n",
      "        0.47220361, 0.40237704, 0.28071103, 0.38059339, 0.38914846],\n",
      "       [0.60797589, 0.71424494, 0.36617969, 0.09539841, 0.73357159,\n",
      "        0.55527522, 0.72164754, 0.50679774, 0.53531881, 0.68176183,\n",
      "        0.43134112, 0.440234  , 0.31610484, 0.46312462, 0.38031868,\n",
      "        0.48798583, 0.36967945, 0.35834199, 0.40185456, 0.37960711],\n",
      "       [0.62321957, 0.82974511, 0.50842507, 0.15109162, 0.74250012,\n",
      "        0.58229961, 0.75662841, 0.47870854, 0.66387309, 0.68607166,\n",
      "        0.51568089, 0.48961242, 0.38958568, 0.44154792, 0.44218671,\n",
      "        0.50263369, 0.43291121, 0.33143389, 0.46391413, 0.40402529],\n",
      "       [0.54857771, 0.85717449, 0.58353653, 0.23477384, 0.66559107,\n",
      "        0.60513121, 0.80163967, 0.45760005, 0.67309233, 0.69247756,\n",
      "        0.57977287, 0.46054013, 0.40591477, 0.45017029, 0.46728084,\n",
      "        0.50835242, 0.48288432, 0.32684405, 0.47892177, 0.44388272]])\n",
      " array([[0.70551015, 0.49821128, 0.59386976, ..., 0.419884  , 0.39265606,\n",
      "        0.41267755],\n",
      "       [0.76592882, 0.47245813, 0.63249629, ..., 0.41124717, 0.41374765,\n",
      "        0.40109318],\n",
      "       [0.73021382, 0.47075677, 0.66992511, ..., 0.41748017, 0.42199201,\n",
      "        0.39790485],\n",
      "       ...,\n",
      "       [0.31728625, 0.51517216, 0.48357028, ..., 0.44187902, 0.43103272,\n",
      "        0.39526543],\n",
      "       [0.32280107, 0.51535633, 0.50492888, ..., 0.40199477, 0.36728799,\n",
      "        0.39610247],\n",
      "       [0.31626533, 0.50685449, 0.53579937, ..., 0.39866276, 0.3447906 ,\n",
      "        0.37878463]])]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-b5673aa2c1ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_principal_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/SC/tensorflow3/backup/SpeakerGenderClassificationTimit_0.3.okay/plda/classifier.py\u001b[0m in \u001b[0;36mfit_model\u001b[0;34m(self, X, Y, n_principal_components)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_principal_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_principal_components\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'D'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize_logps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SC/tensorflow3/backup/SpeakerGenderClassificationTimit_0.3.okay/plda/model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, row_wise_data, labels, n_principal_components)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow_wise_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow_wise_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow_wise_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mrow_wise_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "classifier.fit_model(features_train, labels_train, n_principal_components=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.fit_model(features_train, labels_train, n_principal_components=5)\n",
    "\n",
    "predictions, log_p_predictions = classifier.predict(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(testing_data.shape, testing_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def test_classifier(classifier : Classifier) -> None:\n",
    "    \"\"\"\n",
    "    Wrapper for method run_for_classifier.\n",
    "    :param classifier: The classifier to test\n",
    "    \"\"\"\n",
    "    one_d = not isinstance(classifier, CNNClassifier)\n",
    "    run_for_classifier(classifier, test_set=test_set, train_set=train_set, save=SAVE, load=LOAD, one_d=one_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_for_classifier\n",
      "Finished loading/creating features\n",
      "Using classifier RFClassifier - n_est 10 - max_depth None\n",
      "Training RFClassifier - n_est 10 - max_depth None\n",
      "Saved RFClassifier - n_est 10 - max_depth None\n",
      "ModePath:models/RFClassifier - n_est 10 - max_depth None.pkl\n",
      "Predicting on files...\n",
      "Predicting on samples...\n",
      "Test accuracy - files : 0.9805680119581465\n",
      "Test accuracy - samples : 0.8075283937263386\n"
     ]
    }
   ],
   "source": [
    "test_classifier(RFClassifier(n_estimators=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run_for_classifier\n",
    "Finished loading/creating features\n",
    "Using classifier RFClassifier - n_est 10 - max_depth None\n",
    "Training RFClassifier - n_est 10 - max_depth None\n",
    "Saved RFClassifier - n_est 10 - max_depth None\n",
    "ModePath:models/RFClassifier - n_est 10 - max_depth None.pkl\n",
    "Predicting on files...\n",
    "Predicting on samples...\n",
    "Test accuracy - files : 0.9805680119581465\n",
    "Test accuracy - samples : 0.8075283937263386"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run_for_classifier\n",
    "Finished loading/creating features\n",
    "Using classifier RFClassifier - n_est 10 - max_depth None\n",
    "Training RFClassifier - n_est 10 - max_depth None\n",
    "Saved RFClassifier - n_est 10 - max_depth None\n",
    "ModePath:models/RFClassifier - n_est 10 - max_depth None.pkl\n",
    "Predicting on files...\n",
    "Predicting on samples...\n",
    "Test accuracy - files : 0.9819078947368421\n",
    "Test accuracy - samples : 0.8106407598476447"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run_for_classifier\n",
    "Finished loading/creating features\n",
    "Using classifier RFClassifier - n_est 10 - max_depth None\n",
    "Training RFClassifier - n_est 10 - max_depth None\n",
    "Saved RFClassifier - n_est 10 - max_depth None\n",
    "ModePath:models/RFClassifier - n_est 10 - max_depth None.pkl\n",
    "Predicting on files...\n",
    "Predicting on samples...\n",
    "Test accuracy - files : 0.9748427672955975\n",
    "Test accuracy - samples : 0.7540060177734238"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run_for_classifier\n",
    "Finished loading/creating features\n",
    "Using classifier RFClassifier - n_est 10 - max_depth None\n",
    "Training RFClassifier - n_est 10 - max_depth None\n",
    "Saved RFClassifier - n_est 10 - max_depth None\n",
    "ModePath:models/RFClassifier - n_est 10 - max_depth None.pkl\n",
    "Predicting on files...\n",
    "Predicting on samples...\n",
    "Test accuracy - files : 0.948220064724919\n",
    "Test accuracy - samples : 0.7349437337341006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run_for_classifier\n",
    "Finished loading/creating features\n",
    "Using classifier RFClassifier - n_est 10 - max_depth None\n",
    "Training RFClassifier - n_est 10 - max_depth None\n",
    "Saved RFClassifier - n_est 10 - max_depth None\n",
    "ModePath:models/RFClassifier - n_est 10 - max_depth None.pkl\n",
    "Predicting on files...\n",
    "Predicting on samples...\n",
    "Test accuracy - files : 0.9722222222222222\n",
    "Test accuracy - samples : 0.7556776128705543"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run_for_classifier\n",
    "Finished loading/creating features\n",
    "Using classifier RFClassifier - n_est 10 - max_depth None\n",
    "Training RFClassifier - n_est 10 - max_depth None\n",
    "Saved RFClassifier - n_est 10 - max_depth None\n",
    "ModePath:models/RFClassifier - n_est 10 - max_depth None.pkl\n",
    "Predicting on files...\n",
    "Predicting on samples...\n",
    "Test accuracy - files : 0.9754385964912281\n",
    "Test accuracy - samples : 0.7609640299348194"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run_for_classifier\n",
    "Finished loading/creating features\n",
    "Using classifier RFClassifier - n_est 10 - max_depth None\n",
    "Training RFClassifier - n_est 10 - max_depth None\n",
    "Saved RFClassifier - n_est 10 - max_depth None\n",
    "ModePath:models/RFClassifier - n_est 10 - max_depth None.pkl\n",
    "Predicting on files...\n",
    "Predicting on samples...\n",
    "Test accuracy - files : 0.9820143884892086\n",
    "Test accuracy - samples : 0.7675503799141064"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run_for_classifier\n",
    "Finished loading/creating features\n",
    "Using classifier RFClassifier - n_est 10 - max_depth None\n",
    "Training RFClassifier - n_est 10 - max_depth None\n",
    "Saved RFClassifier - n_est 10 - max_depth None\n",
    "ModePath:models/RFClassifier - n_est 10 - max_depth None.pkl\n",
    "Predicting on files...\n",
    "Predicting on samples...\n",
    "Test accuracy - files : 0.9560439560439561\n",
    "Test accuracy - samples : 0.767567787639443"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_for_classifier\n",
      "Finished loading/creating features\n",
      "Using classifier RFClassifier - n_est 100 - max_depth None\n",
      "Training RFClassifier - n_est 100 - max_depth None\n",
      "Saved RFClassifier - n_est 100 - max_depth None\n",
      "ModePath:models/RFClassifier - n_est 100 - max_depth None.pkl\n",
      "Predicting on files...\n",
      "Predicting on samples...\n",
      "Test accuracy - files : 0.9745889387144993\n",
      "Test accuracy - samples : 0.8410383991346674\n"
     ]
    }
   ],
   "source": [
    "test_classifier(RFClassifier(n_estimators=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run_for_classifier\n",
    "Finished loading/creating features\n",
    "Using classifier RFClassifier - n_est 100 - max_depth None\n",
    "Training RFClassifier - n_est 100 - max_depth None\n",
    "Saved RFClassifier - n_est 100 - max_depth None\n",
    "ModePath:models/RFClassifier - n_est 100 - max_depth None.pkl\n",
    "Predicting on files...\n",
    "Predicting on samples...\n",
    "Test accuracy - files : 0.9802631578947368\n",
    "Test accuracy - samples : 0.8487054626102888"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run_for_classifier\n",
    "Finished loading/creating features\n",
    "Using classifier RFClassifier - n_est 100 - max_depth None\n",
    "Training RFClassifier - n_est 100 - max_depth None\n",
    "Saved RFClassifier - n_est 100 - max_depth None\n",
    "ModePath:models/RFClassifier - n_est 100 - max_depth None.pkl\n",
    "Predicting on files...\n",
    "Predicting on samples...\n",
    "Test accuracy - files : 0.9779874213836478\n",
    "Test accuracy - samples : 0.7998390595479673"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run_for_classifier\n",
    "Finished loading/creating features\n",
    "Using classifier RFClassifier - n_est 100 - max_depth None\n",
    "Training RFClassifier - n_est 100 - max_depth None\n",
    "Saved RFClassifier - n_est 100 - max_depth None\n",
    "ModePath:models/RFClassifier - n_est 100 - max_depth None.pkl\n",
    "Predicting on files...\n",
    "Predicting on samples...\n",
    "Test accuracy - files : 0.9546925566343042\n",
    "Test accuracy - samples : 0.7787471133756094"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run_for_classifier\n",
    "Finished loading/creating features\n",
    "Using classifier RFClassifier - n_est 100 - max_depth None\n",
    "Training RFClassifier - n_est 100 - max_depth None\n",
    "Saved RFClassifier - n_est 100 - max_depth None\n",
    "ModePath:models/RFClassifier - n_est 100 - max_depth None.pkl\n",
    "Predicting on files...\n",
    "Predicting on samples...\n",
    "Test accuracy - files : 0.9756944444444444\n",
    "Test accuracy - samples : 0.7995013828834093"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run_for_classifier\n",
    "Finished loading/creating features\n",
    "Using classifier RFClassifier - n_est 100 - max_depth None\n",
    "Training RFClassifier - n_est 100 - max_depth None\n",
    "Saved RFClassifier - n_est 100 - max_depth None\n",
    "ModePath:models/RFClassifier - n_est 100 - max_depth None.pkl\n",
    "Predicting on files...\n",
    "Predicting on samples...\n",
    "Test accuracy - files : 0.9719298245614035\n",
    "Test accuracy - samples : 0.8007564174780719"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run_for_classifier\n",
    "Finished loading/creating features\n",
    "Using classifier RFClassifier - n_est 100 - max_depth None\n",
    "Training RFClassifier - n_est 100 - max_depth None\n",
    "Saved RFClassifier - n_est 100 - max_depth None\n",
    "ModePath:models/RFClassifier - n_est 100 - max_depth None.pkl\n",
    "Predicting on files...\n",
    "Predicting on samples...\n",
    "Test accuracy - files : 0.9646643109540636\n",
    "Test accuracy - samples : 0.7948184038761863"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run_for_classifier\n",
    "Finished loading/creating features\n",
    "Using classifier RFClassifier - n_est 100 - max_depth None\n",
    "Training RFClassifier - n_est 100 - max_depth None\n",
    "Saved RFClassifier - n_est 100 - max_depth None\n",
    "ModePath:models/RFClassifier - n_est 100 - max_depth None.pkl\n",
    "Predicting on files...\n",
    "Predicting on samples...\n",
    "Test accuracy - files : 0.9820143884892086\n",
    "Test accuracy - samples : 0.8051288404360754"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run_for_classifier\n",
    "Finished loading/creating features\n",
    "Using classifier RFClassifier - n_est 100 - max_depth None\n",
    "Training RFClassifier - n_est 100 - max_depth None\n",
    "Saved RFClassifier - n_est 100 - max_depth None\n",
    "ModePath:models/RFClassifier - n_est 100 - max_depth None.pkl\n",
    "Predicting on files...\n",
    "Predicting on samples...\n",
    "Test accuracy - files : 0.978021978021978\n",
    "Test accuracy - samples : 0.8037619086393616"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run_for_classifier\n",
    "Finished loading/creating features\n",
    "Using classifier RFClassifier - n_est 100 - max_depth None\n",
    "Training RFClassifier - n_est 100 - max_depth None\n",
    "Saved RFClassifier - n_est 100 - max_depth None\n",
    "ModePath:models/RFClassifier - n_est 100 - max_depth None.pkl\n",
    "Predicting on files...\n",
    "Predicting on samples...\n",
    "Test accuracy - files : 0.984313725490196\n",
    "Test accuracy - samples : 0.8058165548098434"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run_for_classifier\n",
    "Finished loading/creating features\n",
    "Using classifier RFClassifier - n_est 100 - max_depth None\n",
    "Training RFClassifier - n_est 100 - max_depth None\n",
    "Saved RFClassifier - n_est 100 - max_depth None\n",
    "ModePath:models/RFClassifier - n_est 100 - max_depth None.pkl\n",
    "Predicting on files...\n",
    "Predicting on samples...\n",
    "Test accuracy - files : 0.9740740740740741\n",
    "Test accuracy - samples : 0.7995526496902959"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run_for_classifier\n",
    "Finished loading/creating features\n",
    "Using classifier RFClassifier - n_est 100 - max_depth None\n",
    "Training RFClassifier - n_est 100 - max_depth None\n",
    "Saved RFClassifier - n_est 100 - max_depth None\n",
    "ModePath:models/RFClassifier - n_est 100 - max_depth None.pkl\n",
    "Predicting on files...\n",
    "Predicting on samples...\n",
    "Test accuracy - files : 0.9839357429718876\n",
    "Test accuracy - samples : 0.8234393987128134"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_for_classifier\n",
      "Finished loading/creating features\n",
      "Using classifier RFClassifier - n_est 10 - max_depth None\n",
      "Training RFClassifier - n_est 10 - max_depth None\n",
      "Saved RFClassifier - n_est 10 - max_depth None\n",
      "ModePath:models/RFClassifier - n_est 10 - max_depth None.pkl\n",
      "Predicting on files...\n",
      "Predicting on samples...\n",
      "Test accuracy - files : 0.9717741935483871\n",
      "Test accuracy - samples : 0.7775365268919346\n"
     ]
    }
   ],
   "source": [
    "test_classifier(RFClassifier(n_estimators=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run_for_classifier\n",
    "Finished loading/creating features\n",
    "Using classifier RFClassifier - n_est 100 - max_depth None\n",
    "Training RFClassifier - n_est 100 - max_depth None\n",
    "Saved RFClassifier - n_est 100 - max_depth None\n",
    "ModePath:models/RFClassifier - n_est 100 - max_depth None.pkl\n",
    "Predicting on files...\n",
    "Predicting on samples...\n",
    "Test accuracy - files : 0.9873417721518988\n",
    "Test accuracy - samples : 0.8189973852673339"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_classifier(classifier : Classifier) -> None:\n",
    "    \"\"\"\n",
    "    Wrapper for method run_for_classifier.\n",
    "    :param classifier: The classifier to test\n",
    "    \"\"\"\n",
    "    one_d = not isinstance(classifier, CNNClassifier)\n",
    "    run_for_classifier(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_for_classifier(classifier: Classifier, one_d: bool = False, cv: int = None,\n",
    "                       train_set: np.ndarray = None,\n",
    "                       test_set: np.ndarray = None,\n",
    "                       save: bool = True,\n",
    "                       load: bool = True) -> None:\n",
    "    \"\"\"\n",
    "    Test a given classifier and print the results.\n",
    "    :param classifier: The classifier to test\n",
    "    :param one_d: If the features are to be flattened or not\n",
    "    :param cv: If >1, will run cross validation(on samples) with the given number of splits on the classifier\n",
    "    :param train_set: Optionally given to save time if run_for_classifier is called multiple times\n",
    "    :param test_set: Optionally given to save time if run_for_classifier is called multiple times\n",
    "    :param save: If the classifier is to be saved to a file\n",
    "    :param load: If the classifier is to be loaded from a file\n",
    "    \"\"\"\n",
    "    print(\"run_for_classifier..\")\n",
    "    #folder = \"data/TIMIT\"\n",
    "    #folder = \"predict_dir/DR5\"\n",
    "    folder = \"predict_dir/Test\"\n",
    "    #folder = \"data/TIMIT/TEST/DR5\"\n",
    "    if train_set is None or test_set is None:\n",
    "        features_with_label = files_to_features_with_labels(list_files(folder))\n",
    "        test_set = features_with_label\n",
    "    print(\"Finished loading/creating features\")\n",
    "    print(\"Using classifier \" + classifier.get_classifier_name())\n",
    "    classifier.load(MODELS_DIR + classifier.get_classifier_name() + DUMP_EXT)\n",
    "    print(\"ModePath:\"+MODELS_DIR + classifier.get_classifier_name() + DUMP_EXT)\n",
    "    print(\"Predicting on files...\")\n",
    "    predictions = []\n",
    "    test_labels = extract_labels(test_set)\n",
    "    for feat_label_tuple in test_set:\n",
    "        features = feat_label_tuple[0]        \n",
    "        results = classifier.predict(features)\n",
    "        predictions.append(return_majority(results))\n",
    "    predictions = np.asarray(predictions)\n",
    "    print(predictions)\n",
    "    print(test_labels)\n",
    "    if not os.path.isdir(OUTPUT_DIR):\n",
    "        os.mkdir(OUTPUT_DIR)\n",
    "    with open(OUTPUT_DIR + classifier.get_classifier_name() + \"_output.txt\", \"w\") as output_file:\n",
    "        output_file.writelines([str(pred) + \"\\n\" for pred in predictions])\n",
    "\n",
    "    # Per sample predictions\n",
    "    print(\"Predicting on samples...\")\n",
    "    if one_d:\n",
    "        transformed_test_set = to_1d(test_set)\n",
    "    else:\n",
    "        transformed_test_set = to_2d(test_set)\n",
    "\n",
    "    samples_features = extract_features(transformed_test_set)\n",
    "    samples_predictions = classifier.predict(samples_features)\n",
    "    samples_test_labels = extract_labels(transformed_test_set)\n",
    "    print(samples_predictions)\n",
    "    print(samples_test_labels)\n",
    "    #prediction = classMode.predict(samples_features)\n",
    "    #print(\"New Test accuracy - files : \" + str(get_accuracy(predictions, test_labels)))\n",
    "    print(\"Test accuracy - files : \" + str(get_accuracy(predictions, test_labels)))\n",
    "    print(\"Test accuracy - samples : \" + str(get_accuracy(samples_predictions, samples_test_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_for_classifier\n",
      "Finished loading/creating features\n",
      "Using classifier RFClassifier - n_est 100 - max_depth None\n",
      "Training RFClassifier - n_est 100 - max_depth None\n",
      "Saved RFClassifier - n_est 100 - max_depth None\n",
      "ModePath:models/RFClassifier - n_est 100 - max_depth None.pkl\n",
      "Predicting on files...\n",
      "Predicting on samples...\n",
      "Test accuracy - files : 0.9751243781094527\n",
      "Test accuracy - samples : 0.8437397305290831\n"
     ]
    }
   ],
   "source": [
    "test_classifier(RFClassifier(n_estimators=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_for_classifier..\n",
      "Finished loading/creating features\n",
      "Using classifier RFClassifier - n_est 100 - max_depth None\n",
      "ModePath:models/RFClassifier - n_est 100 - max_depth None.pkl\n",
      "Predicting on files...\n",
      "[1 1]\n",
      "[0 0]\n",
      "Predicting on samples...\n",
      "[1 1 1 ... 1 1 1]\n",
      "[0 0 0 ... 0 0 0]\n",
      "Test accuracy - files : 0.0\n",
      "Test accuracy - samples : 0.12033067973055726\n"
     ]
    }
   ],
   "source": [
    "test_classifier(RFClassifier(n_estimators=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminary informations\n",
    "##### Disclaimer : The neural networks results may vary a bit when re-training them due to some randomness in tensorflow-gpu / cuDNN.\n",
    "\n",
    "The models were trained on a computer with an i7-6700K, 16GB RAM and a GTX 1070.    \n",
    "The main libraries used are Keras with tensorflow backend, librosa, scikit-learn.    \n",
    "###### If you want to avoid retraining every classifier, set LOAD=True above. The RF with 100 estimators couldn't be pushed to the repository due to its file size though.\n",
    "\n",
    "Let's begin by explaining how to measure the performance of the classifiers. There are two main metrics :    \n",
    "- The sample accuracy : It's the accuracy for predicting the label of a sample of a file. For the CNN, it's a window of 10 samples.\n",
    "- The file accuracy : It's the accuracy for predicting the label of a file. The label is simply calculated by taking the most predicted label on all the samples of the file.\n",
    "\n",
    "The files were cut in samples of 20 MFCC features using the librosa library. This was mostly sufficient to allow the training on most of the classifiers. No preprocessing was done on the audio files or the MFCC features except normalizing them.    \n",
    "Some more preprocessing was done to allow the files to be fed to a CNN (cutting the files in windows).\n",
    "\n",
    "The files were separated in train set and test set using 80/20 proportions. There are 2703 files in total."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constant Classifier\n",
    "This classifier always predicts male."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_for_classifier\n",
      "Finished loading/creating features\n",
      "Using classifier ConstantClassifierTimit\n",
      "Training ConstantClassifierTimit\n",
      "Saved ConstantClassifierTimit\n",
      "ModePath:models/ConstantClassifierTimit.pkl\n",
      "Predicting on files...\n",
      "Predicting on samples...\n",
      "Test accuracy - files : 0.5021645021645021\n",
      "Test accuracy - samples : 0.45987015430937145\n"
     ]
    }
   ],
   "source": [
    "test_classifier(ConstantClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us some information on the files as well as a baseline :     \n",
    "- The files are distributed nearly uniformly between male and female\n",
    "- When taking duration into account, the files are distributed even more closely half male / half female\n",
    "\n",
    "This means that it is not really needed to perform balancing between the train and test set, assuming we distribute the files randomly between them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVC\n",
    "This classifier is created using SVM with a linear kernel. It could serve as another simple baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_for_classifier\n",
      "Finished loading/creating features\n",
      "Using classifier LinearClassifier - C1\n",
      "Training LinearClassifier - C1\n",
      "Saved LinearClassifier - C1\n",
      "ModePath:models/LinearClassifier - C1.pkl\n",
      "Predicting on files...\n",
      "Predicting on samples...\n",
      "Test accuracy - files : 0.9233870967741935\n",
      "Test accuracy - samples : 0.7227574976251866\n"
     ]
    }
   ],
   "source": [
    "test_classifier(LinearClassifier(c=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_for_classifier\n",
    "Finished loading/creating features\n",
    "Using classifier LinearClassifier - C1\n",
    "Training LinearClassifier - C1\n",
    "Saved LinearClassifier - C1\n",
    "ModePath:models/LinearClassifier - C1.pkl\n",
    "Predicting on files...\n",
    "Predicting on samples...\n",
    "Test accuracy - files : 0.9307359307359307\n",
    "Test accuracy - samples : 0.7412965750846819"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Here, the linear SVC returns quite mediocre results, having a file-accuracy of only 82%, and a worse sample accuracy of 70%.    \n",
    "Trying to increase the C parameter to 1000 makes the classifier not converge (or very slowly. When tested earlier, it hadn't converged in 10000 iterations).    \n",
    "It isn't surprising that a linear classifier would fail on this problem, as it is probably non-linear. Improving the preprocessing as well as doing features selection could improve the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_for_classifier\n",
      "Finished loading/creating features\n",
      "Using classifier LinearClassifier - C1000\n",
      "Training LinearClassifier - C1000\n",
      "Saved LinearClassifier - C1000\n",
      "ModePath:models/LinearClassifier - C1000.pkl\n",
      "Predicting on files...\n",
      "Predicting on samples...\n",
      "Test accuracy - files : 0.5604838709677419\n",
      "Test accuracy - samples : 0.6452254941873614\n"
     ]
    }
   ],
   "source": [
    "test_classifier(LinearClassifier(c=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_for_classifier\n",
    "Finished loading/creating features\n",
    "Using classifier LinearClassifier - C1000\n",
    "Training LinearClassifier - C1000\n",
    "Saved LinearClassifier - C1000\n",
    "ModePath:models/LinearClassifier - C1000.pkl\n",
    "Predicting on files...\n",
    "Predicting on samples...\n",
    "Test accuracy - files : 0.5021645021645021\n",
    "Test accuracy - samples : 0.48367519759126837"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestClassifier\n",
    "Let's test RandomForestClassifiers, which are known to be quite accurate when features are well-defined and results are dependent on these features, which should be the case with the MFCC features and the speaker's gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_for_classifier\n",
      "Finished loading/creating features\n",
      "Using classifier RFClassifier - n_est 10 - max_depth None\n",
      "Training RFClassifier - n_est 10 - max_depth None\n",
      "Saved RFClassifier - n_est 10 - max_depth None\n",
      "ModePath:models/RFClassifier - n_est 10 - max_depth None.pkl\n",
      "Predicting on files...\n",
      "Predicting on samples...\n",
      "Test accuracy - files : 0.9800995024875622\n",
      "Test accuracy - samples : 0.8138898017307482\n"
     ]
    }
   ],
   "source": [
    "test_classifier(RFClassifier(n_estimators=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we can already see that the files accuracy is nearly perfect (in fact, only 1 file is mispredicted). The sample accuracy could be better though.    \n",
    "Let's try to improve it by increasing the number of trees. We may also get a 100% file accuracy by doing this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_for_classifier\n",
      "Finished loading/creating features\n",
      "Using classifier RFClassifier - n_est 100 - max_depth None\n",
      "Training RFClassifier - n_est 100 - max_depth None\n",
      "Saved RFClassifier - n_est 100 - max_depth None\n",
      "ModePath:models/RFClassifier - n_est 100 - max_depth None.pkl\n",
      "Predicting on files...\n",
      "Predicting on samples...\n",
      "Test accuracy - files : 0.9914529914529915\n",
      "Test accuracy - samples : 0.836785648233771\n"
     ]
    }
   ],
   "source": [
    "test_classifier(RFClassifier(n_estimators=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It doesn't seem to improve much and isn't really worth it given the increase in memory and time consumption. It is better, as expected (averaging over more votes should lead to a better result), but not needed for the files accuracy.    \n",
    "Let's try with 1 and 5 trees to see if we can go lower than 10 while preserving the accuracy :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_for_classifier\n",
      "Finished loading/creating features\n",
      "Using classifier RFClassifier - n_est 5 - max_depth None\n",
      "Training RFClassifier - n_est 5 - max_depth None\n",
      "Saved RFClassifier - n_est 5 - max_depth None\n",
      "ModePath:models/RFClassifier - n_est 5 - max_depth None.pkl\n",
      "Predicting on files...\n",
      "Predicting on samples...\n",
      "Test accuracy - files : 0.9786184210526315\n",
      "Test accuracy - samples : 0.7906561882262186\n",
      "\n",
      "\n",
      "run_for_classifier\n",
      "Finished loading/creating features\n",
      "Using classifier RFClassifier - n_est 1 - max_depth None\n",
      "Training RFClassifier - n_est 1 - max_depth None\n",
      "Saved RFClassifier - n_est 1 - max_depth None\n",
      "ModePath:models/RFClassifier - n_est 1 - max_depth None.pkl\n",
      "Predicting on files...\n",
      "Predicting on samples...\n",
      "Test accuracy - files : 0.9671052631578947\n",
      "Test accuracy - samples : 0.7200231425678607\n"
     ]
    }
   ],
   "source": [
    "test_classifier(RFClassifier(n_estimators=5))\n",
    "print(\"\\n\")\n",
    "test_classifier(RFClassifier(n_estimators=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run_for_classifier\n",
    "Finished loading/creating features\n",
    "Using classifier RFClassifier - n_est 5 - max_depth None\n",
    "Training RFClassifier - n_est 5 - max_depth None\n",
    "Saved RFClassifier - n_est 5 - max_depth None\n",
    "ModePath:models/RFClassifier - n_est 5 - max_depth None.pkl\n",
    "Predicting on files...\n",
    "Predicting on samples...\n",
    "Test accuracy - files : 0.9434628975265018\n",
    "Test accuracy - samples : 0.7369559123853762\n",
    "\n",
    "\n",
    "run_for_classifier\n",
    "Finished loading/creating features\n",
    "Using classifier RFClassifier - n_est 1 - max_depth None\n",
    "Training RFClassifier - n_est 1 - max_depth None\n",
    "Saved RFClassifier - n_est 1 - max_depth None\n",
    "ModePath:models/RFClassifier - n_est 1 - max_depth None.pkl\n",
    "Predicting on files...\n",
    "Predicting on samples...\n",
    "Test accuracy - files : 0.950530035335689\n",
    "Test accuracy - samples : 0.6760501341448765"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run_for_classifier\n",
    "Finished loading/creating features\n",
    "Using classifier RFClassifier - n_est 5 - max_depth None\n",
    "Training RFClassifier - n_est 5 - max_depth None\n",
    "Saved RFClassifier - n_est 5 - max_depth None\n",
    "ModePath:models/RFClassifier - n_est 5 - max_depth None.pkl\n",
    "Predicting on files...\n",
    "Predicting on samples...\n",
    "Test accuracy - files : 0.974025974025974\n",
    "Test accuracy - samples : 0.7659013925479865\n",
    "\n",
    "\n",
    "run_for_classifier\n",
    "Finished loading/creating features\n",
    "Using classifier RFClassifier - n_est 1 - max_depth None\n",
    "Training RFClassifier - n_est 1 - max_depth None\n",
    "Saved RFClassifier - n_est 1 - max_depth None\n",
    "ModePath:models/RFClassifier - n_est 1 - max_depth None.pkl\n",
    "Predicting on files...\n",
    "Predicting on samples...\n",
    "Test accuracy - files : 0.987012987012987\n",
    "Test accuracy - samples : 0.7046010538200979"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strangely enough, we get a really good result with even only one tree. The sample accuracy decreases quite a bit obviously, but the file accuracy is still very good. This means that there are features which are very relevant to finding the speaker's gender.   \n",
    "With 5 trees, the file accuracy is the same as the one with 10 trees.    \n",
    "The RandomForest seems to be very well suited for this problem, as expected. What was less expected was that such a performance was obtained using a very small number of estimators.    \n",
    "RandomForest is therefore a very efficient and easy way to solve this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shallow Neural Network\n",
    "Let's try using a shallow neural network with only a single fully-connected hidden layer.    \n",
    "In theory, such a simple neural net should be able to approximate every function perfectly, but in practice, a deep neural network usually yields better results than a wide one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_for_classifier\n",
      "Finished loading/creating features\n",
      "Using classifier SNNClassifier - units 64\n",
      "Training SNNClassifier - units 64\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 64)                1344      \n",
      "_________________________________________________________________\n",
      "p_re_lu_1 (PReLU)            (None, 64)                64        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,473\n",
      "Trainable params: 1,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 81080 samples, validate on 20270 samples\n",
      "Epoch 1/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.6258 - acc: 0.6486 - val_loss: 0.6057 - val_acc: 0.6509\n",
      "Epoch 2/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.5648 - acc: 0.6911 - val_loss: 0.5731 - val_acc: 0.6772\n",
      "Epoch 3/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.5354 - acc: 0.7116 - val_loss: 0.5562 - val_acc: 0.6906\n",
      "Epoch 4/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.5135 - acc: 0.7280 - val_loss: 0.5684 - val_acc: 0.6757\n",
      "Epoch 5/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.5007 - acc: 0.7365 - val_loss: 0.5329 - val_acc: 0.7185\n",
      "Epoch 6/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4914 - acc: 0.7407 - val_loss: 0.5257 - val_acc: 0.7252\n",
      "Epoch 7/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4850 - acc: 0.7460 - val_loss: 0.5274 - val_acc: 0.7144\n",
      "Epoch 8/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4796 - acc: 0.7483 - val_loss: 0.5145 - val_acc: 0.7293\n",
      "Epoch 9/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4753 - acc: 0.7517 - val_loss: 0.5129 - val_acc: 0.7312\n",
      "Epoch 10/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4713 - acc: 0.7544 - val_loss: 0.5239 - val_acc: 0.7118\n",
      "Epoch 11/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4681 - acc: 0.7580 - val_loss: 0.5085 - val_acc: 0.7326\n",
      "Epoch 12/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4650 - acc: 0.7602 - val_loss: 0.5136 - val_acc: 0.7269\n",
      "Epoch 13/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4619 - acc: 0.7629 - val_loss: 0.5007 - val_acc: 0.7442\n",
      "Epoch 14/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4600 - acc: 0.7618 - val_loss: 0.5112 - val_acc: 0.7246\n",
      "Epoch 15/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4573 - acc: 0.7645 - val_loss: 0.4975 - val_acc: 0.7482\n",
      "Epoch 16/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4550 - acc: 0.7666 - val_loss: 0.5093 - val_acc: 0.7291\n",
      "Epoch 17/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4531 - acc: 0.7676 - val_loss: 0.5048 - val_acc: 0.7294\n",
      "Epoch 18/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4511 - acc: 0.7692 - val_loss: 0.4957 - val_acc: 0.7451\n",
      "Epoch 19/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4493 - acc: 0.7698 - val_loss: 0.4946 - val_acc: 0.7433\n",
      "Epoch 20/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4479 - acc: 0.7706 - val_loss: 0.4895 - val_acc: 0.7529\n",
      "Epoch 21/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4457 - acc: 0.7725 - val_loss: 0.4867 - val_acc: 0.7519\n",
      "Epoch 22/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4443 - acc: 0.7723 - val_loss: 0.4898 - val_acc: 0.7499\n",
      "Epoch 23/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4427 - acc: 0.7751 - val_loss: 0.4963 - val_acc: 0.7381\n",
      "Epoch 24/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4421 - acc: 0.7732 - val_loss: 0.4923 - val_acc: 0.7456\n",
      "Epoch 25/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4397 - acc: 0.7764 - val_loss: 0.4848 - val_acc: 0.7532\n",
      "Epoch 26/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4392 - acc: 0.7760 - val_loss: 0.4894 - val_acc: 0.7427\n",
      "Epoch 27/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4378 - acc: 0.7776 - val_loss: 0.4892 - val_acc: 0.7462\n",
      "Epoch 28/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4366 - acc: 0.7790 - val_loss: 0.4817 - val_acc: 0.7587\n",
      "Epoch 29/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4361 - acc: 0.7786 - val_loss: 0.4856 - val_acc: 0.7496\n",
      "Epoch 30/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4352 - acc: 0.7781 - val_loss: 0.4903 - val_acc: 0.7467\n",
      "Epoch 31/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4344 - acc: 0.7793 - val_loss: 0.4811 - val_acc: 0.7600\n",
      "Epoch 32/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4329 - acc: 0.7795 - val_loss: 0.4802 - val_acc: 0.7561\n",
      "Epoch 33/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4317 - acc: 0.7798 - val_loss: 0.4789 - val_acc: 0.7598\n",
      "Epoch 34/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4305 - acc: 0.7821 - val_loss: 0.4780 - val_acc: 0.7604\n",
      "Epoch 35/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4302 - acc: 0.7810 - val_loss: 0.4810 - val_acc: 0.7575\n",
      "Epoch 36/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4288 - acc: 0.7833 - val_loss: 0.4792 - val_acc: 0.7539\n",
      "Epoch 37/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4279 - acc: 0.7831 - val_loss: 0.4798 - val_acc: 0.7574\n",
      "Epoch 38/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4274 - acc: 0.7837 - val_loss: 0.4757 - val_acc: 0.7621\n",
      "Epoch 39/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4267 - acc: 0.7836 - val_loss: 0.4750 - val_acc: 0.7616\n",
      "Epoch 40/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4263 - acc: 0.7844 - val_loss: 0.4842 - val_acc: 0.7476\n",
      "Epoch 41/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4255 - acc: 0.7853 - val_loss: 0.5003 - val_acc: 0.7317\n",
      "Epoch 42/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4243 - acc: 0.7859 - val_loss: 0.4848 - val_acc: 0.7447\n",
      "Epoch 43/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4231 - acc: 0.7871 - val_loss: 0.4841 - val_acc: 0.7475\n",
      "Epoch 44/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4231 - acc: 0.7877 - val_loss: 0.4837 - val_acc: 0.7491\n",
      "Epoch 45/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4223 - acc: 0.7879 - val_loss: 0.4798 - val_acc: 0.7483\n",
      "Epoch 46/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4220 - acc: 0.7865 - val_loss: 0.4984 - val_acc: 0.7354\n",
      "Epoch 47/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4197 - acc: 0.7901 - val_loss: 0.4727 - val_acc: 0.7589\n",
      "Epoch 48/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4209 - acc: 0.7884 - val_loss: 0.4897 - val_acc: 0.7422\n",
      "Epoch 49/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4200 - acc: 0.7887 - val_loss: 0.4728 - val_acc: 0.7600\n",
      "Epoch 50/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4193 - acc: 0.7904 - val_loss: 0.4809 - val_acc: 0.7499\n",
      "Epoch 51/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4190 - acc: 0.7892 - val_loss: 0.4739 - val_acc: 0.7581\n",
      "Epoch 52/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4185 - acc: 0.7897 - val_loss: 0.4752 - val_acc: 0.7559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4174 - acc: 0.7905 - val_loss: 0.4669 - val_acc: 0.7653\n",
      "Epoch 54/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4170 - acc: 0.7915 - val_loss: 0.4671 - val_acc: 0.7626\n",
      "Epoch 55/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4158 - acc: 0.7920 - val_loss: 0.4705 - val_acc: 0.7571\n",
      "Epoch 56/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4159 - acc: 0.7906 - val_loss: 0.4784 - val_acc: 0.7485\n",
      "Epoch 57/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4153 - acc: 0.7925 - val_loss: 0.4749 - val_acc: 0.7564\n",
      "Epoch 58/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4148 - acc: 0.7909 - val_loss: 0.4718 - val_acc: 0.7556\n",
      "Epoch 59/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4145 - acc: 0.7908 - val_loss: 0.4712 - val_acc: 0.7560\n",
      "Epoch 60/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4135 - acc: 0.7928 - val_loss: 0.4652 - val_acc: 0.7628\n",
      "Epoch 61/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4140 - acc: 0.7911 - val_loss: 0.4892 - val_acc: 0.7413\n",
      "Epoch 62/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4125 - acc: 0.7930 - val_loss: 0.4681 - val_acc: 0.7577\n",
      "Epoch 63/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4117 - acc: 0.7942 - val_loss: 0.4745 - val_acc: 0.7529\n",
      "Epoch 64/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4120 - acc: 0.7941 - val_loss: 0.4962 - val_acc: 0.7341\n",
      "Epoch 65/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4123 - acc: 0.7934 - val_loss: 0.4663 - val_acc: 0.7625\n",
      "Epoch 66/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4112 - acc: 0.7948 - val_loss: 0.4624 - val_acc: 0.7639\n",
      "Epoch 67/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4092 - acc: 0.7959 - val_loss: 0.4638 - val_acc: 0.7617\n",
      "Epoch 68/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4095 - acc: 0.7944 - val_loss: 0.4608 - val_acc: 0.7667\n",
      "Epoch 69/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4090 - acc: 0.7954 - val_loss: 0.4719 - val_acc: 0.7603\n",
      "Epoch 70/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4093 - acc: 0.7947 - val_loss: 0.4625 - val_acc: 0.7652\n",
      "Epoch 71/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4082 - acc: 0.7962 - val_loss: 0.4649 - val_acc: 0.7621\n",
      "Epoch 72/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4082 - acc: 0.7962 - val_loss: 0.4589 - val_acc: 0.7656\n",
      "Epoch 73/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4072 - acc: 0.7971 - val_loss: 0.4557 - val_acc: 0.7699\n",
      "Epoch 74/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4072 - acc: 0.7966 - val_loss: 0.4624 - val_acc: 0.7645\n",
      "Epoch 75/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4074 - acc: 0.7967 - val_loss: 0.4606 - val_acc: 0.7655\n",
      "Epoch 76/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4059 - acc: 0.7969 - val_loss: 0.4650 - val_acc: 0.7647\n",
      "Epoch 77/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4064 - acc: 0.7967 - val_loss: 0.4601 - val_acc: 0.7656\n",
      "Epoch 78/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4055 - acc: 0.7974 - val_loss: 0.4563 - val_acc: 0.7688\n",
      "Epoch 79/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4049 - acc: 0.7984 - val_loss: 0.4595 - val_acc: 0.7652\n",
      "Epoch 80/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4045 - acc: 0.7973 - val_loss: 0.4584 - val_acc: 0.7633\n",
      "Epoch 81/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4045 - acc: 0.7991 - val_loss: 0.4679 - val_acc: 0.7597\n",
      "Epoch 82/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4038 - acc: 0.7998 - val_loss: 0.4662 - val_acc: 0.7634\n",
      "Epoch 83/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4038 - acc: 0.7991 - val_loss: 0.4595 - val_acc: 0.7655\n",
      "\n",
      "Epoch 00083: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 84/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3971 - acc: 0.8046 - val_loss: 0.4566 - val_acc: 0.7697\n",
      "Epoch 85/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3964 - acc: 0.8046 - val_loss: 0.4556 - val_acc: 0.7699\n",
      "Epoch 86/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3961 - acc: 0.8041 - val_loss: 0.4546 - val_acc: 0.7703\n",
      "Epoch 87/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3961 - acc: 0.8049 - val_loss: 0.4543 - val_acc: 0.7710\n",
      "Epoch 88/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3961 - acc: 0.8047 - val_loss: 0.4551 - val_acc: 0.7694\n",
      "Epoch 89/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3961 - acc: 0.8046 - val_loss: 0.4581 - val_acc: 0.7678\n",
      "Epoch 90/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3959 - acc: 0.8054 - val_loss: 0.4586 - val_acc: 0.7687\n",
      "Epoch 91/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3959 - acc: 0.8051 - val_loss: 0.4551 - val_acc: 0.7714\n",
      "Epoch 92/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3959 - acc: 0.8052 - val_loss: 0.4543 - val_acc: 0.7704\n",
      "Epoch 93/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3958 - acc: 0.8056 - val_loss: 0.4553 - val_acc: 0.7699\n",
      "Epoch 94/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3958 - acc: 0.8044 - val_loss: 0.4578 - val_acc: 0.7681\n",
      "Epoch 95/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3957 - acc: 0.8044 - val_loss: 0.4559 - val_acc: 0.7687\n",
      "Epoch 96/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3956 - acc: 0.8053 - val_loss: 0.4527 - val_acc: 0.7716\n",
      "Epoch 97/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3956 - acc: 0.8052 - val_loss: 0.4591 - val_acc: 0.7670\n",
      "Epoch 98/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3955 - acc: 0.8058 - val_loss: 0.4561 - val_acc: 0.7684\n",
      "Epoch 99/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3954 - acc: 0.8053 - val_loss: 0.4573 - val_acc: 0.7693\n",
      "Epoch 100/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3956 - acc: 0.8053 - val_loss: 0.4531 - val_acc: 0.7713\n",
      "Epoch 101/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3956 - acc: 0.8052 - val_loss: 0.4580 - val_acc: 0.7667\n",
      "Epoch 102/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3955 - acc: 0.8055 - val_loss: 0.4562 - val_acc: 0.7696\n",
      "Epoch 103/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3954 - acc: 0.8045 - val_loss: 0.4574 - val_acc: 0.7680\n",
      "Epoch 104/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3954 - acc: 0.8056 - val_loss: 0.4564 - val_acc: 0.7693\n",
      "Epoch 105/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3953 - acc: 0.8058 - val_loss: 0.4618 - val_acc: 0.7650\n",
      "Epoch 106/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3953 - acc: 0.8044 - val_loss: 0.4559 - val_acc: 0.7691\n",
      "\n",
      "Epoch 00106: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 107/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3944 - acc: 0.8059 - val_loss: 0.4553 - val_acc: 0.7708\n",
      "Epoch 108/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3944 - acc: 0.8060 - val_loss: 0.4557 - val_acc: 0.7702\n",
      "Epoch 109/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3943 - acc: 0.8062 - val_loss: 0.4564 - val_acc: 0.7697\n",
      "Epoch 110/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3943 - acc: 0.8063 - val_loss: 0.4561 - val_acc: 0.7700\n",
      "Epoch 111/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3943 - acc: 0.8058 - val_loss: 0.4560 - val_acc: 0.7700\n",
      "Epoch 00111: early stopping\n",
      "Saved SNNClassifier - units 64\n",
      "ModePath:models/SNNClassifier - units 64.pkl\n",
      "Predicting on files...\n",
      "Predicting on samples...\n",
      "Test accuracy - files : 0.9540636042402827\n",
      "Test accuracy - samples : 0.7851279381732271\n"
     ]
    }
   ],
   "source": [
    "test_classifier(SNNClassifier(num_units=64, verbose=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test accuracy - files : 0.9800995024875622\n",
    "Test accuracy - samples : 0.8527768649359185"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already get a nearly perfect accuracy for files, which is very impressive with only 64 units. This probably means that the function to approximate / the problem is not really complex, but still non-linear.    \n",
    "Let's try to improve the accuracy by increasing the number of units in the dense layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_for_classifier\n",
      "Finished loading/creating features\n",
      "Using classifier SNNClassifier - units 128\n",
      "Training SNNClassifier - units 128\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 128)               2688      \n",
      "_________________________________________________________________\n",
      "p_re_lu_2 (PReLU)            (None, 128)               128       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 129       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 2,945\n",
      "Trainable params: 2,945\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 81080 samples, validate on 20270 samples\n",
      "Epoch 1/300\n",
      "81080/81080 [==============================] - 1s 10us/step - loss: 0.6150 - acc: 0.6531 - val_loss: 0.6117 - val_acc: 0.6460\n",
      "Epoch 2/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.5595 - acc: 0.6923 - val_loss: 0.5691 - val_acc: 0.6801\n",
      "Epoch 3/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.5279 - acc: 0.7159 - val_loss: 0.5498 - val_acc: 0.6915\n",
      "Epoch 4/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.5039 - acc: 0.7331 - val_loss: 0.5405 - val_acc: 0.6937\n",
      "Epoch 5/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4898 - acc: 0.7410 - val_loss: 0.5264 - val_acc: 0.7138\n",
      "Epoch 6/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4808 - acc: 0.7468 - val_loss: 0.5254 - val_acc: 0.7124\n",
      "Epoch 7/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.4744 - acc: 0.7503 - val_loss: 0.5228 - val_acc: 0.7117\n",
      "Epoch 8/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.4693 - acc: 0.7543 - val_loss: 0.5100 - val_acc: 0.7346\n",
      "Epoch 9/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4643 - acc: 0.7581 - val_loss: 0.5091 - val_acc: 0.7305\n",
      "Epoch 10/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4605 - acc: 0.7604 - val_loss: 0.5004 - val_acc: 0.7449\n",
      "Epoch 11/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4579 - acc: 0.7616 - val_loss: 0.5074 - val_acc: 0.7373\n",
      "Epoch 12/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4546 - acc: 0.7640 - val_loss: 0.5074 - val_acc: 0.7281\n",
      "Epoch 13/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4504 - acc: 0.7675 - val_loss: 0.4998 - val_acc: 0.7403\n",
      "Epoch 14/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4487 - acc: 0.7686 - val_loss: 0.4945 - val_acc: 0.7491\n",
      "Epoch 15/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.4466 - acc: 0.7710 - val_loss: 0.5027 - val_acc: 0.7354\n",
      "Epoch 16/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.4441 - acc: 0.7723 - val_loss: 0.4917 - val_acc: 0.7479\n",
      "Epoch 17/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.4410 - acc: 0.7738 - val_loss: 0.4851 - val_acc: 0.7511\n",
      "Epoch 18/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.4396 - acc: 0.7755 - val_loss: 0.4931 - val_acc: 0.7446\n",
      "Epoch 19/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4372 - acc: 0.7766 - val_loss: 0.4819 - val_acc: 0.7510\n",
      "Epoch 20/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.4360 - acc: 0.7769 - val_loss: 0.4789 - val_acc: 0.7533\n",
      "Epoch 21/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.4337 - acc: 0.7784 - val_loss: 0.4909 - val_acc: 0.7443\n",
      "Epoch 22/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.4325 - acc: 0.7801 - val_loss: 0.4896 - val_acc: 0.7419\n",
      "Epoch 23/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.4308 - acc: 0.7814 - val_loss: 0.4814 - val_acc: 0.7576\n",
      "Epoch 24/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.4296 - acc: 0.7809 - val_loss: 0.4821 - val_acc: 0.7453\n",
      "Epoch 25/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.4275 - acc: 0.7834 - val_loss: 0.4830 - val_acc: 0.7445\n",
      "Epoch 26/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.4266 - acc: 0.7838 - val_loss: 0.4852 - val_acc: 0.7441\n",
      "Epoch 27/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.4238 - acc: 0.7872 - val_loss: 0.4866 - val_acc: 0.7394\n",
      "Epoch 28/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.4233 - acc: 0.7860 - val_loss: 0.4735 - val_acc: 0.7566\n",
      "Epoch 29/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.4223 - acc: 0.7855 - val_loss: 0.4664 - val_acc: 0.7670\n",
      "Epoch 30/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.4213 - acc: 0.7870 - val_loss: 0.4680 - val_acc: 0.7574\n",
      "Epoch 31/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.4188 - acc: 0.7881 - val_loss: 0.4694 - val_acc: 0.7570\n",
      "Epoch 32/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.4186 - acc: 0.7897 - val_loss: 0.4750 - val_acc: 0.7508\n",
      "Epoch 33/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.4179 - acc: 0.7882 - val_loss: 0.4660 - val_acc: 0.7663\n",
      "Epoch 34/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.4166 - acc: 0.7887 - val_loss: 0.4701 - val_acc: 0.7603\n",
      "Epoch 35/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.4145 - acc: 0.7915 - val_loss: 0.4758 - val_acc: 0.7500\n",
      "Epoch 36/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.4144 - acc: 0.7909 - val_loss: 0.4635 - val_acc: 0.7630\n",
      "Epoch 37/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.4130 - acc: 0.7922 - val_loss: 0.4671 - val_acc: 0.7607\n",
      "Epoch 38/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.4118 - acc: 0.7938 - val_loss: 0.4651 - val_acc: 0.7599\n",
      "Epoch 39/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.4107 - acc: 0.7943 - val_loss: 0.4628 - val_acc: 0.7627\n",
      "Epoch 40/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.4111 - acc: 0.7923 - val_loss: 0.4683 - val_acc: 0.7555\n",
      "Epoch 41/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.4092 - acc: 0.7949 - val_loss: 0.4554 - val_acc: 0.7691\n",
      "Epoch 42/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.4089 - acc: 0.7951 - val_loss: 0.4656 - val_acc: 0.7642\n",
      "Epoch 43/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.4079 - acc: 0.7961 - val_loss: 0.4564 - val_acc: 0.7711\n",
      "Epoch 44/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.4064 - acc: 0.7964 - val_loss: 0.4666 - val_acc: 0.7543\n",
      "Epoch 45/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.4056 - acc: 0.7969 - val_loss: 0.4648 - val_acc: 0.7618\n",
      "Epoch 46/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.4046 - acc: 0.7977 - val_loss: 0.4517 - val_acc: 0.7728\n",
      "Epoch 47/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.4049 - acc: 0.7969 - val_loss: 0.4650 - val_acc: 0.7581\n",
      "Epoch 48/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.4034 - acc: 0.7980 - val_loss: 0.4564 - val_acc: 0.7651\n",
      "Epoch 49/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.4030 - acc: 0.7988 - val_loss: 0.4724 - val_acc: 0.7538\n",
      "Epoch 50/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.4027 - acc: 0.7986 - val_loss: 0.4543 - val_acc: 0.7734\n",
      "Epoch 51/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.4010 - acc: 0.8017 - val_loss: 0.4681 - val_acc: 0.7546\n",
      "Epoch 52/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.4005 - acc: 0.8018 - val_loss: 0.4501 - val_acc: 0.7719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.4003 - acc: 0.7996 - val_loss: 0.4506 - val_acc: 0.7684\n",
      "Epoch 54/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.4000 - acc: 0.7994 - val_loss: 0.4606 - val_acc: 0.7624\n",
      "Epoch 55/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3995 - acc: 0.8012 - val_loss: 0.4571 - val_acc: 0.7667\n",
      "Epoch 56/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3974 - acc: 0.8023 - val_loss: 0.4561 - val_acc: 0.7699\n",
      "Epoch 57/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3974 - acc: 0.8027 - val_loss: 0.4624 - val_acc: 0.7614\n",
      "Epoch 58/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3965 - acc: 0.8028 - val_loss: 0.4523 - val_acc: 0.7662\n",
      "Epoch 59/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3958 - acc: 0.8034 - val_loss: 0.4552 - val_acc: 0.7709\n",
      "Epoch 60/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3964 - acc: 0.8027 - val_loss: 0.4526 - val_acc: 0.7734\n",
      "Epoch 61/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.3944 - acc: 0.8047 - val_loss: 0.4635 - val_acc: 0.7573\n",
      "Epoch 62/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3944 - acc: 0.8039 - val_loss: 0.4729 - val_acc: 0.7515\n",
      "\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 63/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.3850 - acc: 0.8108 - val_loss: 0.4479 - val_acc: 0.7719\n",
      "Epoch 64/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.3838 - acc: 0.8117 - val_loss: 0.4476 - val_acc: 0.7727\n",
      "Epoch 65/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3834 - acc: 0.8129 - val_loss: 0.4433 - val_acc: 0.7750\n",
      "Epoch 66/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.3834 - acc: 0.8129 - val_loss: 0.4481 - val_acc: 0.7725\n",
      "Epoch 67/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.3832 - acc: 0.8130 - val_loss: 0.4429 - val_acc: 0.7761\n",
      "Epoch 68/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3833 - acc: 0.8124 - val_loss: 0.4444 - val_acc: 0.7753\n",
      "Epoch 69/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.3830 - acc: 0.8129 - val_loss: 0.4473 - val_acc: 0.7720\n",
      "Epoch 70/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3832 - acc: 0.8125 - val_loss: 0.4433 - val_acc: 0.7758\n",
      "Epoch 71/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.3831 - acc: 0.8132 - val_loss: 0.4467 - val_acc: 0.7728\n",
      "Epoch 72/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.3829 - acc: 0.8130 - val_loss: 0.4429 - val_acc: 0.7764\n",
      "Epoch 73/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3828 - acc: 0.8130 - val_loss: 0.4425 - val_acc: 0.7787\n",
      "Epoch 74/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3827 - acc: 0.8131 - val_loss: 0.4466 - val_acc: 0.7740\n",
      "Epoch 75/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3826 - acc: 0.8139 - val_loss: 0.4451 - val_acc: 0.7759\n",
      "Epoch 76/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3824 - acc: 0.8137 - val_loss: 0.4474 - val_acc: 0.7716\n",
      "Epoch 77/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3823 - acc: 0.8132 - val_loss: 0.4472 - val_acc: 0.7735\n",
      "Epoch 78/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3821 - acc: 0.8134 - val_loss: 0.4476 - val_acc: 0.7739\n",
      "Epoch 79/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3823 - acc: 0.8133 - val_loss: 0.4477 - val_acc: 0.7728\n",
      "Epoch 80/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3820 - acc: 0.8133 - val_loss: 0.4456 - val_acc: 0.7754\n",
      "Epoch 81/300\n",
      "81080/81080 [==============================] - 1s 9us/step - loss: 0.3819 - acc: 0.8142 - val_loss: 0.4441 - val_acc: 0.7756\n",
      "Epoch 82/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3817 - acc: 0.8135 - val_loss: 0.4427 - val_acc: 0.7758\n",
      "Epoch 83/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3819 - acc: 0.8136 - val_loss: 0.4428 - val_acc: 0.7765\n",
      "\n",
      "Epoch 00083: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 84/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3806 - acc: 0.8149 - val_loss: 0.4434 - val_acc: 0.7759\n",
      "Epoch 85/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3805 - acc: 0.8153 - val_loss: 0.4434 - val_acc: 0.7761\n",
      "Epoch 86/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3804 - acc: 0.8151 - val_loss: 0.4424 - val_acc: 0.7763\n",
      "Epoch 87/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3804 - acc: 0.8153 - val_loss: 0.4437 - val_acc: 0.7763\n",
      "Epoch 88/300\n",
      "81080/81080 [==============================] - 1s 8us/step - loss: 0.3804 - acc: 0.8151 - val_loss: 0.4442 - val_acc: 0.7763\n",
      "Epoch 00088: early stopping\n",
      "Saved SNNClassifier - units 128\n",
      "ModePath:models/SNNClassifier - units 128.pkl\n",
      "Predicting on files...\n",
      "Predicting on samples...\n",
      "Test accuracy - files : 0.9646643109540636\n",
      "Test accuracy - samples : 0.7918952468666159\n"
     ]
    }
   ],
   "source": [
    "test_classifier(SNNClassifier(num_units=128, verbose=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the sample accuracy is ~1% better, and the file accuracy is now perfect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading/creating features\n",
      "Using classifier SNNClassifier - units 256\n",
      "Training SNNClassifier - units 256\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 256)               5376      \n",
      "_________________________________________________________________\n",
      "p_re_lu_3 (PReLU)            (None, 256)               256       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 5,889\n",
      "Trainable params: 5,889\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 384480 samples, validate on 96121 samples\n",
      "Epoch 1/300\n",
      "384480/384480 [==============================] - 4s 9us/step - loss: 0.5089 - acc: 0.7378 - val_loss: 0.4492 - val_acc: 0.7834\n",
      "Epoch 2/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.4241 - acc: 0.7948 - val_loss: 0.4121 - val_acc: 0.8089\n",
      "Epoch 3/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.3963 - acc: 0.8125 - val_loss: 0.3936 - val_acc: 0.8153\n",
      "Epoch 4/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.3800 - acc: 0.8220 - val_loss: 0.3745 - val_acc: 0.8294\n",
      "Epoch 5/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.3691 - acc: 0.8278 - val_loss: 0.3681 - val_acc: 0.8321\n",
      "Epoch 6/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.3607 - acc: 0.8322 - val_loss: 0.3605 - val_acc: 0.8381\n",
      "Epoch 7/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.3546 - acc: 0.8350 - val_loss: 0.3504 - val_acc: 0.8434\n",
      "Epoch 8/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.3490 - acc: 0.8383 - val_loss: 0.3573 - val_acc: 0.8357\n",
      "Epoch 9/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.3440 - acc: 0.8413 - val_loss: 0.3546 - val_acc: 0.8352\n",
      "Epoch 10/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.3404 - acc: 0.8433 - val_loss: 0.3384 - val_acc: 0.8497\n",
      "Epoch 11/300\n",
      "384480/384480 [==============================] - 4s 9us/step - loss: 0.3363 - acc: 0.8452 - val_loss: 0.3525 - val_acc: 0.8353\n",
      "Epoch 12/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.3327 - acc: 0.8476 - val_loss: 0.3438 - val_acc: 0.8412\n",
      "Epoch 13/300\n",
      "384480/384480 [==============================] - 4s 9us/step - loss: 0.3291 - acc: 0.8495 - val_loss: 0.3361 - val_acc: 0.8519\n",
      "Epoch 14/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.3265 - acc: 0.8507 - val_loss: 0.3259 - val_acc: 0.8570\n",
      "Epoch 15/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.3238 - acc: 0.8521 - val_loss: 0.3306 - val_acc: 0.8522\n",
      "Epoch 16/300\n",
      "384480/384480 [==============================] - 4s 9us/step - loss: 0.3214 - acc: 0.8536 - val_loss: 0.3241 - val_acc: 0.8559\n",
      "Epoch 17/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.3179 - acc: 0.8560 - val_loss: 0.3402 - val_acc: 0.8437\n",
      "Epoch 18/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.3159 - acc: 0.8562 - val_loss: 0.3276 - val_acc: 0.8518\n",
      "Epoch 19/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.3145 - acc: 0.8569 - val_loss: 0.3228 - val_acc: 0.8563\n",
      "Epoch 20/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.3118 - acc: 0.8584 - val_loss: 0.3191 - val_acc: 0.8609\n",
      "Epoch 21/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.3096 - acc: 0.8600 - val_loss: 0.3318 - val_acc: 0.8493\n",
      "Epoch 22/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.3076 - acc: 0.8612 - val_loss: 0.3407 - val_acc: 0.8447\n",
      "Epoch 23/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.3066 - acc: 0.8620 - val_loss: 0.3156 - val_acc: 0.8607\n",
      "Epoch 24/300\n",
      "384480/384480 [==============================] - 4s 9us/step - loss: 0.3045 - acc: 0.8631 - val_loss: 0.3229 - val_acc: 0.8571\n",
      "Epoch 25/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.3030 - acc: 0.8635 - val_loss: 0.3206 - val_acc: 0.8557\n",
      "Epoch 26/300\n",
      "384480/384480 [==============================] - 4s 9us/step - loss: 0.3006 - acc: 0.8648 - val_loss: 0.3161 - val_acc: 0.8609\n",
      "Epoch 27/300\n",
      "384480/384480 [==============================] - 4s 9us/step - loss: 0.2996 - acc: 0.8655 - val_loss: 0.3072 - val_acc: 0.8661\n",
      "Epoch 28/300\n",
      "384480/384480 [==============================] - 4s 9us/step - loss: 0.2981 - acc: 0.8664 - val_loss: 0.3069 - val_acc: 0.8659\n",
      "Epoch 29/300\n",
      "384480/384480 [==============================] - 4s 9us/step - loss: 0.2971 - acc: 0.8668 - val_loss: 0.3122 - val_acc: 0.8609\n",
      "Epoch 30/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2960 - acc: 0.8677 - val_loss: 0.3165 - val_acc: 0.8589\n",
      "Epoch 31/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2943 - acc: 0.8685 - val_loss: 0.3143 - val_acc: 0.8637\n",
      "Epoch 32/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2931 - acc: 0.8690 - val_loss: 0.3033 - val_acc: 0.8674\n",
      "Epoch 33/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2928 - acc: 0.8693 - val_loss: 0.3039 - val_acc: 0.8661\n",
      "Epoch 34/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2914 - acc: 0.8705 - val_loss: 0.3208 - val_acc: 0.8567\n",
      "Epoch 35/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2904 - acc: 0.8708 - val_loss: 0.3172 - val_acc: 0.8578\n",
      "Epoch 36/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2895 - acc: 0.8709 - val_loss: 0.2991 - val_acc: 0.8710\n",
      "Epoch 37/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2881 - acc: 0.8716 - val_loss: 0.3132 - val_acc: 0.8587\n",
      "Epoch 38/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2872 - acc: 0.8725 - val_loss: 0.3115 - val_acc: 0.8648\n",
      "Epoch 39/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2863 - acc: 0.8731 - val_loss: 0.3058 - val_acc: 0.8673\n",
      "Epoch 40/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2855 - acc: 0.8736 - val_loss: 0.3120 - val_acc: 0.8634\n",
      "Epoch 41/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2857 - acc: 0.8734 - val_loss: 0.3017 - val_acc: 0.8701\n",
      "Epoch 42/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2840 - acc: 0.8744 - val_loss: 0.2996 - val_acc: 0.8712\n",
      "Epoch 43/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2840 - acc: 0.8741 - val_loss: 0.3089 - val_acc: 0.8662\n",
      "Epoch 44/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2833 - acc: 0.8741 - val_loss: 0.3013 - val_acc: 0.8709\n",
      "Epoch 45/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2822 - acc: 0.8753 - val_loss: 0.2973 - val_acc: 0.8704\n",
      "Epoch 46/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2820 - acc: 0.8750 - val_loss: 0.2997 - val_acc: 0.8693\n",
      "Epoch 47/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2807 - acc: 0.8764 - val_loss: 0.3017 - val_acc: 0.8672\n",
      "Epoch 48/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2800 - acc: 0.8759 - val_loss: 0.3053 - val_acc: 0.8677\n",
      "Epoch 49/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2798 - acc: 0.8770 - val_loss: 0.3083 - val_acc: 0.8653\n",
      "Epoch 50/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2793 - acc: 0.8768 - val_loss: 0.2982 - val_acc: 0.8710\n",
      "Epoch 51/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2781 - acc: 0.8773 - val_loss: 0.3010 - val_acc: 0.8699\n",
      "Epoch 52/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2786 - acc: 0.8767 - val_loss: 0.2995 - val_acc: 0.8697\n",
      "Epoch 53/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2776 - acc: 0.8776 - val_loss: 0.2982 - val_acc: 0.8711\n",
      "Epoch 54/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2770 - acc: 0.8777 - val_loss: 0.3073 - val_acc: 0.8637\n",
      "Epoch 55/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2764 - acc: 0.8782 - val_loss: 0.3042 - val_acc: 0.8671\n",
      "\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 56/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2598 - acc: 0.8881 - val_loss: 0.2847 - val_acc: 0.8787\n",
      "Epoch 57/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2592 - acc: 0.8883 - val_loss: 0.2837 - val_acc: 0.8808\n",
      "Epoch 58/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2591 - acc: 0.8883 - val_loss: 0.2852 - val_acc: 0.8800\n",
      "Epoch 59/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2589 - acc: 0.8884 - val_loss: 0.2840 - val_acc: 0.8806\n",
      "Epoch 60/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2587 - acc: 0.8886 - val_loss: 0.2838 - val_acc: 0.8800\n",
      "Epoch 61/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2585 - acc: 0.8885 - val_loss: 0.2854 - val_acc: 0.8795\n",
      "Epoch 62/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2584 - acc: 0.8888 - val_loss: 0.2844 - val_acc: 0.8790\n",
      "Epoch 63/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2582 - acc: 0.8887 - val_loss: 0.2838 - val_acc: 0.8803\n",
      "Epoch 64/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2580 - acc: 0.8890 - val_loss: 0.2828 - val_acc: 0.8804\n",
      "Epoch 65/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2578 - acc: 0.8893 - val_loss: 0.2826 - val_acc: 0.8808\n",
      "Epoch 66/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2577 - acc: 0.8891 - val_loss: 0.2817 - val_acc: 0.8818\n",
      "Epoch 67/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2575 - acc: 0.8891 - val_loss: 0.2839 - val_acc: 0.8795\n",
      "Epoch 68/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2574 - acc: 0.8892 - val_loss: 0.2834 - val_acc: 0.8800\n",
      "Epoch 69/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2573 - acc: 0.8892 - val_loss: 0.2841 - val_acc: 0.8796\n",
      "Epoch 70/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2573 - acc: 0.8891 - val_loss: 0.2836 - val_acc: 0.8802\n",
      "Epoch 71/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2571 - acc: 0.8895 - val_loss: 0.2817 - val_acc: 0.8804\n",
      "Epoch 72/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2570 - acc: 0.8895 - val_loss: 0.2844 - val_acc: 0.8787\n",
      "Epoch 73/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2569 - acc: 0.8892 - val_loss: 0.2819 - val_acc: 0.8807\n",
      "Epoch 74/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2566 - acc: 0.8897 - val_loss: 0.2810 - val_acc: 0.8821\n",
      "Epoch 75/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2566 - acc: 0.8895 - val_loss: 0.2833 - val_acc: 0.8803\n",
      "Epoch 76/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2565 - acc: 0.8898 - val_loss: 0.2819 - val_acc: 0.8813\n",
      "Epoch 77/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2563 - acc: 0.8900 - val_loss: 0.2817 - val_acc: 0.8816\n",
      "Epoch 78/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2562 - acc: 0.8898 - val_loss: 0.2816 - val_acc: 0.8816\n",
      "Epoch 79/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2562 - acc: 0.8899 - val_loss: 0.2830 - val_acc: 0.8809\n",
      "Epoch 80/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2560 - acc: 0.8896 - val_loss: 0.2831 - val_acc: 0.8808\n",
      "Epoch 81/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2559 - acc: 0.8900 - val_loss: 0.2831 - val_acc: 0.8801\n",
      "Epoch 82/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2558 - acc: 0.8899 - val_loss: 0.2810 - val_acc: 0.8825\n",
      "Epoch 83/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2557 - acc: 0.8902 - val_loss: 0.2819 - val_acc: 0.8811\n",
      "Epoch 84/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2555 - acc: 0.8901 - val_loss: 0.2827 - val_acc: 0.8813\n",
      "\n",
      "Epoch 00084: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 85/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2537 - acc: 0.8912 - val_loss: 0.2806 - val_acc: 0.8822\n",
      "Epoch 86/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2535 - acc: 0.8912 - val_loss: 0.2809 - val_acc: 0.8817\n",
      "Epoch 87/300\n",
      "384480/384480 [==============================] - 4s 9us/step - loss: 0.2534 - acc: 0.8914 - val_loss: 0.2809 - val_acc: 0.8818\n",
      "Epoch 88/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2534 - acc: 0.8913 - val_loss: 0.2802 - val_acc: 0.8826\n",
      "Epoch 89/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2534 - acc: 0.8914 - val_loss: 0.2806 - val_acc: 0.8818\n",
      "Epoch 90/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2534 - acc: 0.8914 - val_loss: 0.2807 - val_acc: 0.8819\n",
      "Epoch 91/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2534 - acc: 0.8915 - val_loss: 0.2807 - val_acc: 0.8817\n",
      "Epoch 92/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2534 - acc: 0.8914 - val_loss: 0.2803 - val_acc: 0.8824\n",
      "Epoch 93/300\n",
      "384480/384480 [==============================] - 4s 9us/step - loss: 0.2534 - acc: 0.8914 - val_loss: 0.2808 - val_acc: 0.8815\n",
      "Epoch 94/300\n",
      "384480/384480 [==============================] - 4s 9us/step - loss: 0.2533 - acc: 0.8914 - val_loss: 0.2804 - val_acc: 0.8819\n",
      "Epoch 95/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2533 - acc: 0.8914 - val_loss: 0.2806 - val_acc: 0.8820\n",
      "Epoch 96/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2533 - acc: 0.8914 - val_loss: 0.2807 - val_acc: 0.8820\n",
      "Epoch 97/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2533 - acc: 0.8914 - val_loss: 0.2808 - val_acc: 0.8816\n",
      "Epoch 98/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2533 - acc: 0.8915 - val_loss: 0.2804 - val_acc: 0.8822\n",
      "\n",
      "Epoch 00098: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 99/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2531 - acc: 0.8916 - val_loss: 0.2804 - val_acc: 0.8821\n",
      "Epoch 100/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2530 - acc: 0.8916 - val_loss: 0.2804 - val_acc: 0.8820\n",
      "Epoch 101/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2530 - acc: 0.8916 - val_loss: 0.2804 - val_acc: 0.8820\n",
      "Epoch 102/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2530 - acc: 0.8916 - val_loss: 0.2804 - val_acc: 0.8820\n",
      "Epoch 103/300\n",
      "384480/384480 [==============================] - 3s 9us/step - loss: 0.2530 - acc: 0.8917 - val_loss: 0.2804 - val_acc: 0.8821\n",
      "Epoch 00103: early stopping\n",
      "Saved SNNClassifier - units 256\n",
      "Predicting on files...\n",
      "Predicting on samples...\n",
      "Test accuracy - files : 1.0\n",
      "Test accuracy - samples : 0.8861442697868652\n"
     ]
    }
   ],
   "source": [
    "test_classifier(SNNClassifier(num_units=256, verbose=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We gain a very marginal increase in sample accuracy. File accuracy is still perfect. Increasing the model complexity further shouldn't yield any worthy increase in accuracy, as this model (and even the one with 128 units) is complex enough to accurately class the audio files.\n",
    "\n",
    "I decided to not add any Dropout or regularization to the network because, as we can see in the results, there is little to no overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neural Network\n",
    "The CNN Classifier was more difficult to implement.    \n",
    "First, the input is different compared to the other classifiers. We need to give identical 2D inputs to the network, but the number of samples per file varies a lot.    \n",
    "- The first attempt was padding the smaller files to the size of the biggest one by adding 0s features. Due to the difference in size, the network couldn't learn anything, as most of the data was empty (smallest file has 46 samples, biggest has around 1200).   \n",
    "- The next attempt was cutting the files into smaller windows of 46 samples (and potentially padding the last sample of the file). The next cell is the (reduced) output of a run using this strategy.    \n",
    "- The current one is to cut the files into windows of 10 samples. We'll see the result later.\n",
    "\n",
    "As the purpose of this classifier is to be a deep neural network, I decided to put two convolutional layers along with two max pooling, followed by two denses layers and an output layer. The whole network can be seen in the following cell.    \n",
    "Due to the number of parameters for this network (parameters in each layer, layout of the network, etc), most of these are heuristically chosen from a previous project on road segmentation. \n",
    "\n",
    "About design decisions :    \n",
    "- Batch normalization is used for faster and better training\n",
    "- Prelu activation is used instead of relu for potential better results\n",
    "- Glorot Normal initialization is used, but it seems that it is a matter of preference between uniform and normal and has no real impact on performance\n",
    "- Dropouts are used after max pooling and dense layers to reduce overfitting\n",
    "- Kernel regularizers are used on the convolution and dense layers to reduce overfitting\n",
    "- (Both dropouts and regularizers were added after checking that the network could learn perfectly the training set)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Finished loading/creating features\n",
    "Using classifier CNNClassifier\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "batch_normalization_13 (Batc (None, 46, 20, 1)         4         \n",
    "_________________________________________________________________\n",
    "conv2d_9 (Conv2D)            (None, 44, 18, 32)        320       \n",
    "_________________________________________________________________\n",
    "p_re_lu_17 (PReLU)           (None, 44, 18, 32)        25344     \n",
    "_________________________________________________________________\n",
    "batch_normalization_14 (Batc (None, 44, 18, 32)        128       \n",
    "_________________________________________________________________\n",
    "max_pooling2d_9 (MaxPooling2 (None, 43, 17, 32)        0         \n",
    "_________________________________________________________________\n",
    "dropout_17 (Dropout)         (None, 43, 17, 32)        0         \n",
    "_________________________________________________________________\n",
    "conv2d_10 (Conv2D)           (None, 41, 15, 64)        18496     \n",
    "_________________________________________________________________\n",
    "p_re_lu_18 (PReLU)           (None, 41, 15, 64)        39360     \n",
    "_________________________________________________________________\n",
    "batch_normalization_15 (Batc (None, 41, 15, 64)        256       \n",
    "_________________________________________________________________\n",
    "max_pooling2d_10 (MaxPooling (None, 40, 14, 64)        0         \n",
    "_________________________________________________________________\n",
    "dropout_18 (Dropout)         (None, 40, 14, 64)        0         \n",
    "_________________________________________________________________\n",
    "flatten_5 (Flatten)          (None, 35840)             0         \n",
    "_________________________________________________________________\n",
    "dense_13 (Dense)             (None, 512)               18350592  \n",
    "_________________________________________________________________\n",
    "p_re_lu_19 (PReLU)           (None, 512)               512       \n",
    "_________________________________________________________________\n",
    "dropout_19 (Dropout)         (None, 512)               0         \n",
    "_________________________________________________________________\n",
    "dense_14 (Dense)             (None, 256)               131328    \n",
    "_________________________________________________________________\n",
    "p_re_lu_20 (PReLU)           (None, 256)               256       \n",
    "_________________________________________________________________\n",
    "dropout_20 (Dropout)         (None, 256)               0         \n",
    "_________________________________________________________________\n",
    "dense_15 (Dense)             (None, 1)                 257       \n",
    "_________________________________________________________________\n",
    "activation_5 (Activation)    (None, 1)                 0         \n",
    "=================================================================\n",
    "Total params: 18,566,853\n",
    "Trainable params: 18,566,659\n",
    "Non-trainable params: 194\n",
    "_________________________________________________________________\n",
    "None\n",
    "Training CNNClassifier\n",
    "Train on 9183 samples, validate on 2296 samples\n",
    "Epoch 1/200\n",
    "9183/9183 [==============================] - 5s 527us/step - loss: 14.4615 - acc: 0.5050 - val_loss: 10.9467 - val_acc: 0.4808\n",
    "Epoch 2/200\n",
    "9183/9183 [==============================] - 3s 371us/step - loss: 7.1822 - acc: 0.5513 - val_loss: 4.3108 - val_acc: 0.7522\n",
    "...\n",
    "Epoch 17/200\n",
    "9183/9183 [==============================] - 3s 375us/step - loss: 0.7153 - acc: 0.9245 - val_loss: 0.6791 - val_acc: 0.9299\n",
    "...\n",
    "Epoch 50/200\n",
    "9183/9183 [==============================] - 3s 371us/step - loss: 0.3034 - acc: 0.9543 - val_loss: 0.3069 - val_acc: 0.9525\n",
    "...\n",
    "Epoch 92/200\n",
    "9183/9183 [==============================] - 4s 411us/step - loss: 0.1006 - acc: 0.9808 - val_loss: 0.1658 - val_acc: 0.9612\n",
    "...\n",
    "Epoch 153/200\n",
    "9183/9183 [==============================] - 4s 390us/step - loss: 0.0760 - acc: 0.9857 - val_loss: 0.1658 - val_acc: 0.9564\n",
    "Epoch 154/200\n",
    "9183/9183 [==============================] - 3s 381us/step - loss: 0.0759 - acc: 0.9858 - val_loss: 0.1660 - val_acc: 0.9573\n",
    "\n",
    "Epoch 00154: early stopping\n",
    "Saved CNNClassifier\n",
    "Predicting on files...\n",
    "Predicting on samples...\n",
    "Test accuracy - files : 0.9796672828096118\n",
    "Test accuracy - samples : 0.9539430086149768\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the CNN got a really good score for both file and sample accuracy, but it strangely was not perfect like the SNN and is even a bit worse than the random forest. Moreover, the sample accuracy can not really be compared to the one obtained with the previous classifiers, as the CNN has more context (46 times more information than the other classifiers).  \n",
    "The next run obtains a perfect file score by reducing the window size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_for_classifier\n",
      "Finished loading/creating features\n",
      "Using classifier CNNClassifier\n",
      "Training CNNClassifier\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_1 (Batch (None, 10, 20, 1)         4         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 8, 18, 32)         320       \n",
      "_________________________________________________________________\n",
      "p_re_lu_1 (PReLU)            (None, 8, 18, 32)         4608      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 8, 18, 32)         128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 17, 32)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 7, 17, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 5, 15, 64)         18496     \n",
      "_________________________________________________________________\n",
      "p_re_lu_2 (PReLU)            (None, 5, 15, 64)         4800      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 5, 15, 64)         256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 14, 64)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 14, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3584)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1835520   \n",
      "_________________________________________________________________\n",
      "p_re_lu_3 (PReLU)            (None, 512)               512       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "p_re_lu_4 (PReLU)            (None, 256)               256       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,996,485\n",
      "Trainable params: 1,996,291\n",
      "Non-trainable params: 194\n",
      "_________________________________________________________________\n",
      "None\n",
      "getModeCNN\n",
      "Train on 14134 samples, validate on 3534 samples\n",
      "Epoch 1/300\n",
      "14134/14134 [==============================] - 14s 1ms/step - loss: 8.0929 - acc: 0.6261 - val_loss: 3.8418 - val_acc: 0.7196\n",
      "Epoch 2/300\n",
      "14134/14134 [==============================] - 13s 909us/step - loss: 2.5610 - acc: 0.7180 - val_loss: 1.6531 - val_acc: 0.7620\n",
      "Epoch 3/300\n",
      "14134/14134 [==============================] - 14s 959us/step - loss: 1.3574 - acc: 0.7430 - val_loss: 1.0578 - val_acc: 0.7756\n",
      "Epoch 4/300\n",
      "14134/14134 [==============================] - 13s 905us/step - loss: 0.9667 - acc: 0.7616 - val_loss: 0.8225 - val_acc: 0.7892\n",
      "Epoch 5/300\n",
      "14134/14134 [==============================] - 13s 891us/step - loss: 0.7820 - acc: 0.7781 - val_loss: 0.7051 - val_acc: 0.8028\n",
      "Epoch 6/300\n",
      "14134/14134 [==============================] - 13s 906us/step - loss: 0.7006 - acc: 0.7812 - val_loss: 0.6382 - val_acc: 0.7937\n",
      "Epoch 7/300\n",
      "14134/14134 [==============================] - 13s 887us/step - loss: 0.6387 - acc: 0.7928 - val_loss: 0.5921 - val_acc: 0.8124\n",
      "Epoch 8/300\n",
      "14134/14134 [==============================] - 12s 875us/step - loss: 0.6138 - acc: 0.7945 - val_loss: 0.5716 - val_acc: 0.8076\n",
      "Epoch 9/300\n",
      "14134/14134 [==============================] - 12s 883us/step - loss: 0.5880 - acc: 0.7948 - val_loss: 0.5414 - val_acc: 0.8234\n",
      "Epoch 10/300\n",
      "14134/14134 [==============================] - 12s 875us/step - loss: 0.5807 - acc: 0.7942 - val_loss: 0.5317 - val_acc: 0.8121\n",
      "Epoch 11/300\n",
      "14134/14134 [==============================] - 13s 887us/step - loss: 0.5548 - acc: 0.8061 - val_loss: 0.5154 - val_acc: 0.8291\n",
      "Epoch 12/300\n",
      "14134/14134 [==============================] - 13s 892us/step - loss: 0.5476 - acc: 0.8059 - val_loss: 0.5179 - val_acc: 0.8260\n",
      "Epoch 13/300\n",
      "14134/14134 [==============================] - 13s 887us/step - loss: 0.5503 - acc: 0.8115 - val_loss: 0.5206 - val_acc: 0.8178\n",
      "Epoch 14/300\n",
      "14134/14134 [==============================] - 13s 895us/step - loss: 0.5449 - acc: 0.8071 - val_loss: 0.5464 - val_acc: 0.8016\n",
      "Epoch 15/300\n",
      "14134/14134 [==============================] - 13s 891us/step - loss: 0.5316 - acc: 0.8146 - val_loss: 0.4963 - val_acc: 0.8268\n",
      "Epoch 16/300\n",
      "14134/14134 [==============================] - 13s 886us/step - loss: 0.5364 - acc: 0.8123 - val_loss: 0.5156 - val_acc: 0.8144\n",
      "Epoch 17/300\n",
      "14134/14134 [==============================] - 13s 886us/step - loss: 0.5224 - acc: 0.8159 - val_loss: 0.4978 - val_acc: 0.8268\n",
      "Epoch 18/300\n",
      "14134/14134 [==============================] - 13s 902us/step - loss: 0.5227 - acc: 0.8166 - val_loss: 0.4815 - val_acc: 0.8319\n",
      "Epoch 19/300\n",
      "14134/14134 [==============================] - 13s 891us/step - loss: 0.5187 - acc: 0.8177 - val_loss: 0.5036 - val_acc: 0.8212\n",
      "Epoch 20/300\n",
      "14134/14134 [==============================] - 12s 878us/step - loss: 0.5131 - acc: 0.8223 - val_loss: 0.4896 - val_acc: 0.8347\n",
      "Epoch 21/300\n",
      "14134/14134 [==============================] - 12s 878us/step - loss: 0.5150 - acc: 0.8175 - val_loss: 0.4858 - val_acc: 0.8345\n",
      "Epoch 22/300\n",
      "14134/14134 [==============================] - 13s 913us/step - loss: 0.5037 - acc: 0.8216 - val_loss: 0.4764 - val_acc: 0.8410\n",
      "Epoch 23/300\n",
      "14134/14134 [==============================] - 13s 901us/step - loss: 0.5019 - acc: 0.8242 - val_loss: 0.4667 - val_acc: 0.8353\n",
      "Epoch 24/300\n",
      "14134/14134 [==============================] - 13s 897us/step - loss: 0.5079 - acc: 0.8204 - val_loss: 0.4782 - val_acc: 0.8336\n",
      "Epoch 25/300\n",
      "14134/14134 [==============================] - 13s 898us/step - loss: 0.5041 - acc: 0.8226 - val_loss: 0.4851 - val_acc: 0.8297\n",
      "Epoch 26/300\n",
      "14134/14134 [==============================] - 13s 887us/step - loss: 0.4954 - acc: 0.8257 - val_loss: 0.4661 - val_acc: 0.8393\n",
      "Epoch 27/300\n",
      "14134/14134 [==============================] - 13s 891us/step - loss: 0.4936 - acc: 0.8262 - val_loss: 0.4794 - val_acc: 0.8438\n",
      "Epoch 28/300\n",
      "14134/14134 [==============================] - 13s 909us/step - loss: 0.4936 - acc: 0.8269 - val_loss: 0.4813 - val_acc: 0.8302\n",
      "Epoch 29/300\n",
      "14134/14134 [==============================] - 13s 886us/step - loss: 0.5012 - acc: 0.8271 - val_loss: 0.4934 - val_acc: 0.8248\n",
      "Epoch 30/300\n",
      "14134/14134 [==============================] - 12s 883us/step - loss: 0.4896 - acc: 0.8268 - val_loss: 0.4646 - val_acc: 0.8449\n",
      "Epoch 31/300\n",
      "14134/14134 [==============================] - 13s 891us/step - loss: 0.4867 - acc: 0.8298 - val_loss: 0.4708 - val_acc: 0.8396\n",
      "Epoch 32/300\n",
      "14134/14134 [==============================] - 13s 913us/step - loss: 0.4874 - acc: 0.8290 - val_loss: 0.4660 - val_acc: 0.8308\n",
      "Epoch 33/300\n",
      "14134/14134 [==============================] - 13s 902us/step - loss: 0.4840 - acc: 0.8296 - val_loss: 0.4563 - val_acc: 0.8404\n",
      "Epoch 34/300\n",
      "14134/14134 [==============================] - 13s 895us/step - loss: 0.4866 - acc: 0.8314 - val_loss: 0.4515 - val_acc: 0.8444\n",
      "Epoch 35/300\n",
      "14134/14134 [==============================] - 13s 886us/step - loss: 0.4851 - acc: 0.8300 - val_loss: 0.4564 - val_acc: 0.8393\n",
      "Epoch 36/300\n",
      "14134/14134 [==============================] - 13s 923us/step - loss: 0.4823 - acc: 0.8324 - val_loss: 0.4494 - val_acc: 0.8447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/300\n",
      "14134/14134 [==============================] - 13s 905us/step - loss: 0.4760 - acc: 0.8313 - val_loss: 0.4772 - val_acc: 0.8356\n",
      "Epoch 38/300\n",
      "14134/14134 [==============================] - 13s 894us/step - loss: 0.4846 - acc: 0.8270 - val_loss: 0.4653 - val_acc: 0.8475\n",
      "Epoch 39/300\n",
      "14134/14134 [==============================] - 13s 897us/step - loss: 0.4886 - acc: 0.8335 - val_loss: 0.4625 - val_acc: 0.8534\n",
      "Epoch 40/300\n",
      "14134/14134 [==============================] - 12s 881us/step - loss: 0.4793 - acc: 0.8318 - val_loss: 0.4802 - val_acc: 0.8220\n",
      "Epoch 41/300\n",
      "14134/14134 [==============================] - 12s 879us/step - loss: 0.4752 - acc: 0.8356 - val_loss: 0.4912 - val_acc: 0.8274\n",
      "Epoch 42/300\n",
      "14134/14134 [==============================] - 12s 880us/step - loss: 0.4821 - acc: 0.8321 - val_loss: 0.4563 - val_acc: 0.8565\n",
      "Epoch 43/300\n",
      "14134/14134 [==============================] - 13s 903us/step - loss: 0.4789 - acc: 0.8337 - val_loss: 0.4507 - val_acc: 0.8531\n",
      "Epoch 44/300\n",
      "14134/14134 [==============================] - 13s 901us/step - loss: 0.4763 - acc: 0.8356 - val_loss: 0.4667 - val_acc: 0.8384\n",
      "Epoch 45/300\n",
      "14134/14134 [==============================] - 13s 897us/step - loss: 0.4852 - acc: 0.8381 - val_loss: 0.4625 - val_acc: 0.8546\n",
      "Epoch 46/300\n",
      "14134/14134 [==============================] - 13s 890us/step - loss: 0.4760 - acc: 0.8369 - val_loss: 0.4566 - val_acc: 0.8421\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 47/300\n",
      "14134/14134 [==============================] - 13s 915us/step - loss: 0.4428 - acc: 0.8480 - val_loss: 0.4282 - val_acc: 0.8534\n",
      "Epoch 48/300\n",
      "14134/14134 [==============================] - 13s 901us/step - loss: 0.4087 - acc: 0.8589 - val_loss: 0.4062 - val_acc: 0.8602\n",
      "Epoch 49/300\n",
      "14134/14134 [==============================] - 13s 907us/step - loss: 0.3921 - acc: 0.8625 - val_loss: 0.3933 - val_acc: 0.8676\n",
      "Epoch 50/300\n",
      "14134/14134 [==============================] - 13s 904us/step - loss: 0.3805 - acc: 0.8660 - val_loss: 0.3942 - val_acc: 0.8645\n",
      "Epoch 51/300\n",
      "14134/14134 [==============================] - 13s 904us/step - loss: 0.3714 - acc: 0.8650 - val_loss: 0.3777 - val_acc: 0.8636\n",
      "Epoch 52/300\n",
      "14134/14134 [==============================] - 13s 905us/step - loss: 0.3645 - acc: 0.8688 - val_loss: 0.3818 - val_acc: 0.8582\n",
      "Epoch 53/300\n",
      "14134/14134 [==============================] - 13s 903us/step - loss: 0.3546 - acc: 0.8717 - val_loss: 0.3676 - val_acc: 0.8687\n",
      "Epoch 54/300\n",
      "14134/14134 [==============================] - 12s 881us/step - loss: 0.3530 - acc: 0.8712 - val_loss: 0.3701 - val_acc: 0.8653\n",
      "Epoch 55/300\n",
      "14134/14134 [==============================] - 12s 881us/step - loss: 0.3489 - acc: 0.8679 - val_loss: 0.3670 - val_acc: 0.8684\n",
      "Epoch 56/300\n",
      "14134/14134 [==============================] - 12s 875us/step - loss: 0.3417 - acc: 0.8742 - val_loss: 0.3645 - val_acc: 0.8690\n",
      "Epoch 57/300\n",
      "14134/14134 [==============================] - 12s 882us/step - loss: 0.3405 - acc: 0.8753 - val_loss: 0.3586 - val_acc: 0.8701\n",
      "Epoch 58/300\n",
      "14134/14134 [==============================] - 12s 881us/step - loss: 0.3321 - acc: 0.8759 - val_loss: 0.3539 - val_acc: 0.8707\n",
      "Epoch 59/300\n",
      "14134/14134 [==============================] - 12s 882us/step - loss: 0.3313 - acc: 0.8770 - val_loss: 0.3544 - val_acc: 0.8701\n",
      "Epoch 60/300\n",
      "14134/14134 [==============================] - 13s 919us/step - loss: 0.3298 - acc: 0.8786 - val_loss: 0.3525 - val_acc: 0.8761\n",
      "Epoch 61/300\n",
      "14134/14134 [==============================] - 13s 902us/step - loss: 0.3216 - acc: 0.8782 - val_loss: 0.3485 - val_acc: 0.8698\n",
      "Epoch 62/300\n",
      "14134/14134 [==============================] - 13s 903us/step - loss: 0.3199 - acc: 0.8818 - val_loss: 0.3498 - val_acc: 0.8701\n",
      "Epoch 63/300\n",
      "14134/14134 [==============================] - 12s 882us/step - loss: 0.3198 - acc: 0.8838 - val_loss: 0.3511 - val_acc: 0.8696\n",
      "Epoch 64/300\n",
      "14134/14134 [==============================] - 13s 888us/step - loss: 0.3154 - acc: 0.8797 - val_loss: 0.3450 - val_acc: 0.8729\n",
      "Epoch 65/300\n",
      "14134/14134 [==============================] - 13s 902us/step - loss: 0.3153 - acc: 0.8810 - val_loss: 0.3451 - val_acc: 0.8707\n",
      "Epoch 66/300\n",
      "14134/14134 [==============================] - 13s 894us/step - loss: 0.3098 - acc: 0.8839 - val_loss: 0.3435 - val_acc: 0.8729\n",
      "Epoch 67/300\n",
      "14134/14134 [==============================] - 13s 908us/step - loss: 0.3115 - acc: 0.8837 - val_loss: 0.3552 - val_acc: 0.8662\n",
      "Epoch 68/300\n",
      "14134/14134 [==============================] - 13s 916us/step - loss: 0.3105 - acc: 0.8859 - val_loss: 0.3426 - val_acc: 0.8724\n",
      "Epoch 69/300\n",
      "14134/14134 [==============================] - 13s 920us/step - loss: 0.3081 - acc: 0.8838 - val_loss: 0.3377 - val_acc: 0.8820\n",
      "Epoch 70/300\n",
      "14134/14134 [==============================] - 13s 927us/step - loss: 0.3067 - acc: 0.8832 - val_loss: 0.3452 - val_acc: 0.8744\n",
      "Epoch 71/300\n",
      "14134/14134 [==============================] - 13s 916us/step - loss: 0.3059 - acc: 0.8845 - val_loss: 0.3550 - val_acc: 0.8662\n",
      "Epoch 72/300\n",
      "14134/14134 [==============================] - 13s 909us/step - loss: 0.3071 - acc: 0.8847 - val_loss: 0.3401 - val_acc: 0.8749\n",
      "Epoch 73/300\n",
      "14134/14134 [==============================] - 13s 937us/step - loss: 0.3013 - acc: 0.8874 - val_loss: 0.3396 - val_acc: 0.8713\n",
      "Epoch 74/300\n",
      "14134/14134 [==============================] - 13s 920us/step - loss: 0.2966 - acc: 0.8914 - val_loss: 0.3385 - val_acc: 0.8729\n",
      "Epoch 75/300\n",
      "14134/14134 [==============================] - 13s 915us/step - loss: 0.3004 - acc: 0.8893 - val_loss: 0.3417 - val_acc: 0.8758\n",
      "Epoch 76/300\n",
      "14134/14134 [==============================] - 13s 915us/step - loss: 0.3005 - acc: 0.8884 - val_loss: 0.3464 - val_acc: 0.8741\n",
      "Epoch 77/300\n",
      "14134/14134 [==============================] - 13s 910us/step - loss: 0.2980 - acc: 0.8883 - val_loss: 0.3379 - val_acc: 0.8707\n",
      "Epoch 78/300\n",
      "14134/14134 [==============================] - 13s 906us/step - loss: 0.2930 - acc: 0.8932 - val_loss: 0.3543 - val_acc: 0.8647\n",
      "Epoch 79/300\n",
      "14134/14134 [==============================] - 13s 898us/step - loss: 0.2916 - acc: 0.8927 - val_loss: 0.3349 - val_acc: 0.8758\n",
      "Epoch 80/300\n",
      "14134/14134 [==============================] - 13s 900us/step - loss: 0.2945 - acc: 0.8915 - val_loss: 0.3389 - val_acc: 0.8690\n",
      "Epoch 81/300\n",
      "14134/14134 [==============================] - 13s 898us/step - loss: 0.2906 - acc: 0.8900 - val_loss: 0.3439 - val_acc: 0.8735\n",
      "Epoch 82/300\n",
      "14134/14134 [==============================] - 13s 902us/step - loss: 0.2941 - acc: 0.8912 - val_loss: 0.3456 - val_acc: 0.8659\n",
      "Epoch 83/300\n",
      "14134/14134 [==============================] - 13s 898us/step - loss: 0.2930 - acc: 0.8901 - val_loss: 0.3377 - val_acc: 0.8732\n",
      "Epoch 84/300\n",
      "14134/14134 [==============================] - 13s 918us/step - loss: 0.2929 - acc: 0.8924 - val_loss: 0.3413 - val_acc: 0.8707\n",
      "Epoch 85/300\n",
      "14134/14134 [==============================] - 13s 909us/step - loss: 0.2952 - acc: 0.8912 - val_loss: 0.3407 - val_acc: 0.8698\n",
      "Epoch 86/300\n",
      "14134/14134 [==============================] - 13s 923us/step - loss: 0.2896 - acc: 0.8945 - val_loss: 0.3373 - val_acc: 0.8718\n",
      "Epoch 87/300\n",
      "14134/14134 [==============================] - 13s 909us/step - loss: 0.2888 - acc: 0.8922 - val_loss: 0.3451 - val_acc: 0.8696\n",
      "Epoch 88/300\n",
      "14134/14134 [==============================] - 13s 903us/step - loss: 0.2888 - acc: 0.8955 - val_loss: 0.3365 - val_acc: 0.8800\n",
      "Epoch 89/300\n",
      "14134/14134 [==============================] - 13s 927us/step - loss: 0.2872 - acc: 0.8962 - val_loss: 0.3414 - val_acc: 0.8758\n",
      "\n",
      "Epoch 00089: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 90/300\n",
      "14134/14134 [==============================] - 13s 928us/step - loss: 0.2832 - acc: 0.8969 - val_loss: 0.3397 - val_acc: 0.8775\n",
      "Epoch 91/300\n",
      "14134/14134 [==============================] - 13s 912us/step - loss: 0.2809 - acc: 0.8959 - val_loss: 0.3336 - val_acc: 0.8783\n",
      "Epoch 92/300\n",
      "14134/14134 [==============================] - 13s 907us/step - loss: 0.2805 - acc: 0.8980 - val_loss: 0.3354 - val_acc: 0.8744\n",
      "Epoch 93/300\n",
      "14134/14134 [==============================] - 13s 901us/step - loss: 0.2756 - acc: 0.9000 - val_loss: 0.3399 - val_acc: 0.8727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/300\n",
      "14134/14134 [==============================] - 13s 898us/step - loss: 0.2750 - acc: 0.8985 - val_loss: 0.3347 - val_acc: 0.8772\n",
      "Epoch 95/300\n",
      "14134/14134 [==============================] - 12s 884us/step - loss: 0.2720 - acc: 0.9002 - val_loss: 0.3328 - val_acc: 0.8775\n",
      "Epoch 96/300\n",
      "14134/14134 [==============================] - 12s 882us/step - loss: 0.2750 - acc: 0.9014 - val_loss: 0.3368 - val_acc: 0.8769\n",
      "Epoch 97/300\n",
      "14134/14134 [==============================] - 12s 884us/step - loss: 0.2739 - acc: 0.9005 - val_loss: 0.3291 - val_acc: 0.8769\n",
      "Epoch 98/300\n",
      "14134/14134 [==============================] - 13s 885us/step - loss: 0.2693 - acc: 0.9053 - val_loss: 0.3341 - val_acc: 0.8766\n",
      "Epoch 99/300\n",
      "14134/14134 [==============================] - 12s 882us/step - loss: 0.2763 - acc: 0.8995 - val_loss: 0.3326 - val_acc: 0.8775\n",
      "Epoch 100/300\n",
      "14134/14134 [==============================] - 13s 888us/step - loss: 0.2729 - acc: 0.9006 - val_loss: 0.3343 - val_acc: 0.8803\n",
      "Epoch 101/300\n",
      "14134/14134 [==============================] - 12s 884us/step - loss: 0.2718 - acc: 0.9024 - val_loss: 0.3303 - val_acc: 0.8780\n",
      "Epoch 102/300\n",
      "14134/14134 [==============================] - 13s 887us/step - loss: 0.2691 - acc: 0.9024 - val_loss: 0.3305 - val_acc: 0.8763\n",
      "Epoch 103/300\n",
      "14134/14134 [==============================] - 13s 888us/step - loss: 0.2717 - acc: 0.9014 - val_loss: 0.3338 - val_acc: 0.8769\n",
      "Epoch 104/300\n",
      "14134/14134 [==============================] - 12s 879us/step - loss: 0.2726 - acc: 0.9020 - val_loss: 0.3436 - val_acc: 0.8667\n",
      "Epoch 105/300\n",
      "14134/14134 [==============================] - 12s 880us/step - loss: 0.2665 - acc: 0.9030 - val_loss: 0.3292 - val_acc: 0.8758\n",
      "Epoch 106/300\n",
      "14134/14134 [==============================] - 13s 918us/step - loss: 0.2690 - acc: 0.9052 - val_loss: 0.3283 - val_acc: 0.8778\n",
      "Epoch 107/300\n",
      "14134/14134 [==============================] - 12s 879us/step - loss: 0.2670 - acc: 0.9028 - val_loss: 0.3348 - val_acc: 0.8755\n",
      "Epoch 108/300\n",
      "14134/14134 [==============================] - 13s 900us/step - loss: 0.2676 - acc: 0.9026 - val_loss: 0.3347 - val_acc: 0.8778\n",
      "Epoch 109/300\n",
      "14134/14134 [==============================] - 12s 880us/step - loss: 0.2643 - acc: 0.9048 - val_loss: 0.3448 - val_acc: 0.8696\n",
      "Epoch 110/300\n",
      "14134/14134 [==============================] - 12s 873us/step - loss: 0.2629 - acc: 0.9058 - val_loss: 0.3306 - val_acc: 0.8778\n",
      "Epoch 111/300\n",
      "14134/14134 [==============================] - 12s 871us/step - loss: 0.2695 - acc: 0.9043 - val_loss: 0.3339 - val_acc: 0.8752\n",
      "Epoch 112/300\n",
      "14134/14134 [==============================] - 12s 880us/step - loss: 0.2631 - acc: 0.9067 - val_loss: 0.3332 - val_acc: 0.8729\n",
      "Epoch 113/300\n",
      "14134/14134 [==============================] - 13s 900us/step - loss: 0.2669 - acc: 0.9046 - val_loss: 0.3260 - val_acc: 0.8792\n",
      "Epoch 114/300\n",
      "14134/14134 [==============================] - 13s 886us/step - loss: 0.2617 - acc: 0.9063 - val_loss: 0.3305 - val_acc: 0.8786\n",
      "Epoch 115/300\n",
      "14134/14134 [==============================] - 13s 906us/step - loss: 0.2658 - acc: 0.9018 - val_loss: 0.3266 - val_acc: 0.8800\n",
      "Epoch 116/300\n",
      "14134/14134 [==============================] - 13s 903us/step - loss: 0.2653 - acc: 0.9027 - val_loss: 0.3288 - val_acc: 0.8752\n",
      "Epoch 117/300\n",
      "14134/14134 [==============================] - 13s 885us/step - loss: 0.2653 - acc: 0.9026 - val_loss: 0.3278 - val_acc: 0.8780\n",
      "Epoch 118/300\n",
      "14134/14134 [==============================] - 13s 910us/step - loss: 0.2636 - acc: 0.9022 - val_loss: 0.3303 - val_acc: 0.8783\n",
      "Epoch 119/300\n",
      "14134/14134 [==============================] - 13s 890us/step - loss: 0.2639 - acc: 0.9033 - val_loss: 0.3309 - val_acc: 0.8763\n",
      "Epoch 120/300\n",
      "14134/14134 [==============================] - 13s 899us/step - loss: 0.2645 - acc: 0.9068 - val_loss: 0.3294 - val_acc: 0.8789\n",
      "Epoch 121/300\n",
      "14134/14134 [==============================] - 13s 908us/step - loss: 0.2622 - acc: 0.9050 - val_loss: 0.3298 - val_acc: 0.8803\n",
      "Epoch 122/300\n",
      "14134/14134 [==============================] - 13s 935us/step - loss: 0.2601 - acc: 0.9060 - val_loss: 0.3279 - val_acc: 0.8778\n",
      "Epoch 123/300\n",
      "14134/14134 [==============================] - 13s 906us/step - loss: 0.2637 - acc: 0.9056 - val_loss: 0.3279 - val_acc: 0.8806\n",
      "\n",
      "Epoch 00123: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 124/300\n",
      "14134/14134 [==============================] - 13s 905us/step - loss: 0.2593 - acc: 0.9079 - val_loss: 0.3353 - val_acc: 0.8783\n",
      "Epoch 125/300\n",
      "14134/14134 [==============================] - 13s 900us/step - loss: 0.2623 - acc: 0.9077 - val_loss: 0.3286 - val_acc: 0.8792\n",
      "Epoch 126/300\n",
      "14134/14134 [==============================] - 13s 904us/step - loss: 0.2650 - acc: 0.9037 - val_loss: 0.3322 - val_acc: 0.8789\n",
      "Epoch 127/300\n",
      "14134/14134 [==============================] - 13s 906us/step - loss: 0.2620 - acc: 0.9080 - val_loss: 0.3291 - val_acc: 0.8769\n",
      "Epoch 128/300\n",
      "14134/14134 [==============================] - 13s 944us/step - loss: 0.2593 - acc: 0.9077 - val_loss: 0.3291 - val_acc: 0.8786\n",
      "Epoch 00128: early stopping\n",
      "Saved CNNClassifier\n",
      "ModePath:models/CNNClassifier.pkl\n",
      "Predicting on files...\n",
      "Predicting on samples...\n",
      "Test accuracy - files : 0.9539473684210527\n",
      "Test accuracy - samples : 0.8594594594594595\n"
     ]
    }
   ],
   "source": [
    "test_classifier(CNNClassifier(verbose=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test accuracy - files : 0.9798387096774194\n",
    "Test accuracy - samples : 0.8597168597168597"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test accuracy - files : 0.950530035335689\n",
    "Test accuracy - samples : 0.8377042949448879"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, by using windows of size 10, we get a the same result as the RandomForest for file accuracy (1 mispredicted file), which is better than with a window size of 46. It is probably mainly due to averaging over more samples : As the per sample accuracy is still very high, averaging over them allows for a very good score. In theory, as long as we have a per sample accuracy >50% and a very high number of samples per file, the predictions should be perfect. It is not always the case in practice due to the number of samples per file. \n",
    "\n",
    "\n",
    "100% files accuracy should be obtainable by tuning the parameters or changing the layout.      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to the other classifiers however, it is slower to train, more memory hungry, and therefore seems a bit overkill for this task, given than a simple neural net with a single hidden layer obtains file predictions results better than this one.    \n",
    "\n",
    "### Dumps size\n",
    "If we compare the performance/file size metric of the classifiers, we see that the SNN is easily the best one, the 256 units network weighing only 96Ko, compared to the 12Mo for the 10 estimators RandomForest or the 23Mo CNN. The linear SVC only weighs 1Ko, but gives bad results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other considerations\n",
    "- I've also added a cross-validation method to test the classifiers on samples, but due to the time it takes to execute it, I decided to leave it out.\n",
    "- I have considered data augmentation, but given the results we've already obtained, this isn't at all necessary for this problem and would only be wasted time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "In conclusion, we can rate the classifiers like this : \n",
    "- The winner is obviously the SNN. The complexity of designing it is really low, the file size is also very small, and it gets a perfect result.\n",
    "- The second one would be the RandomForest. The design complexity is non-existant, the file size is moderately high but still very manageable for a low number of trees, and it gets a nearly perfect result.\n",
    "- The third is the CNN. Although the design complexity is high due to the number of parameters we can change and layouts we can do, and the file size is higher than the others, it gets a nearly score. It is totally unnecessary to implement such a complex network for this problem though.\n",
    "- The fourth is the linear SVC, because even though the design complexity and file size is null, the results are bad.\n",
    "- For obvious reasons, the constant classifier is the last one.\n",
    "\n",
    "In short, a more complex model is not always better than a simple one. If the neural network doesn't have to learn complex features, which is the case here as it seems that the MFCC features are expressive enough, a simple model can do a very good job while being faster and less resource-intensive to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = RFClassifier(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/RFClassifier - n_est 100 - max_depth None.pkl\n",
      "Begin to Load model\n"
     ]
    }
   ],
   "source": [
    "pathGender = MODELS_DIR + classifier.get_classifier_name() + DUMP_EXT\n",
    "print(pathGender)\n",
    "if os.path.isfile(pathGender):\n",
    "    print(\"Begin to Load model\")\n",
    "    classifier.load(pathGender)\n",
    "    #model.save_weights(\"gender_cnn_model_weight.h5\")\n",
    "    #json_string = model.to_json()\n",
    "    #open('gender_cnn_model_json.json','w').write(json_string)\n",
    "    #model.save(\"gender_cnn_model.h5\")\n",
    "else:\n",
    "    print(\"Model file not exist.{}\".format(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_for_classifier..\n",
      "Finished loading/creating features\n",
      "Using classifier RFClassifier - n_est 100 - max_depth None\n",
      "Loaded RFClassifier - n_est 100 - max_depth None\n",
      "ModePath:models/RFClassifier - n_est 100 - max_depth None.pkl\n",
      "Predicting on files...\n",
      "Predicting on samples...\n",
      "Test accuracy - files : 0.0\n",
      "Test accuracy - samples : 0.4727272727272727\n"
     ]
    }
   ],
   "source": [
    "test_classifier(RFClassifier(n_estimators=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_for_classifier..\n",
      "Finished loading/creating features\n",
      "Using classifier RFClassifier - n_est 100 - max_depth None\n",
      "Loaded RFClassifier - n_est 100 - max_depth None\n",
      "ModePath:models/RFClassifier - n_est 100 - max_depth None.pkl\n",
      "Predicting on files...\n",
      "Predicting on samples...\n",
      "Test accuracy - files : 1.0\n",
      "Test accuracy - samples : 0.5824175824175825\n"
     ]
    }
   ],
   "source": [
    "test_classifier(RFClassifier(n_estimators=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_for_classifier\n",
      "Finished loading/creating features\n",
      "Using classifier RFClassifier - n_est 100 - max_depth None\n",
      "Loaded RFClassifier - n_est 100 - max_depth None\n",
      "ModePath:models/RFClassifier - n_est 100 - max_depth None.pkl\n",
      "Predicting on files...\n",
      "Predicting on samples...\n",
      "Test accuracy - files : 0.969047619047619\n",
      "Test accuracy - samples : 0.8715568593163971\n"
     ]
    }
   ],
   "source": [
    "test_classifier(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_for_classifier..\n",
      "Finished loading/creating features\n",
      "Using classifier RFClassifier - n_est 100 - max_depth None\n",
      "Loaded RFClassifier - n_est 100 - max_depth None\n",
      "ModePath:models/RFClassifier - n_est 100 - max_depth None.pkl\n",
      "Predicting on files...\n",
      "Predicting on samples...\n",
      "Test accuracy - files : 0.969047619047619\n",
      "Test accuracy - samples : 0.8715568593163971\n"
     ]
    }
   ],
   "source": [
    "test_classifier(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
